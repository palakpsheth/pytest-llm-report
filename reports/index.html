<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test Report &bull; 623 tests</title>
    <!-- Optional: Inter font from rsms.me CDN. Falls back to system fonts if unavailable. -->
    <link rel="stylesheet" href="https://rsms.me/inter/inter.css">
    <style>
/* Modern Color Palette */
:root {
    --bg-color: #f8fafc;
    --text-primary: #1e293b;
    --text-secondary: #64748b;
    --border-color: #e2e8f0;
    --card-bg: #ffffff;
    --surface-muted: #f1f5f9;
    --primary-color: #3b82f6;
    color-scheme: light dark;

    /* Status Colors */
    --passed-bg: #dcfce7;
    --passed-text: #166534;
    --failed-bg: #fee2e2;
    --failed-text: #991b1b;
    --skipped-bg: #fef9c3;
    --skipped-text: #854d0e;
    --xfailed-bg: #ffedd5;
    --xfailed-text: #9a3412;
    --xpassed-bg: #f3e8ff;
    --xpassed-text: #6b21a8;
    --error-bg: #fee2e2;
    --error-text: #991b1b;
}

body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
    background-color: var(--bg-color);
    color: var(--text-primary);
    line-height: 1.5;
    margin: 0;
    padding: 0;
}

.container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 2rem;
}

/* Header */
header {
    margin-bottom: 2rem;
    border-bottom: 1px solid var(--border-color);
    padding-bottom: 1rem;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

h1 {
    font-size: 1.875rem;
    font-weight: 700;
    color: var(--text-primary);
    margin: 0;
}

.meta {
    font-size: 0.875rem;
    color: var(--text-secondary);
}

/* Summary Grid */
.summary {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
    gap: 1rem;
    margin-bottom: 2rem;
}

.summary-card {
    background: var(--card-bg);
    border-radius: 0.5rem;
    padding: 1.5rem;
    box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
    text-align: center;
    border: 1px solid var(--border-color);
    transition: transform 0.2s;
}

.summary-card:hover {
    transform: translateY(-2px);
}

.summary-card .count {
    font-size: 2.25rem;
    font-weight: 700;
    line-height: 1;
    margin-bottom: 0.5rem;
}

.summary-card .label {
    text-transform: uppercase;
    font-size: 0.75rem;
    font-weight: 600;
    letter-spacing: 0.05em;
    color: var(--text-secondary);
}

/* Status Colors for Summary */
.summary-card.passed .count {
    color: var(--passed-text);
}

.summary-card.failed .count {
    color: var(--failed-text);
}

.summary-card.skipped .count {
    color: var(--skipped-text);
}

.summary-card.xfailed .count {
    color: var(--xfailed-text);
}

.summary-card.xpassed .count {
    color: var(--xpassed-text);
}

.summary-card.coverage .count {
    color: var(--primary-color);
}

/* Filters */
.filters {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.5rem;
    border: 1px solid var(--border-color);
    margin-bottom: 1.5rem;
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.filter-input {
    flex: 1;
    padding: 0.5rem 1rem;
    border: 1px solid var(--border-color);
    border-radius: 0.375rem;
    font-size: 0.875rem;
    background: var(--card-bg);
    color: var(--text-primary);
}

.filter-input::placeholder {
    color: var(--text-secondary);
}

.filter-statuses {
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
}

.filter-chip {
    display: inline-flex;
    align-items: center;
    gap: 0.35rem;
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    border: 1px solid var(--border-color);
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.04em;
}

.filter-chip input {
    margin: 0;
}

.filter-chip.passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.filter-chip.failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.filter-chip.skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.filter-chip.xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.filter-chip.xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.filter-chip.error {
    background: var(--error-bg);
    color: var(--error-text);
}

/* Test List */
.test-list {
    display: flex;
    flex-direction: column;
    gap: 0.75rem;
}

.test-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
    overflow: hidden;
}

.test-header {
    padding: 1rem;
    display: flex;
    align-items: center;
    gap: 1rem;
    cursor: pointer;
    background: var(--card-bg);
}

.test-header:hover {
    background: var(--surface-muted);
}

.status-badge {
    padding: 0.25rem 0.75rem;
    border-radius: 9999px;
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
}

.status-passed {
    background: var(--passed-bg);
    color: var(--passed-text);
}

.status-failed {
    background: var(--failed-bg);
    color: var(--failed-text);
}

.status-skipped {
    background: var(--skipped-bg);
    color: var(--skipped-text);
}

.status-xfailed {
    background: var(--xfailed-bg);
    color: var(--xfailed-text);
}

.status-xpassed {
    background: var(--xpassed-bg);
    color: var(--xpassed-text);
}

.status-error {
    background: var(--error-bg);
    color: var(--error-text);
}

.test-name {
    flex: 1;
    font-family: monospace;
    font-size: 0.9rem;
    color: var(--text-primary);
    word-break: break-all;
}

.test-meta {
    display: flex;
    gap: 1rem;
    align-items: center;
    color: var(--text-secondary);
    font-size: 0.875rem;
}

/* Details Section */
.test-details {
    padding: 0 1rem 1rem 1rem;
    border-top: 1px solid var(--border-color);
    background: var(--surface-muted);
}

.detail-section {
    margin-top: 1rem;
}

.detail-title {
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    color: var(--text-secondary);
    margin-bottom: 0.5rem;
}

.coverage-item {
    font-family: monospace;
    font-size: 0.85rem;
    padding: 0.25rem 0;
    border-bottom: 1px solid var(--border-color);
    display: grid;
    grid-template-columns: minmax(200px, 2fr) minmax(120px, 1fr);
    gap: 1rem;
}

.coverage-list {
    background: var(--card-bg);
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
    overflow: hidden;
}

.source-coverage {
    margin-top: 2rem;
}

.source-coverage h2 {
    margin: 0 0 1rem;
    font-size: 1.5rem;
}

.source-coverage-table {
    display: grid;
    gap: 0.35rem;
}

.source-coverage-header,
.source-coverage-row {
    display: grid;
    grid-template-columns: minmax(200px, 2fr) repeat(4, minmax(60px, 0.5fr)) minmax(
            140px,
            1fr
        ) minmax(140px, 1fr);
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem 1rem;
    border-radius: 0.5rem;
}

.source-coverage-header {
    background: var(--surface-muted);
    font-size: 0.75rem;
    font-weight: 700;
    text-transform: uppercase;
    letter-spacing: 0.04em;
    color: var(--text-secondary);
}

.source-coverage-row {
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    font-size: 0.85rem;
}

.source-path {
    font-family: monospace;
    word-break: break-word;
}

.source-lines {
    font-family: monospace;
    color: var(--text-secondary);
    word-break: break-word;
}

.llm-annotation {
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--border-color);
}

.llm-annotation p {
    margin: 0 0 0.5rem 0;
}

.llm-annotation p:last-child {
    margin-bottom: 0;
}

.llm-annotation ul {
    margin: 0.5rem 0 0;
    padding-left: 1.25rem;
}

.llm-annotation li {
    margin-bottom: 0.25rem;
}

.error-message {
    font-family: monospace;
    color: var(--failed-text);
    background: var(--card-bg);
    padding: 1rem;
    border-radius: 0.375rem;
    border: 1px solid var(--failed-bg);
    white-space: pre-wrap;
    overflow-x: auto;
}

/* HTML5 Progress Bar for Coverage */
progress {
    width: 60px;
}

/* Utility: Hidden state for filtering */
.hidden {
    display: none !important;
}

/* Dark Mode Support */
@media (prefers-color-scheme: dark) {
    :root {
        --bg-color: #0f172a;
        --text-primary: #f1f5f9;
        --text-secondary: #94a3b8;
        --border-color: #334155;
        --card-bg: #1e293b;
        --surface-muted: #0b1220;
        --primary-color: #60a5fa;

        /* Status Colors - Adjusted for dark mode */
        --passed-bg: #14532d;
        --passed-text: #86efac;
        --failed-bg: #7f1d1d;
        --failed-text: #fca5a5;
        --skipped-bg: #713f12;
        --skipped-text: #fde047;
        --xfailed-bg: #7c2d12;
        --xfailed-text: #fdba74;
        --error-bg: #7f1d1d;
        --error-text: #fca5a5;
    }

    /* Adjust box shadows for dark mode */
    .summary-card {
        box-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.3), 0 1px 2px -1px rgb(0 0 0 / 0.3);
    }
}

@media print {
    body {
        background: #ffffff;
        color: #0f172a;
    }

    .container {
        max-width: none;
        padding: 1rem 1.5rem;
    }

    header {
        border-bottom: 2px solid var(--border-color);
    }

    .filters {
        display: none;
    }

    .summary-card,
    .test-row {
        box-shadow: none;
    }

    .test-header {
        background: #ffffff;
    }

    .test-row {
        page-break-inside: avoid;
        break-inside: avoid;
    }

    .test-details {
        background: #ffffff;
    }

    .llm-annotation {
        background: var(--surface-muted);
    }

    progress {
        width: 80px;
    }
}

body.pdf-mode .filters {
    display: none;
}

body.pdf-mode .test-row {
    page-break-inside: avoid;
    break-inside: avoid;
}

/* TOC Styling */
.toc {
    margin-bottom: 2rem;
    padding: 1rem;
    background: var(--card-bg);
    border: 1px solid var(--border-color);
    border-radius: 0.5rem;
}
.toc ul {
    list-style: none;
    padding: 0;
    margin: 0;
    display: flex;
    gap: 1.5rem;
    flex-wrap: wrap;
}
.toc a {
    color: var(--primary-color);
    text-decoration: none;
    font-weight: 600;
    cursor: pointer;
}
.toc a:hover {
    text-decoration: underline;
}

/* File Group Styling */
.test-file-group {
    margin-bottom: 2rem;
}
.test-file-header {
    font-size: 1.1rem;
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: 1rem;
    padding-bottom: 0.5rem;
    border-bottom: 2px solid var(--border-color);
    display: flex;
    justify-content: space-between;
    align-items: center;
}    </style>
    <script>
// pytest-llm-report interactive features

// Global state for filters
const activeStatuses = new Set(['passed', 'failed', 'skipped', 'xfailed', 'xpassed', 'error']);

// Filter tests based on search input and outcome filters
function filterTests() {
    const query = document.getElementById('searchInput').value.toLowerCase();
    document.querySelectorAll('.test-row').forEach(row => {
        const nodeid = row.querySelector('.test-name').textContent.toLowerCase();
        const statusMatch = row.dataset.status ? activeStatuses.has(row.dataset.status) : false;
        const matchesSearch = nodeid.includes(query);
        row.classList.toggle('hidden', !matchesSearch || !statusMatch);
    });
}

// Show only failures and scroll to list
function showFailuresOnly() {
    document.querySelectorAll('.filter-chip input').forEach(cb => {
        const s = cb.dataset.status;
        if (s === 'failed' || s === 'error') {
            cb.checked = true;
            activeStatuses.add(s);
        } else {
            cb.checked = false;
            activeStatuses.delete(s);
        }
    });
    filterTests();
    const testList = document.getElementById('test-list');
    if (testList) {
        testList.scrollIntoView({ behavior: 'smooth' });
    }
}

// Toggle visibility of status filters
function toggleStatus(checkbox) {
    const status = checkbox.dataset.status;
    if (checkbox.checked) {
        activeStatuses.add(status);
    } else {
        activeStatuses.delete(status);
    }
    filterTests();
}

// Initialize interactive features after DOM is ready
document.addEventListener('DOMContentLoaded', function () {
    'use strict';

    // Toggle dark mode on preference
    if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.documentElement.dataset.theme = 'dark';
    }

    // Default: expand all details
    document.querySelectorAll('details').forEach(details => {
        details.setAttribute('open', '');
    });

    const params = new URLSearchParams(window.location.search);
    if (params.get('pdf') === '1') {
        document.body.classList.add('pdf-mode');
    }
});    </script>
</head>
<body>
    <div class="container">
        <header>
            <div>
                <h1>Test Report</h1>
                <div class="meta">
                    Run ID: 21342027602-py3.12 &bull;
                    Generated: 2026-01-26 00:14:25 &bull;
                    Duration: 120.64s<br>
                    <strong>Plugin:</strong> v0.2.1
                        (a03dbe622cdc018f89b74731aed91adf1a582867)
[dirty]<br>
                    <strong>Repo:</strong> v0.2.1
                        (3145d53f452fcab2350c3fbbe2bf81eb0b563169)
[dirty]<br>
                    <strong>LLM:</strong> ollama / llama3.2:1b
                        (minimal context,
                         620 annotated, 2 errors)
                        <br><strong>Token Usage:</strong>
                        135747 input,
                        75289 output
                        (Total: 211036)
                </div>
            </div>
            <div style="text-align: right">
                <div style="font-size: 2rem; font-weight: 700; color: var(--primary-color)">
                    93.04%
                </div>
                <div class="meta">Total Coverage</div>
            </div>
        </header>

        <!-- Summary Cards -->
        <div class="summary">
            <div class="summary-card">
                <div class="count">623</div>
                <div class="label">Total Tests</div>
            </div>
            <div class="summary-card passed">
                <div class="count">623</div>
                <div class="label">Passed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Failed</div>
            </div>
            <div class="summary-card skipped">
                <div class="count">0</div>
                <div class="label">Skipped</div>
            </div>
            <div class="summary-card xfailed">
                <div class="count">0</div>
                <div class="label">XFailed</div>
            </div>
            <div class="summary-card xpassed">
                <div class="count">0</div>
                <div class="label">XPassed</div>
            </div>
            <div class="summary-card failed">
                <div class="count">0</div>
                <div class="label">Errors</div>
            </div>
        </div>

        <!-- Table of Contents -->
        <nav class="toc">
            <ul>
                <li><a href="#source-coverage">Source Coverage</a></li>
                <li><a href="#test-list">Per Test Details</a></li>
                <li><a onclick="showFailuresOnly()">Failures Only</a></li>
            </ul>
        </nav>

        <section class="source-coverage" id="source-coverage">
            <h2>Source Coverage</h2>
            <div class="source-coverage-table">
                <div class="source-coverage-header">
                    <span>File</span>
                    <span>Stmts</span>
                    <span>Miss</span>
                    <span>Cover</span>
                    <span>%</span>
                    <span>Covered Lines</span>
                    <span>Missed Lines</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/_git_info.py</span>
                    <span>2</span>
                    <span>0</span>
                    <span>2</span>
                    <span>100.0%</span>
                    <span class="source-lines">2-3</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/aggregation.py</span>
                    <span>121</span>
                    <span>6</span>
                    <span>115</span>
                    <span>95.04%</span>
                    <span class="source-lines">13, 15-19, 21, 36, 39, 45, 47, 53-54, 56-58, 60, 62-65, 70, 74-75, 78-81, 85, 88-90, 94, 104, 110, 113-115, 117-121, 123-124, 129, 131-132, 134-135, 138-139, 145-147, 149, 152, 155, 158, 160, 162, 176, 178, 182, 184, 186, 196, 198-202, 204-205, 208, 210, 219, 231, 233-247, 249, 251, 259-260, 262-263, 265, 267-269, 273, 276-277, 279-280, 283, 285-286, 288, 290-291, 295</span>
                    <span class="source-lines">67, 91-92, 111, 206, 217</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/cache.py</span>
                    <span>47</span>
                    <span>3</span>
                    <span>44</span>
                    <span>93.62%</span>
                    <span class="source-lines">13, 15-19, 21, 27, 33, 39-41, 43, 53, 55-56, 58, 60-62, 68-69, 78, 86, 88, 90, 92, 94, 97, 103, 107, 118-119, 121, 123, 129, 132-136, 141, 144, 153</span>
                    <span class="source-lines">64-65, 130</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/collector.py</span>
                    <span>111</span>
                    <span>1</span>
                    <span>110</span>
                    <span>99.1%</span>
                    <span class="source-lines">19, 21-22, 24, 26-27, 33-34, 45-50, 52, 58, 60-62, 69, 78-79, 81, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127-128, 130, 132-133, 135-137, 140-141, 143, 155, 163-164, 167-169, 171, 173, 181-182, 185-189, 191, 198-200, 202, 209-210, 212-214, 216, 218, 227-228, 230-236, 238, 241, 250-252, 254, 261, 264-265, 268-269, 271, 277, 279, 285</span>
                    <span class="source-lines">239</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/context_util.py</span>
                    <span>53</span>
                    <span>3</span>
                    <span>50</span>
                    <span>94.34%</span>
                    <span class="source-lines">13-15, 18, 27, 29-31, 33, 35-36, 38-41, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 72, 81-82, 86, 88-90, 93, 96, 108, 111, 124, 126-127, 129-130, 133, 135</span>
                    <span class="source-lines">53, 83-84</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/coverage_map.py</span>
                    <span>135</span>
                    <span>6</span>
                    <span>129</span>
                    <span>95.56%</span>
                    <span class="source-lines">13, 15-17, 19-22, 30, 38, 44-45, 47, 58-60, 64, 72-73, 83, 86, 88-90, 92, 94-96, 98, 101-104, 106-108, 114, 116, 118, 121-122, 127-128, 131-135, 137-140, 144-146, 148, 150, 152-153, 156, 160-162, 165, 167-168, 173, 176, 178-184, 187-189, 191, 196, 199-200, 202, 204, 216-217, 220, 224-225, 228-234, 236, 239, 241, 243-244, 246-250, 252-254, 257, 259-260, 263-264, 271, 273-274, 276-279, 281-283, 285, 299-300, 302, 308</span>
                    <span class="source-lines">62, 123, 125, 157, 221, 251</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/errors.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">8-9, 12, 25-28, 31-36, 39-42, 45-46, 49-51, 54-55, 64-66, 68, 70, 73, 77-79, 83, 132, 142</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/__init__.py</span>
                    <span>3</span>
                    <span>0</span>
                    <span>3</span>
                    <span>100.0%</span>
                    <span class="source-lines">4-5, 7</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/annotator.py</span>
                    <span>154</span>
                    <span>21</span>
                    <span>133</span>
                    <span>86.36%</span>
                    <span class="source-lines">4, 6-10, 12-15, 21-22, 25-30, 33, 47-48, 50-52, 56, 58-59, 65, 67-68, 70, 73-74, 76, 84, 86-90, 95-96, 98-99, 106-107, 112-113, 116, 121-126, 130, 132, 134, 137, 144, 156, 181-182, 184, 186, 188-189, 199, 211, 213-216, 221-223, 226, 249-252, 254-255, 260, 262, 264-267, 269-270, 277-279, 281, 283-284, 289-290, 292-293, 298-301, 303, 306, 329-332, 334, 336, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381</span>
                    <span class="source-lines">77-81, 160-168, 173, 286-287, 345, 364-365, 371</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/base.py</span>
                    <span>131</span>
                    <span>6</span>
                    <span>125</span>
                    <span>95.42%</span>
                    <span class="source-lines">13, 15-18, 20, 30, 33, 47, 50, 53, 59, 65-66, 68, 87-88, 96, 101, 103, 105, 128, 134-135, 137-138, 149, 155, 157, 163, 165, 174, 176, 185-186, 188, 191-198, 200, 202, 212, 214-217, 219-222, 224, 232, 243, 245, 247, 264, 266-267, 270-272, 274-275, 277, 279, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314, 316, 325-326, 329-331, 333-334, 337-339, 342-347, 351, 353, 359-360, 363-364, 367-369, 372, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404, 406</span>
                    <span class="source-lines">91-92, 230, 284, 292, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/batching.py</span>
                    <span>90</span>
                    <span>4</span>
                    <span>86</span>
                    <span>95.56%</span>
                    <span class="source-lines">8, 10-13, 20, 23-24, 27-29, 31-32, 34, 36-37, 39, 44, 53-55, 58, 67-68, 70, 73, 92-93, 95, 97, 103-106, 108-110, 112, 122-123, 126-128, 136, 139, 156-157, 160, 162, 164-167, 170-176, 181-185, 187-188, 190, 192-194, 196-197, 203-206, 209-210, 213-214, 216-218, 222, 224</span>
                    <span class="source-lines">158, 207, 211, 220</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/gemini.py</span>
                    <span>325</span>
                    <span>7</span>
                    <span>318</span>
                    <span>97.85%</span>
                    <span class="source-lines">7, 9-13, 15-16, 23-27, 30-34, 37-42, 44-46, 48-50, 52, 57-63, 65-70, 72-73, 75-78, 80-85, 87-89, 91-97, 99-114, 121-122, 125, 128, 134-135, 137-141, 143-144, 146, 164-166, 173-175, 178, 181-182, 184, 186-189, 191-192, 198-206, 208-210, 212-213, 215, 218, 221-230, 232-233, 235-237, 239-243, 246-247, 249-252, 254-255, 259, 261, 263, 268, 272-276, 279-281, 283, 288-293, 295, 299-305, 308-309, 311-312, 318-319, 322, 326, 332-333, 335, 339-343, 345-349, 352-353, 358-359, 366-367, 369, 383, 385-386, 390, 410, 413-415, 418-422, 424-427, 432, 434-435, 437, 441-444, 446, 449-463, 469, 471-473, 475-478, 480, 486, 488-491, 493, 495, 497-498, 502-508, 511, 514-516, 518-521, 523-528, 534, 537, 539-543, 547-548, 550-559, 562-564, 567-570, 574</span>
                    <span class="source-lines">115-117, 298, 310, 313-314</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/litellm_provider.py</span>
                    <span>77</span>
                    <span>1</span>
                    <span>76</span>
                    <span>98.7%</span>
                    <span class="source-lines">8, 10, 12-13, 21, 31, 37-38, 41-42, 44, 51, 60-62, 64, 82-83, 89, 92, 95-96, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 122, 124-126, 129-130, 132, 135, 137, 139, 141-142, 144, 148, 170, 182-183, 186-188, 190, 192-193, 196-198, 204, 206, 211, 213, 215, 221-222, 224, 227-231, 234, 236, 242-243, 245</span>
                    <span class="source-lines">207</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/noop.py</span>
                    <span>13</span>
                    <span>0</span>
                    <span>13</span>
                    <span>100.0%</span>
                    <span class="source-lines">8, 10, 12-13, 20, 26, 32, 34, 51, 53, 59, 61, 67</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/ollama.py</span>
                    <span>72</span>
                    <span>1</span>
                    <span>71</span>
                    <span>98.61%</span>
                    <span class="source-lines">7, 9, 11-12, 18, 24, 42-43, 49, 52-53, 55, 58, 60-61, 63-67, 70, 74-77, 83, 85-86, 92, 94, 96-98, 100-101, 103, 107, 113-114, 116-118, 122, 128, 130, 138, 140, 142-144, 149-150, 156, 158, 160-162, 165-167, 172-173, 178, 180, 190, 192-193, 204, 209, 211-212</span>
                    <span class="source-lines">90</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/schemas.py</span>
                    <span>36</span>
                    <span>1</span>
                    <span>35</span>
                    <span>97.22%</span>
                    <span class="source-lines">8, 10-12, 16, 22, 38, 42-44, 46-47, 50-53, 55, 58-59, 62-65, 67-68, 77, 84, 90, 94-98, 102, 130</span>
                    <span class="source-lines">39</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/token_refresh.py</span>
                    <span>71</span>
                    <span>0</span>
                    <span>71</span>
                    <span>100.0%</span>
                    <span class="source-lines">7, 9-14, 17, 20, 23-24, 36-39, 41-43, 47, 59-60, 63-66, 69-72, 74, 83, 85-88, 90-91, 93, 101-103, 107-109, 111, 113-116, 120, 132-136, 139-140, 143-145, 148-150, 153-156, 158, 160-162</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/llm/utils.py</span>
                    <span>33</span>
                    <span>2</span>
                    <span>31</span>
                    <span>93.94%</span>
                    <span class="source-lines">4, 6, 9, 20, 23, 42-43, 46-47, 51-53, 55-56, 66, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90, 93-94, 96, 98</span>
                    <span class="source-lines">48, 78</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/models.py</span>
                    <span>253</span>
                    <span>0</span>
                    <span>253</span>
                    <span>100.0%</span>
                    <span class="source-lines">17-18, 20, 23, 26-27, 36-38, 40, 42, 49-50, 59-61, 63, 65, 72-73, 86-92, 94, 96, 107-108, 120-126, 128, 130, 135-143, 146-147, 169-185, 187-188, 190, 192, 194, 201-224, 227-228, 236-237, 239, 241, 247-248, 257-259, 261, 263, 270-271, 280-282, 284, 286, 290-292, 295-296, 333-362, 364-372, 374, 376, 394-417, 419-437, 440-441, 455-463, 465, 467, 477-479, 482-483, 500-510, 512, 518, 520, 526-540</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/options.py</span>
                    <span>268</span>
                    <span>57</span>
                    <span>211</span>
                    <span>78.73%</span>
                    <span class="source-lines">122, 170, 199, 202-204, 209-211, 217-219, 225-227, 233-235, 241-242, 245-254, 257-259, 265-267, 271-274, 276, 284, 293, 308, 311-312, 320-325, 327, 332-337, 340-345, 348-349, 352-353, 356-357, 360-369, 372-375, 378-393, 396-397, 400-405, 408-409, 412-413, 416-421, 426-427, 430-431, 436-439, 444-447, 449, 451, 453, 460-461, 463-464, 466-467, 470-475, 479, 482-495, 498, 502-503, 507, 510, 514-515, 519-520, 524, 527, 531, 534-536, 540-541, 545-546, 550, 553, 557, 560, 564-565, 569, 572-574, 578, 581-584, 587, 591-592, 596, 599-608, 611, 613</span>
                    <span class="source-lines">13-15, 21-22, 98-102, 105-107, 110-115, 118-121, 138-139, 142-149, 152-155, 158-160, 163-166, 169, 180-184, 187-188, 191, 193, 278, 287, 296</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/plugin.py</span>
                    <span>182</span>
                    <span>24</span>
                    <span>158</span>
                    <span>86.81%</span>
                    <span class="source-lines">41, 44, 50, 56, 62, 68, 74, 81, 90, 96, 102, 108, 114, 122, 128, 134, 142, 148, 155, 161, 169, 176, 185, 192, 199, 208, 215, 223, 229, 235, 241, 247, 254, 260, 268, 274, 283, 289, 297, 304, 311, 328, 332, 336, 342-343, 346-347, 349, 351, 354-356, 362-363, 371-372, 399-400, 403-404, 407, 410-411, 413-414, 417-418, 420, 422-426, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 476-477, 485-487, 491-494, 497, 499, 502-507, 509, 512-514, 516-521, 523, 534-535, 558-559, 562-563, 566-568, 579-580, 583, 586-587, 590-592, 602-603, 606-608, 619-620, 623, 626, 628-629</span>
                    <span class="source-lines">13, 15-18, 20-21, 23, 29-32, 35, 319, 377, 481-482, 488, 548-549, 571, 595, 611-612</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/prompts.py</span>
                    <span>110</span>
                    <span>3</span>
                    <span>107</span>
                    <span>97.27%</span>
                    <span class="source-lines">13, 15-17, 24, 27, 33, 35, 49, 52, 55, 58-61, 63, 65, 67, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 114, 116, 118, 139-140, 142-144, 147, 152-153, 155-157, 159-161, 163-164, 166-167, 170-171, 173, 177, 180, 189, 192-194, 196-197, 201, 203, 216-217, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249, 251, 268, 275, 284-287</span>
                    <span class="source-lines">80, 185, 233</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/render.py</span>
                    <span>65</span>
                    <span>6</span>
                    <span>59</span>
                    <span>90.77%</span>
                    <span class="source-lines">13, 15-16, 18, 24, 30-31, 34, 40, 42, 50-51, 53, 56, 65-67, 70, 79, 87, 90, 99, 101-102, 107, 110, 121-124, 126-129, 131-134, 140-142, 147, 155-157, 159, 172-177, 191, 210-211, 224, 267, 269, 285</span>
                    <span class="source-lines">148-149, 212, 217-218, 222</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/report_writer.py</span>
                    <span>167</span>
                    <span>3</span>
                    <span>164</span>
                    <span>98.2%</span>
                    <span class="source-lines">13, 15-25, 27-29, 46, 55, 58, 67-68, 76, 83-84, 89, 98-100, 102, 105-108, 110, 113, 116, 127-128, 130, 142, 150, 156-158, 160, 186-189, 192, 197-199, 202-203, 211, 222-223, 226-227, 230-231, 233, 235, 254, 256-259, 262-264, 266, 268, 310, 319, 321-322, 324-335, 337, 339, 347, 350-352, 355-356, 359-361, 364, 367, 375, 383, 385-386, 389, 392, 395, 398, 406, 408-409, 415, 417, 419, 421-432, 439, 441-442, 444-446, 454-458, 460, 462, 465, 468-469, 471, 477-481, 487-488, 495, 502, 504, 506-508, 510, 513-514, 516, 522-523</span>
                    <span class="source-lines">135-137</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/fs.py</span>
                    <span>34</span>
                    <span>1</span>
                    <span>33</span>
                    <span>97.06%</span>
                    <span class="source-lines">11, 13-14, 17, 30, 33, 36, 39, 42, 45, 55-56, 58-60, 63-65, 67, 70, 79, 82, 100, 103, 111-113, 116-117, 119-121, 123</span>
                    <span class="source-lines">40</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/hashing.py</span>
                    <span>36</span>
                    <span>0</span>
                    <span>36</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 14-17, 23, 32, 35, 44-48, 51, 61, 64, 73-74, 76-78, 80-81, 86, 96, 103-104, 107, 113-114, 116-121</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/ranges.py</span>
                    <span>33</span>
                    <span>0</span>
                    <span>33</span>
                    <span>100.0%</span>
                    <span class="source-lines">12, 15, 29-30, 33, 35-37, 39-40, 42, 45-47, 50, 52, 55, 65-67, 70, 81-82, 84-91, 93, 95</span>
                    <span class="source-lines">-</span>
                </div>
                <div class="source-coverage-row">
                    <span class="source-path">src/pytest_llm_report/util/time.py</span>
                    <span>16</span>
                    <span>0</span>
                    <span>16</span>
                    <span>100.0%</span>
                    <span class="source-lines">4, 6, 9, 15, 18, 27, 30, 39-44, 46-48</span>
                    <span class="source-lines">-</span>
                </div>
            </div>
        </section>

        <section class="per-test-details" id="test-list">
            <h2>Per Test Details</h2>

        <!-- Filters -->
        <div class="filters">
            <input type="text" id="searchInput" class="filter-input" placeholder="Search tests..." onkeyup="filterTests()">
            <div class="filter-statuses" aria-label="Filter by status">
                <label class="filter-chip passed">
                    <input type="checkbox" data-status="passed" checked onchange="toggleStatus(this)">
                    Passed
                </label>
                <label class="filter-chip failed">
                    <input type="checkbox" data-status="failed" checked onchange="toggleStatus(this)">
                    Failed
                </label>
                <label class="filter-chip skipped">
                    <input type="checkbox" data-status="skipped" checked onchange="toggleStatus(this)">
                    Skipped
                </label>
                <label class="filter-chip xfailed">
                    <input type="checkbox" data-status="xfailed" checked onchange="toggleStatus(this)">
                    XFailed
                </label>
                <label class="filter-chip xpassed">
                    <input type="checkbox" data-status="xpassed" checked onchange="toggleStatus(this)">
                    XPassed
                </label>
                <label class="filter-chip error">
                    <input type="checkbox" data-status="error" checked onchange="toggleStatus(this)">
                    Error
                </label>
            </div>
        </div>

        <!-- Test List -->
        <div class="test-list">
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_adaptive_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_complex_test_high_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_complex_test_high_complexity</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks for complexity estimation in tests that have multiple assertions and mocks.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assertion count', 'value': 5}</li>
                                            <li>{'name': 'mocks used', 'value': 3}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        103 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_empty_source_zero_complexity</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the behavior of the `Config` class when given an empty source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "assert provider._estimate_test_complexity('') == 0", 'expected_value': 0, 'message': "Expected provider._estimate_test_complexity('') to return 0"}</li>
                                            <li>{'description': 'assert provider._estimate_test_complexity(None) == 0', 'expected_value': 0, 'message': 'Expected provider._estimate_test_complexity(None) to return 0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        163 output =
                                        299 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 185-186, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestComplexityEstimation::test_simple_test_low_complexity</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks if Simple tests have low complexity scores.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'complexity_score', 'value': 'low'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        79 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 65-66, 185, 188, 191-198, 200, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid prompt tier</p>
                                    <p><strong>Why Needed:</strong> To test that the 'invalid' prompt tier is considered an error during validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The 'prompt_tier' field should be present in any error message.", 'expected_value': 'prompt_tier'}</li>
                                            <li>{'description': "Any error messages should contain the string 'prompt_tier'.", 'expected_value': 'prompt_tier'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        110 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestConfigValidation::test_valid_prompt_tiers</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Valid prompt tiers are validated</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` parameter is correctly validated and does not cause any issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected errors for invalid prompt tiers', 'description': 'The validation should return an empty list of errors for valid prompt tiers'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        84 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_complex_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_complex_test</p>
                                    <p><strong>Why Needed:</strong> Auto mode should use standard prompt for complex tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'standard_prompt_for_complex_tests', 'expected_value': 'standard prompt for complex tests'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        80 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-220, 222, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_auto_tier_simple_test</p>
                                    <p><strong>Why Needed:</strong> To ensure that the auto mode selects a minimal prompt for simple tests, which is essential for efficient and effective test execution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'selected_prompt_type', 'value': 'MINIMAL_SYSTEM_PROMPT'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        155 input +
                                        91 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_adaptive_prompts.py::TestPromptTierSelection::test_minimal_tier_override</p>
                                    <p><strong>Why Needed:</strong> Config override to minimal should always use minimal prompt.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'value': 'none'}</li>
                                            <li>{'name': 'prompt_tier', 'value': 'minimal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        91 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 212, 214-215, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_adaptive_prompts.py::TestPromptTierSelection::test_standard_tier_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Config override to standard should always use standard prompt.</p>
                                    <p><strong>Why Needed:</strong> Because the config override is not necessary in this case, and using the standard prompt is a better practice.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is', 'expected_value': 'standard_system_prompt'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        77 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 212, 214, 216-217, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_all_policy</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the aggregate function correctly handles all policy when aggregating multiple test cases</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where an aggregation of multiple tests results in only one test being retained due to a missing or incomplete policy.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The aggregated report should contain both test case information for each run.</li>
                                            <li>The number of tests in the aggregated report should be equal to the total number of runs.</li>
                                            <li>Each test case should have a corresponding run in the aggregated report.</li>
                                            <li>All retained test cases should be included in the aggregated report.</li>
                                            <li>Any missing or incomplete policy should not result in only one test being retained.</li>
                                            <li>The aggregate function should correctly handle all policy when aggregating multiple tests.</li>
                                            <li>The temporary directory created for the aggregation process should be deleted after the test is completed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        180 output =
                                        544 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">71 lines (ranges: 53, 56-57, 60, 62-64, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py::TestAggregator::test_aggregate_dir_not_exists</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the `aggregate` method of the Aggregator class does not check if the aggregation directory exists before aggregating data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected behavior', 'description': 'The `aggregate` method should return None when the aggregation directory does not exist.', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        109 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 53, 56-58, 110, 113-115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_latest_policy</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `aggregate` method consistently picks the latest policy for a given test case across different times.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the latest policy is not picked correctly due to inconsistent timing of reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The result of `aggregator.aggregate()` should contain only one test with an outcome of 'passed'.</li>
                                            <li>The number of tests in the result should be equal to 1.</li>
                                            <li>The outcome of the first test in the result should be 'passed'.</li>
                                            <li>The `run_meta` object should have a `is_aggregated` attribute set to True.</li>
                                            <li>The `run_meta.run_count` attribute should be equal to 2.</li>
                                            <li>The `summary.passed` attribute should be equal to 1 (i.e., the first test passed).</li>
                                            <li>The `summary.failed` attribute should be equal to 0 (i.e., no tests failed).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        205 output =
                                        682 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">79 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138, 145, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 204-205, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_dir_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_aggregation.py::TestAggregator::test_aggregate_no_dir_configured</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the aggregator requires a directory to aggregate data from.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'agg', 'type': 'NoneType', 'expected_type': 'NoneType'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        84 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 45, 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_no_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `aggregate` method of the Aggregator class should not be called when there are no reports to aggregate.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `aggregate` method is called on an empty list of reports, causing it to return `None` instead of raising an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate` method should be called with an empty list of reports.</li>
                                            <li>The `aggregate` method should raise an error when given an empty list of reports.</li>
                                            <li>The `aggregate` method should not call the `is_file()` and `is_dir()` methods on empty lists of reports.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        142 output =
                                        343 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 53, 56-58, 110, 113-114, 117-118, 184)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_coverage_and_llm_annotations</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that coverage and LLM annotations are properly deserialized and can be re-serialized.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in core functionality by ensuring accurate token usage and coverage information is preserved during serialization.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Coverage was correctly deserialized from the JSON report.</li>
                                            <li>LLM annotation was correctly deserialized with the expected scenario, why needed, and key assertions.</li>
                                            <li>Token usage was correctly serialized back into a JSON object.</li>
                                            <li>The test can be re-serialized to ensure it remains accurate.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        1002 input +
                                        121 output =
                                        1123 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">87 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 134-135, 138-141, 145-147, 149-150, 152-153, 155, 158, 160, 162-167, 169, 171-173, 184, 196, 198-202, 208, 231, 233-237, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-45, 65-68, 130-133, 135-137, 139, 141-143, 190, 194-199, 201, 203, 205, 207, 210-214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_aggregate_with_source_coverage</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test source coverage summary deserialization when aggregate is configured.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the source coverage summary is not correctly deserialized if the aggregate configuration does not match the report format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `source_coverage` key exists in the `report1` dictionary and has the expected structure.</li>
                                            <li>The `file_path` value of the first `SourceCoverageEntry` is 'src/foo.py'.</li>
                                            <li>The `coverage_percent` value is 83.33%.</li>
                                            <li>The `covered_ranges` value is '1-5, 7-11'.</li>
                                            <li>The `missed_ranges` value is '6, 12'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        158 output =
                                        553 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">67 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123, 129, 131-132, 162-169, 171-173, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_load_coverage_from_source</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading coverage from configured source file when option is not set.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the test fails due to an incorrect assumption about the configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that aggregator._load_coverage_from_source() returns None when llm_coverage_source is not set.</li>
                                            <li>Verify that aggregator._load_coverage_from_source() raises a UserWarning when llm_coverage_source does not exist.</li>
                                            <li>Verify that aggregator._load_coverage_from_source() correctly loads coverage from the configured source file (mocking coverage.py).</li>
                                            <li>Verify that mock_cov.report() returns 80.0 as expected after calling cov.report().</li>
                                            <li>Verify that mock_mapper.map_source_coverage() correctly maps the coverage data to entries.</li>
                                            <li>Verify that aggregator._load_coverage_from_source() correctly returns a tuple containing one entry when successful loading is achieved.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        584 input +
                                        189 output =
                                        773 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 259-260, 262-263, 265, 267-271, 273, 276-277, 279-280, 283, 285-286, 288)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_recalculate_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_recalculate_summary verifies that the aggregator recalculates the latest summary correctly and preserves coverage percentage.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the aggregation logic, ensuring that the latest summary is calculated accurately and coverage percentage remains preserved.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of tests passed should be equal to the original count.</li>
                                            <li>The number of failed tests should remain unchanged.</li>
                                            <li>The number of skipped tests should remain unchanged.</li>
                                            <li>The number of tests with unknown status (xfailed, xpassed) should remain unchanged.</li>
                                            <li>The error rate should be within a reasonable range (e.g., 0-100%).</li>
                                            <li>The coverage percentage should not decrease below the original value.</li>
                                            <li>The total duration of all tests should increase by at least 5 seconds to reflect the recalculated summary.</li>
                                            <li>The latest summary should have the same node IDs as the original test results.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        198 output =
                                        671 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 231, 233-247, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation.py::TestAggregator::test_skips_invalid_json</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that skipping an invalid JSON report prevents the aggregation from counting it as a valid report.</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `aggregate` function correctly handles reports with missing or malformed data, preventing it from incorrectly counting them as valid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `aggregate` function should not count an invalid JSON report as a valid one.</li>
                                            <li>The `aggregate` function should only count the valid report (in this case, 'run1') in its run meta.</li>
                                            <li>The test should raise a warning when trying to aggregate a report with missing fields ('missing_fields.json').</li>
                                            <li>The test should assert that the aggregation result is not None and has exactly one run meta entry.</li>
                                            <li>The test should only count the valid report (in this case, 'run1') in its run meta.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        352 input +
                                        182 output =
                                        534 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 53, 56-57, 60, 65, 70, 74-75, 78-81, 85, 88-90, 94-101, 110, 113-114, 117-121, 123-124, 129, 131-132, 162-167, 169, 171-173, 176, 178-180, 182, 184, 196, 198-200, 208, 231, 233-234, 249, 259, 262-263, 265, 267, 290-293, 295)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_aggregation_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_aggregation_maximal.py::TestAggregationMaximal::test_recalculate_summary_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the aggregator recalculates the summary correctly when new tests are added and the latest summary is updated.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage calculation when new tests are added to the aggregation process, ensuring accuracy of the overall coverage percentage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>summary.total == 2</li>
                                            <li>summary.passed == 1</li>
                                            <li>summary.failed == 1</li>
                                            <li>summary.coverage_total_percent == 88.5</li>
                                            <li>summary.total_duration == 3.0</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        125 output =
                                        424 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/aggregation.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 45, 231, 233-239, 249)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_annotator.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_batch_optimization_message</p>
                                    <p><strong>Why Needed:</strong> To test the batch optimization message functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_assembler.send_message', 'expected_output': 'optimized message'}</li>
                                            <li>{'name': 'mock_provider.get_messages', 'expected_output': ['optimized message']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        97 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-91, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the progress reporting is cached correctly and not overwritten by subsequent requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked cache should be updated with correct data', 'expected_value': {'progress': 50, 'total': 100}, 'actual_value': {'progress': 0, 'total': 0}}</li>
                                            <li>{'name': 'Mocked cache should not overwrite previous progress reports', 'expected_value': {'progress': 50, 'total': 100}, 'actual_value': {'progress': 25, 'total': 75}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        163 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-128, 130, 134, 156, 181-182, 184, 211, 213-219, 221, 223)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_cached_tests_are_skipped</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks if cached tests are skipped. This is a critical functionality for ensuring the reliability and efficiency of the annotator.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'mocking', 'expected_mock_calls': [], 'actual_mock_calls': [], 'reason': "The test is testing if the mock objects are being called correctly, which is essential for verifying the correctness of the annotator's behavior."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        134 output =
                                        236 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">95 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-124, 130, 132, 134, 137-141, 144-151, 156, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation</p>
                                    <p><strong>Why Needed:</strong> To ensure that annotators can annotate data in a concurrent manner without causing any issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'concurrency', 'expected_result': 'No exceptions should be raised when multiple annotators are concurrently annotating the same dataset.'}</li>
                                            <li>{'assertion_type': 'threading', 'expected_result': 'All annotators should finish annotating their assigned tasks within a reasonable time frame (e.g., 10 seconds).'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        139 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221, 223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_concurrent_annotation_handles_failures</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the current implementation of `annotate` may not handle failures correctly when multiple annotators are working concurrently.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider returns a valid annotation', 'expected_value': 'Annotation returned by mock provider'}</li>
                                            <li>{'name': 'Mock cache does not store annotations', 'expected_value': 'Annotations are not stored in the mock cache'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        128 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188-196, 213-219, 221-223, 329-332, 334, 336-340, 342, 344, 350-351, 353-354, 356-359, 361-362, 367-368, 370, 376-379, 381)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_progress_reporting</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator reports progress accurately and consistently throughout the annotation process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider should be called with a valid task', 'expected_value': 'mock_provider.task', 'actual_value': 'mock_provider.get_task()'}</li>
                                            <li>{'name': 'mock_cache should not be modified during the annotation process', 'expected_value': 'None', 'actual_value': 'mock_cache'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        134 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_reports_progress_messages</p>
                                    <p><strong>Why Needed:</strong> To ensure that the progress messages are returned correctly when annotating reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_type': 'MockProvider', 'actual_type': 'MockProvider'}</li>
                                            <li>{'name': 'mock_cache', 'expected_type': 'MockCache', 'actual_type': 'MockCache'}</li>
                                            <li>{'name': 'mock_assembler', 'expected_type': 'MockAssembler', 'actual_type': 'MockAssembler'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        146 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_opt_out_and_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the annotator respects the opt-out and limit settings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_result': {'opt_out': [1, 2], 'limit': 5}, 'actual_result': {'opt_out': [1, 3], 'limit': 10}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        102 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 47, 50-51, 58-59, 65, 67-68, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_respects_rate_limit</p>
                                    <p><strong>Why Needed:</strong> The test respects the rate limit for annotating a single document.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_provider', 'expected_value': 1, 'actual_value': 2}</li>
                                            <li>{'name': 'mock_cache', 'expected_value': 1000, 'actual_value': 2000}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        113 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-257, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation</span>
                            <div class="test-meta">
                                <span>12.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Sequential annotation</p>
                                    <p><strong>Why Needed:</strong> To ensure that the annotator can correctly annotate sequential data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'annotator behaves as expected', 'description': 'The annotator should be able to correctly identify and annotate sequential elements in the input data.'}</li>
                                            <li>{'name': 'sequential annotations are preserved', 'description': 'The sequential annotations should be preserved across multiple passes of the annotator, even if the input data is reordered or split into smaller chunks.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        122 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">94 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation_error_tracking</span>
                            <div class="test-meta">
                                <span>24.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_sequential_annotation_error_tracking</p>
                                    <p><strong>Why Needed:</strong> Error tracking in sequential annotation is necessary to ensure that errors are properly reported and handled by the annotator.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mock provider should be called with error message', 'expected_output': 'Mock provider was called with an error message', 'actual_output': 'Mock provider was not called with an error message'}</li>
                                            <li>{'name': 'Mock cache should be cleared after error is reported', 'expected_output': 'Mock cache should be cleared after error is reported', 'actual_output': 'Mock cache remains unchanged'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        159 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-87, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264-267, 269-274, 277-279, 281, 283-284, 289-290, 292, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_disabled</p>
                                    <p><strong>Why Needed:</strong> The test should be skipped when the LLM (Large Language Model) is not enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config', 'value': "Config(provider='none')"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        81 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 47-48)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_annotator.py::TestAnnotateTests::test_skips_if_provider_unavailable</p>
                                    <p><strong>Why Needed:</strong> The test is skipped if the provider is unavailable because it prevents the test from running and potentially causing data loss.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Provider is not available', 'expected': 'Provider is not available'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        90 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 47, 50-54, 56)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_coverage_v2.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_malformed_json_after_extract</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Base Parse Response Malformed JSON After Extract</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `_parse_response` method correctly handles malformed JSON responses and raises a `JSONDecodeError` with a meaningful error message.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Expected error message', 'expected_value': 'Failed to parse LLM response as JSON'}</li>
                                            <li>{'assertion_type': 'Expected error code', 'expected_value': 2}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        114 output =
                                        266 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 325-326, 329-330, 333-334, 359-360)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_coverage_v2.py::test_base_parse_response_non_string_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `test_base_parse_response_non_string_fields` test case checks for non-string fields in the response data.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function does not handle cases with non-string fields in its response data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.scenario == '123'</li>
                                            <li>assert annotation.why_needed == ['list']</li>
                                            <li>assert annotation.key_assertions == ['a']</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        103 output =
                                        372 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342-346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_base_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_gemini_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_gemini_provider` function is correctly creating a `GeminiProvider` instance.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider type', 'expected_type': 'GeminiProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        83 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_invalid_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that a ValueError is raised when an unknown LLM provider is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'raises', 'message': 'Unknown LLM provider: invalid'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        80 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_litellm_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure the `get_litellm_provider` function returns a valid instance of `LiteLLMProvider`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider type', 'expected': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        86 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_noop_provider</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the `get_provider` function returns a NoopProvider instance when no provider is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider type', 'expected_value': 'NoopProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        87 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestGetProvider::test_get_ollama_provider</p>
                                    <p><strong>Why Needed:</strong> To verify the correctness of the OllamaProvider class.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider_type', 'expected': 'OllamaProvider', 'actual': 'isinstance(provider, OllamaProvider)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        89 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_available_caches_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the LlmProvider can be checked for availability without raising an exception.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the LlmProvider raises an exception when checking its availability, causing the test to fail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The provider is not raised an exception when checking its availability.</li>
                                            <li>The provider's checks counter is incremented correctly.</li>
                                            <li>The provider returns True for availability checks.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        99 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 134-135, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_model_name_defaults_to_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py::TestLlmProviderDefaults</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM model name is set to the default configuration when no explicit model name is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "provider.get_model_name() == 'test-model'", 'expected_value': 'test-model'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        86 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_get_rate_limits_defaults_to_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `get_rate_limits` method returns `None` when no default rate limits are specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert get_rate_limits is None', 'description': 'The `get_rate_limits` method should return `None`.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        87 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_base_maximal.py::TestLlmProviderDefaults::test_is_local_defaults_to_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_base_maximal.py</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLM provider defaults to false when in local mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_local() should return False', 'expected_value': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        105 input +
                                        68 output =
                                        173 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 174)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_batching.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_context_files_included</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that context files are included in the batch prompt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where context files are not added to the prompt, potentially leading to incorrect usage of the `build_batch_prompt` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'src/module.py' file is present in the prompt.</li>
                                            <li>The 'def helper()' function is present in the prompt.</li>
                                            <li>Context files should be added to the prompt according to their locations.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        261 input +
                                        108 output =
                                        369 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 192-194, 196-200, 203-206, 209-210, 213-214, 216-218, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_parametrized_batch_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the parametrized batch prompt includes all required information.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the prompt is missing or incorrect, making it difficult to understand and use the `build_batch_prompt` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Test Group: test.py::test_add[*]</li>
                                            <li>Parameterizations (2 variants)</li>
                                            <li>[1+1=2]</li>
                                            <li>[0+0=0]</li>
                                            <li>ONE annotation</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        330 input +
                                        107 output =
                                        437 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 34, 39-40, 156-157, 160, 162, 164-168, 170-177, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestBuildBatchPrompt::test_single_test_prompt</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Single test should generate normal prompt.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the batched prompt is missing 'Test: test.py::test_foo' and incorrectly includes 'Parameterizations'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert "Test: test.py::test_foo" in prompt</li>
                                            <li>assert "```python" in prompt</li>
                                            <li>assert source in prompt</li>
                                            <li>assert 'Parameterizations' not in prompt</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        269 input +
                                        108 output =
                                        377 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 34, 39, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the same source code produces the same hash value.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where different versions of the test function produce different hashes, leading to inconsistent results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `source` variable is set to a string containing the test function definition.</li>
                                            <li>Two calls to `_compute_source_hash(source)` return the same hash value.</li>
                                            <li>The length of the returned hash value is 32 bytes as expected.</li>
                                            <li>_compute_source_hash(source) should not modify or alter the input source code.</li>
                                            <li>The `source` variable should be a string containing the test function definition.</li>
                                            <li>The hash value calculated by `_compute_source_hash(source)` should match the original hash value.</li>
                                            <li>If the same source code is used multiple times, the returned hash values should remain consistent.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        181 output =
                                        401 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_different_source_different_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that different source code produces different hashes, which is a requirement for batch processing to work correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'different', 'condition': 'hash1 != hash2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        85 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67, 70)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestComputeSourceHash::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestComputeSourceHash::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> The current implementation of ComputeSourceHash does not handle an empty source correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _compute_source_hash() returns an empty string for an empty input', 'expected_result': '', 'actual_result': '_compute_source_hash()'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        93 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 67-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_batch_max_tests_minimum</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `batch_max_tests` configuration option must be at least 1.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The error message should contain 'batch_max_tests' in order to trigger this assertion.", 'expected_value': 'batch_max_tests', 'actual_value': '0'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        103 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestConfigValidation::test_context_line_padding_non_negative</p>
                                    <p><strong>Why Needed:</strong> Context line padding must be non-negative.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding must be >= 0', 'description': 'The context line padding value is negative.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        79 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid context compression</p>
                                    <p><strong>Why Needed:</strong> To test that an invalid context compression mode raises an error during validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'value': 'context_compression', 'expected_value': 'invalid'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        72 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestConfigValidation::test_valid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> Valid compression modes should pass.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Context compression is enabled.', 'expected': 'None'}</li>
                                            <li>{'message': 'Context compression is disabled.', 'expected': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        75 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_nested_params</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_nested_params</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the current implementation of _get_base_nodeid does not fully strip nested parameters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert stripped params are correct', 'expected': 'test.py::test[a-b-c]', 'actual': '_get_base_nodeid('}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        99 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_parametrized_nodeid</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the behavior of `_get_base_nodeid` when a parameterized node id is passed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "_get_base_nodeid('tests/test_foo.py::test_add[1+1=2]'') == 'tests/test_foo.py::test_add'", 'expected_result': 'tests/test_foo.py::test_add'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        124 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53-54)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_batching.py::TestGetBaseNodeid::test_simple_nodeid</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks the behavior of _get_base_nodeid when given a simple nodeid without any parameters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected result', 'value': 'tests/test_foo.py::test_bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        91 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 53, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batch_max_size_respected</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Large groups should be split by batch_max_tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where large groups are not split into batches of the correct size, potentially leading to performance issues or incorrect results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of tests in each batch is equal to `batch_max_tests`.</li>
                                            <li>Each batch has exactly two tests.</li>
                                            <li>Only one batch contains three tests.</li>
                                            <li>All tests are present in their respective batches.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        364 input +
                                        106 output =
                                        470 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 53-54, 67-68, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_batching_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case for batched tests</p>
                                    <p><strong>Why Needed:</strong> To ensure that each test is separate and not affected by the batching mechanism.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Number of batches should be equal to number of tests', 'expected_value': 2, 'actual_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        81 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 92-93, 95, 97-99)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_parametrized_tests_grouped</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test parametrized tests should be grouped together.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the grouping of tests for batching is not considered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>batches should contain exactly one group with parameterized tests.</li>
                                            <li>each group in batches should have exactly three tests.</li>
                                            <li>the first group in batches should be marked as parametrized and have its base nodeid as 'test.py::test_add'.</li>
                                            <li>all tests within a group should be from the same module (in this case, 'test.py').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        129 output =
                                        475 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 34, 39-40, 53-54, 67, 70, 92-93, 95, 103-106, 108-110, 122-123, 126-132, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_batching.py::TestGroupTestsForBatching::test_single_tests_no_grouping</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Single tests should each be their own batch.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where multiple tests are grouped together and potentially interfere with each other's execution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Each test is in its own batch.</li>
                                            <li>There are two batches, one for each test.</li>
                                            <li>Each batch has exactly one test.</li>
                                            <li>The first batch contains only one test.</li>
                                            <li>The second batch also contains only one test.</li>
                                            <li>No tests are grouped together and interfere with each other's execution.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        121 output =
                                        399 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_cache.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_consistent_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_consistent_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache is consistent across different runs of the test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Same source should produce same hash', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        75 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_different_source_different_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for cache functionality</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache is working correctly and producing unique hashes for different inputs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Hash of input 1 should not match hash of input 2', 'expected_result': 'different'}</li>
                                            <li>{'name': 'Hash of input 3 should match hash of input 4', 'expected_result': 'same'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        105 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestHashSource::test_hash_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestHashSource::test_hash_length</p>
                                    <p><strong>Why Needed:</strong> To ensure the hash value is of a fixed length (16 characters).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The hash value should be 16 characters long.', 'value': 16}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        77 output =
                                        177 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_clear</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that clearing the cache removes all entries.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of large number of cache entries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The clear method should remove all cache entries.</li>
                                            <li>The get method should return None for non-existent keys.</li>
                                            <li>The count property should be updated correctly after clearing the cache.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        82 output =
                                        365 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 129, 132-136, 141)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_does_not_cache_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestLlmCache::test_does_not_cache_errors</p>
                                    <p><strong>Why Needed:</strong> To ensure that LLM annotations with errors are not cached.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cache annotation for error', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        73 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_get_missing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_cache.py::TestLlmCache::test_get_missing</p>
                                    <p><strong>Why Needed:</strong> To test that the get method returns None for missing entries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        70 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 39-41, 53, 55-56, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_cache.py::TestLlmCache::test_set_and_get</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that annotations can be set and retrieved from the cache.</p>
                                    <p><strong>Why Needed:</strong> Prevents bypass attacks by ensuring that LLMCache stores and retrieves annotations in a secure manner.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Check if the annotation is stored correctly in the cache.</li>
                                            <li>Check if the retrieved annotation matches the expected value.</li>
                                            <li>Verify that the confidence level of the retrieved annotation is correct.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        93 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 39-41, 53, 55, 58, 60-62, 68-73, 86, 90, 92, 94, 97-101, 103, 118-119, 121)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">11 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_collection_error_structure</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the collection errors have the correct structure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': {'message': 'nodeid should be a string'}, 'expected_result': 'nodeid should be a string'}</li>
                                            <li>{'assertion': {'message': 'message should be a string'}, 'expected_result': 'message should be a string'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        116 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorCollectionErrors::test_get_collection_errors_initially_empty</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_collection_errors` method returns an empty list when the collection is initially empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert collector.get_collection_errors() == []', 'expected_value': [], 'message': 'Expected get_collection_errors() to return an empty list'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        103 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_context_override_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_context_override_default_none</p>
                                    <p><strong>Why Needed:</strong> Default llm_context_override should be None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        74 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_opt_out_default_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorMarkerExtraction::test_llm_opt_out_default_false</p>
                                    <p><strong>Why Needed:</strong> The default value of llm_opt_out should be False.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'llm_opt_out is not equal to False', 'expected_value': False, 'actual_value': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        89 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for Collector Output Capture</p>
                                    <p><strong>Why Needed:</strong> Test that output capture is enabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Output capture should be enabled by default', 'description': 'The output capture feature should be enabled by default.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        70 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default</p>
                                    <p><strong>Why Needed:</strong> The default value for capture output max chars is not being tested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert config.capture_output_max_chars == 4000', 'expected_result': 4000, 'actual_result': 'tests/test_collector.py::TestCollectorOutputCapture::test_capture_max_chars_default'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        105 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_failed_is_xfailed</p>
                                    <p><strong>Why Needed:</strong> To ensure that xfail failures are correctly recorded as xfailed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'xfailed', 'actual_value': 'xfail'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        206 input +
                                        78 output =
                                        284 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212, 216, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestCollectorXfailHandling::test_xfail_passed_is_xpassed</p>
                                    <p><strong>Why Needed:</strong> xfail passes should be recorded as xpassed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'type', 'expected_value': 'xpassed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        75 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 212-214)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_create_collector</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `create_collector` method of `TestCollector` class.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the collector does not initialize with empty results, potentially leading to incorrect data being collected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>collector.results should be an empty dictionary.</li>
                                            <li>collector.collection_errors should be an empty list.</li>
                                            <li>collector.collected_count should be zero.</li>
                                            <li>assert collector.results == {}</li>
                                            <li>assert collector.collection_errors == []</li>
                                            <li>assert collector.collected_count == 0</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        205 input +
                                        121 output =
                                        326 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_get_results_sorted</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector.py::TestTestCollector::test_get_results_sorted</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks if the results are sorted by nodeid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'nodeids', 'expected': ['a_test.py::test_a', 'z_test.py::test_z'], 'actual': ['a_test.py::test_a', 'z_test.py::test_z']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        106 output =
                                        333 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector.py::TestTestCollector::test_handle_collection_finish</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `handle_collection_finish` method to ensure it correctly tracks collected and deselected counts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the collected count is not updated correctly when items are deselected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `collected_count` attribute should be set to 3 after collecting all items.</li>
                                            <li>The `deselected_count` attribute should be set to 1 after deselecting one item.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        105 output =
                                        361 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 78-79, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_collector_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_disabled_via_handle_report</p>
                                    <p><strong>Why Needed:</strong> To test that the collector does not capture output when config is disabled (integration via handle_runtest_logreport)</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'collector.handle_runtest_logreport', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        90 output =
                                        301 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorInternals test</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `collector._capture_output` method correctly captures stderr output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected captured stderr to be empty', 'expected_value': '', 'actual_value': 'Some error'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        76 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorInternals test capture_output_stdout</p>
                                    <p><strong>Why Needed:</strong> To verify that the `test_capture_output_stdout` method correctly captures stdout.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'captured_stdout', 'expected_value': 'Some output'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        69 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_capture_output_truncated</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_internals</p>
                                    <p><strong>Why Needed:</strong> Truncating output exceeding max chars in TestCollectorInternals test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected captured stdout length', 'value': 10}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        174 input +
                                        65 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 261, 264-265, 268)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_create_result_with_item_markers</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test creates a result with item markers.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the collector does not extract item markers correctly when they are present in an item's callspec.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>item.get_closest_marker('llm_opt_out') returns MagicMock().</li>
                                            <li>item.get_closest_marker('llm_context_override') returns MagicMock() with 'complete' args.</li>
                                            <li>item.get_closest_marker('requirement') returns MagicMock().</li>
                                            <li>item.get_closest_marker('llm_opt_out') is not None.</li>
                                            <li>item.get_closest_marker('llm_context_override') is not None.</li>
                                            <li>item.get_closest_marker('requirement') is not None.</li>
                                            <li>result.param_id == 'param1' is True.</li>
                                            <li>result.llm_opt_out is True.</li>
                                            <li>result.llm_context_override == 'complete' is True.</li>
                                            <li>result.requirements == ['REQ-1', 'REQ-2'] is True.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        382 input +
                                        213 output =
                                        595 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 155-159, 163-164, 167-169, 171, 181-182, 185-189, 198-200, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_repr_crash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_error_string</p>
                                    <p><strong>Why Needed:</strong> To ensure the `_extract_error` method returns a string that can be used to recreate the original exception.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _extract_error returns correct error message', 'expected_value': 'Some error occurred'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        90 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_fallback</p>
                                    <p><strong>Why Needed:</strong> To ensure the `_extract_skip_reason` method returns `None` when no longrepr is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert _extract_skip_reason returns None for no longrepr', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        92 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250, 252)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_string</p>
                                    <p><strong>Why Needed:</strong> To ensure the `extract_skip_reason` method returns a string as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected return value', 'value': 'Just skipped'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        78 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorInternals::test_extract_skip_reason_tuple</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 250-251)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_collection_report_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the TestCollector handleCollectionReport function when a collection report fails.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the TestCollector does not correctly record and log collection errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The collector should have recorded one collection error with nodeid 'test_broken.py' and message 'SyntaxError'.</li>
                                            <li>The collected error should be of type 'TestCollectorReportFailure'.</li>
                                            <li>The collector's collection_errors list should contain the expected error object.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        112 output =
                                        385 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 58, 60-65, 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_rerun</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `handle_runtest_rerun` method of TestCollector.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in handling reruns for a specific test case.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'rerun' attribute of the report should be set to 1 after a runtest call.</li>
                                            <li>The final outcome of the test should still be 'failed' even if the rerun count is 1.</li>
                                            <li>The `results` dictionary in the collector's results object should contain the expected data for the test case.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        122 output =
                                        403 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-118, 124, 127-128, 130, 140-141, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238, 261, 264-265, 268-269)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_setup_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestCollectorHandleRuntestSetupFailure verifies that the test collector correctly handles a setup failure in the runtest log report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the test collector correctly records and reports errors during setup.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'setup' event is recorded with an outcome of 'error'.</li>
                                            <li>The phase is set to 'setup'.</li>
                                            <li>The error message is set to 'Setup failed'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        300 input +
                                        106 output =
                                        406 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_collector_maximal.py::TestCollectorReportHandling::test_handle_runtest_teardown_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Collector should record error if teardown fails after pass.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression in case of a teardown failure, where the test is expected to fail but actually succeeds due to a teardown issue.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>res.outcome == 'error'</li>
                                            <li>res.phase == 'teardown'</li>
                                            <li>res.error_message == 'Cleanup failed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        88 output =
                                        479 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 90, 93-94, 96, 99, 110-112, 114-115, 124, 127-128, 130, 132-133, 135-137, 140, 155-159, 163, 167, 171, 209-210, 227-228, 230-234, 238)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_compression.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_invalid_compression_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test invalid context compression mode</p>
                                    <p><strong>Why Needed:</strong> To test that an invalid compression mode fails validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Context compression must be one of "none", "gzip", or "lzma"', 'expected_value': 'invalid'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        74 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_negative_padding_invalid</p>
                                    <p><strong>Why Needed:</strong> Negative padding should fail validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'column': 0, 'line': 1, 'message': 'context_line_padding is not a valid value for this context type.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        81 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_valid_compression_modes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestConfigValidation</p>
                                    <p><strong>Why Needed:</strong> To ensure that valid compression modes pass validation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'context_compression': 'none'}, 'actual': {'context_compression': 'lines'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        64 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestConfigValidation::test_zero_padding_valid</p>
                                    <p><strong>Why Needed:</strong> Zero padding is a valid configuration option.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config', 'type': 'Config', 'value': {'provider': 'none', 'context_line_padding': 0}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        83 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_compression_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> Context compression should be enabled by default ('lines').</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_compression', 'expected_value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        74 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_compression_mode_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for Context Compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context compression is working correctly and providing the expected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context Compression Mode', 'description': 'The context compression mode should be available.', 'expected_value': 'lines'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        77 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestContextCompression::test_line_padding_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestContextCompression::test_line_padding_default</p>
                                    <p><strong>Why Needed:</strong> To ensure that line padding is correctly set to 2 when the context provider is 'none'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.context_line_padding', 'expected_value': 2, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        89 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_contiguous_lines_no_gap</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Contiguous covered lines should not have gap indicators.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where contiguous lines are separated by gaps, potentially misleading the user about coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The # ... indicator is present for contiguous lines.</li>
                                            <li>The line numbers L3, L4, and L5 are included in the result.</li>
                                            <li>No gap indicators are added to contiguous lines.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        94 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_compression.py::TestExtractCoveredLines::test_empty_coverage</p>
                                    <p><strong>Why Needed:</strong> Empty coverage is necessary to test the ContextAssembler's ability to extract covered lines from a test with no actual execution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        79 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 216-217)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_multiple_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that multiple covered ranges are extracted with gap indicators.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the output does not contain gap indicators between ranges of covered lines.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output should contain a '#' character followed by ' ...' to indicate gaps between ranges.</li>
                                            <li>The output should contain '# L3:' to indicate range starting at line 3.</li>
                                            <li>The output should contain '# L15:' to indicate range starting at line 15.</li>
                                            <li>The output should have gap indicators between the ranges of covered lines.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        125 output =
                                        399 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_extract_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Single covered line should be extracted with padding.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where single lines are not extracted correctly due to missing padding.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_extract_covered_lines` includes lines 2, 3, and 4 in the result.</li>
                                            <li>Lines 2, 3, and 4 have 1 line padding.</li>
                                            <li>The test asserts that '# L2:', '# L3:', and '# L4:' are present in the result.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        302 input +
                                        118 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_compression.py::TestExtractCoveredLines::test_padding_boundary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extracted Covered Lines: Padding should not go beyond file boundaries.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where padding exceeds the file boundary, potentially causing incorrect coverage metrics.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert '# L1:' in result</li>
                                            <li>assert '# L2:' in result</li>
                                            <li>assert '# L3:' in result</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        85 output =
                                        373 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">23 lines (ranges: 33, 216, 219-220, 223-228, 231-232, 235-237, 239-240, 242, 244-247, 249)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_limits.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_no_truncation_needed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_limits.py::test_no_truncation_needed</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the current implementation of `provider._build_prompt` truncates the context when it detects that a node's content exceeds the specified limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "The 'prompt' variable should contain the full content of the node.", 'expected_value': 'short content'}</li>
                                            <li>{'assertion': "The 'truncated' key in the 'prompt' dictionary should be absent.", 'expected_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        158 input +
                                        133 output =
                                        291 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_smart_distribution</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_smart_distribution verifies that the smart distribution logic prevents a regression and optimizes F2's budget.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a regression in the smart distribution logic by ensuring F2 gets at least their fair share of tokens, even if it means truncating some content to avoid waste.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>F1 should be full (A*160).</li>
                                            <li>F2 should get at least 110 tokens (100+80).</li>
                                            <li>F2's budget should not exceed the total available tokens (220).</li>
                                            <li>The smart split logic uses 40 + 180 = 220 tokens, which is zero waste.</li>
                                            <li>F2 should be truncated to avoid exceeding their fair share of tokens (480 < 536).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        773 input +
                                        169 output =
                                        942 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_splitting_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the splitting logic correctly truncates strings and meets the expected requirements.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the splitting logic does not truncate strings, leading to incorrect output or unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The string 'f1' should be truncated in the prompt.</li>
                                            <li>The string 'f2' should be truncated in the prompt.</li>
                                            <li>The keyword 'truncated' should be present in the prompt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        109 output =
                                        426 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 243, 245, 264, 266, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307, 310, 312, 314)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_limits.py::test_truncation_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `provider._build_prompt` function truncates prompts to fit within a specified limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regressions where large context files cause excessive prompting and context is not relevant.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>len(prompt) should be less than (limit * 5)</li>
                                            <li>[... truncated] should be present in the prompt or 'Relevant context' should not be present</li>
                                            <li>prompt should contain a header indicating truncation</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        397 input +
                                        111 output =
                                        508 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 243, 245, 264, 266, 270-272, 274-275)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_context_util.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">28 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_collapse_three_empty_lines</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the functionality of the `collapse_empty_lines` function when there are 3+ empty lines in a source string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'line1\n\nline2', 'actual': 'line1\n\n'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        97 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_many_empty_lines</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collapsing many empty lines to one blank line.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The collapsed source code should have only one newline character.', 'expected_value': '\n\nline1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        88 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_preserve_two_empty_lines</p>
                                    <p><strong>Why Needed:</strong> Preserves up to 2 consecutive newlines in context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'line1\n\nline2', 'actual_result': 'line1\n\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        83 output =
                                        208 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestCollapseEmptyLines::test_single_newline</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of collapsing empty lines in a single newline scenario.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The result should be the original source string with no changes.', 'expected_result': 'line1\nline2\nline3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        90 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 108)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_always_collapses_empty_lines</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks if the `optimize_context` function always collapses empty lines, regardless of the flags used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'source should be modified to have only one line with no trailing whitespace', 'expected_result': 'line1\nline2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        137 input +
                                        102 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_combined_optimization</p>
                                    <p><strong>Why Needed:</strong> To ensure that the combined optimization process is applied correctly to the test context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'id': 'combined_optimization_process', 'expected_result': 'The combined optimization process should have been applied successfully.'}</li>
                                            <li>{'id': 'optimized_context', 'expected_result': 'The test context has been optimized correctly.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        110 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_default_strips_docs_only</p>
                                    <p><strong>Why Needed:</strong> The default behavior of the `optimize_context` function should strip all docstrings, not just those in comments.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring stripping', 'expected': True, 'actual': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        88 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_empty_source</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_empty_source</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the current implementation of `optimize_context` does not handle empty sources correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'result == ""', 'expected_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        78 output =
                                        173 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_source_with_only_whitespace</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the current implementation does not handle source code with only whitespace characters correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '   \n\n   \n', 'actual_value': '   \n\n   \n'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        91 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_both</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_both</p>
                                    <p><strong>Why Needed:</strong> To optimize the context by removing unnecessary docstrings and comments.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'strip both', 'expected_result': {'docstring': '', 'comment': ''}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        78 output =
                                        173 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69, 81-82, 86, 88-90, 93, 108, 124, 126-127, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_comments_only</p>
                                    <p><strong>Why Needed:</strong> To optimize the context by removing unnecessary comment lines that do not affect the functionality of the code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'expected_string_length', 'expected_value': 0, 'actual_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        89 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 81-82, 86, 88-90, 93, 108, 124, 126, 129-130, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestOptimizeContext::test_strip_neither</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestOptimizeContext::test_strip_neither</p>
                                    <p><strong>Why Needed:</strong> To ensure that the optimizer can correctly handle cases where neither strip nor optimize is requested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'source', 'expected': 'def foo():'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        76 output =
                                        170 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 108, 124, 126, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_comment_after_string_with_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function correctly strips comments from strings containing a hash (#) symbol.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The expected output of the test is compared to the actual output.', 'expected_output': "'url = ", 'actual_output': '"http://example.com#anchor"'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        103 output =
                                        237 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_escaped_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_escaped_quotes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context utility correctly handles escaped quotes in strings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should not return a string containing an escaped quote.', 'expected_result': '# comment'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        80 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_mixed_quotes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_mixed_quotes</p>
                                    <p><strong>Why Needed:</strong> To strip quotes from code that contains both single and double quotes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '"don\'t # worry"', 'actual': '"don\'t \\# worry"'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        77 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_no_comments</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_no_comments</p>
                                    <p><strong>Why Needed:</strong> To strip comments from the source code, ensuring that only relevant information is included in the output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': '.*#.*', 'expected_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        91 input +
                                        84 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_double_quoted_string</p>
                                    <p><strong>Why Needed:</strong> Preserves # inside double-quoted strings in source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'strip_comments() removes leading and trailing whitespace from the entire string, including comments.', 'expected_result': '', 'actual_result': 'url = "http://example.com#anchor"'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        104 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_preserve_hash_in_single_quoted_string</p>
                                    <p><strong>Why Needed:</strong> To ensure that comments are stripped from single-quoted strings, preserving the hash character (#) to maintain code readability.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result == 'url = 'http://example.com#anchor',</li>
                                            <li>  # Expected: 'url = 'http://example.com#anchor'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        96 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_simple_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_simple_comment</p>
                                    <p><strong>Why Needed:</strong> To remove simple end-of-line comments from the source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'x = 1', 'actual_value': 'strip_comments(source)', 'message': "Expected strip_comments(source) to return 'x = 1', but got '{}' instead."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        98 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripComments::test_strip_standalone_comment</p>
                                    <p><strong>Why Needed:</strong> To strip standalone comments from the test source code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': "The line should be stripped of any leading or trailing whitespace and then removed if it's a standalone comment.", 'actual': 'The line remains unchanged.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        89 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81-82, 86, 88-90, 93)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_handles_syntax_error_gracefully</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks that the function does not modify the original source code when a syntax error occurs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The function should return the original source code without any modifications.', 'expected_result': 'def foo( unclosed paren', 'actual_result': 'def foo( unclosed paren'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        112 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 27, 29-31)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_multiple_docstrings</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks if the context_util module can strip out multiple docstrings from a given string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'strip_multiple_docstrings', 'expected_result': 'Module docstring.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        86 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_multiline_data_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve multiline data strings in docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'docstring triple quotes are preserved', 'expected_value': 'def foo():\n    """\n    def bar():\n        pass\n    \\\n    return \'Hello, World!\'\n"""', 'actual_value': '\'"""def foo():\n    """def bar():\n        pass\n    \\\n    return \'Hello, World!\'\n"""\''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        151 output =
                                        254 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_preserves_regular_strings</p>
                                    <p><strong>Why Needed:</strong> Preserve regular strings in test context</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Regular string is preserved', 'condition': "source.contains('hello world') == True", 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        83 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 27, 29, 33, 35-36, 38-45, 49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_preserves_strings_in_structures</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>LLM error:</strong> Failed to parse LLM response as JSON</p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58, 61, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_multiline_docstring</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context utility function works correctly when dealing with multiline docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'remove_all', 'expected_result': 'str', 'actual_result': 'str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        87 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_double_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context manager works correctly, especially when dealing with triple double-quoted docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `strip_triple_double_quoted_docstring` should remove all triple double-quoted docstrings from the given source code.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        93 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_context_util.py::TestStripDocstrings::test_strip_triple_single_quoted_docstring</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the current implementation does not correctly strip triple single-quoted docstrings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'strip_triple_single_quoted_docstring', 'expected_value': '', 'message': 'Expected to return an empty string after stripping triple single-quoted docstrings.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        107 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 27, 29, 33, 35-36, 38-45, 47-49, 51-52, 55-56, 58-59, 61-62, 64, 66-69)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_boosters.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_model_parsing_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the parsing of preferred models for a Gemini configuration with edge cases.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case the 'm1' or 'm2' model is not available, as it would cause an error when trying to parse them.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'm1' in models</li>
                                            <li>assert 'm2' in models</li>
                                            <li>assert provider._parse_preferred_models() == []</li>
                                            <li>assert provider._parse_preferred_models() == ['All']</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        118 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 134-135, 137-141, 143-144, 476, 478, 524-531)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_gemini_rate_limiter_edge_math</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter prevents over and under token limits when recording tokens but not requests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the rate limiter allows excessive token usage without preventing the request from being processed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The next_available_in() method should return an error (0) for both over and under token limits when recording tokens but not requests.</li>
                                            <li>The next_available_in() method should return a valid time in seconds for both over and under token limits when recording tokens but not requests.</li>
                                            <li>The rate limiter should prevent excessive token usage without preventing the request from being processed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        142 output =
                                        415 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_boosters.py::TestCoverageBoosters::test_models_to_dict_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `to_dict()` method of `SourceCoverageEntry` and `LlmAnnotation` classes returns the expected values for coverage percent, error message, and duration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the coverage percent is not correctly calculated for `SourceCoverageEntry` instances with multiple statements covered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `d['coverage_percent']` should be equal to 50.0.</li>
                                            <li>The value of `ann.to_dict()['error']` should be equal to 'timeout'.</li>
                                            <li>The value of `meta.to_dict()['duration']` should be equal to 1.0.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        147 output =
                                        465 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 96-103, 130-133, 135, 137-139, 141, 143, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_create_mapper</p>
                                    <p><strong>Why Needed:</strong> To ensure the Mapper class initializes with a valid configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mapper.config is config', 'expected_value': 'config'}</li>
                                            <li>{'name': 'mapper.warnings == []', 'expected_value': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        91 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapper::test_get_warnings</p>
                                    <p><strong>Why Needed:</strong> To ensure the get_warnings method returns a list of warnings as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Type of warnings is correct', 'expected_type': 'list', 'actual_type': 'list'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        82 output =
                                        192 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 44-45, 308)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapper::test_map_coverage_no_coverage_file</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `map_coverage` function returns an empty dictionary when no coverage file exists.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of missing coverage files, ensuring accurate coverage reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `map_coverage()` method should return a dictionary with all keys set to False (indicating no coverage).</li>
                                            <li>The `map_coverage()` method should have at least one warning (indicating potential issues).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        277 input +
                                        102 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_all_phases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `CoverageMapper` correctly extracts node IDs for all phases when the `include_phase` parameter is set to 'all'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `CoverageMapper` does not extract node IDs for certain phases, leading to incorrect coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `_extract_nodeid` method returns the expected node ID for each phase.</li>
                                            <li>The `_extract_nodeid` method returns the same node ID across all phases.</li>
                                            <li>The `assert` statements check that the extracted node IDs match the expected values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        134 output =
                                        413 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_empty_context</p>
                                    <p><strong>Why Needed:</strong> To handle the case when the context is empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'assert mapper._extract_nodeid([]) == None', 'expected_result': 'None'}</li>
                                            <li>{'assertion': 'assert mapper._extract_nodeid(None) == None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        111 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_filters_setup</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_filters_setup</p>
                                    <p><strong>Why Needed:</strong> To filter out setup phase when include_phase=run.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is_none', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        139 input +
                                        76 output =
                                        215 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 216, 220, 224-225, 228-230)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map.py::TestCoverageMapperContextExtraction::test_extract_nodeid_with_run_phase</p>
                                    <p><strong>Why Needed:</strong> To extract the correct node ID from the run phase context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "nodeid == 'test.py::test_foo'", 'expected_result': 'test.py::test_foo'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        90 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">17 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_contexts_by_lineno_exception</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_contexts_by_lineno_exception' verifies that the test_contexts_by_lineno function handles exceptions correctly.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a potential regression where the test_contexts_by_lineno function fails to handle an exception when accessing contexts for files with multiple lines of code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mock_data.contexts_by_lineno.side_effect is set to raise an Exception when it encounters the first file ('file.py') in the measured_files list.</li>
                                            <li>The test asserts that the result of calling mapper._extract_contexts(mock_data) is an empty dictionary, indicating that the function handled the exception correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        140 output =
                                        472 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152, 156, 160-162, 167-170, 199, 202)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_no_measured_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Extract Contexts</p>
                                    <p><strong>Why Needed:</strong> When no measured files are present in the coverage data, an empty dictionary should be returned.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is a dictionary', 'expected_value': '{}', 'actual_value': 'assert result == {}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        78 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 44-45, 118, 121-122, 127-128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestExtractContexts::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestExtractContexts::test_skip_non_python_files</p>
                                    <p><strong>Why Needed:</strong> To skip non-Python files from coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'equals', 'expected_value': {}, 'actual_value': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        76 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_coverage_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 44-45)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestLoadCoverageData::test_no_coverage_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestLoadCoverageData</p>
                                    <p><strong>Why Needed:</strong> To test the scenario when no .coverage file exists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result is None', 'expected_value': 'None'}</li>
                                            <li>{'name': "assert any('W001' in w.code for w in mapper.warnings)", 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        93 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_analysis_exception_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_analysis_exception_handling function prevents regression by catching Analysis2 exceptions and adding warnings.</p>
                                    <p><strong>Why Needed:</strong> This test verifies that the test_analysis_exception_handling function handles analysis2 exceptions correctly, preventing potential regressions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return an empty list when analyzing a source code with no coverage data.</li>
                                            <li>The function should add a warning to the warnings list for each Analysis2 exception it catches.</li>
                                            <li>The function should not add any COVERAGE_ANALYSIS_FAILED warnings in this specific test case.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        122 output =
                                        408 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_empty_statements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when file has no statements.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the coverage map is correctly handled when a file contains no statements.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': [], 'actual_result': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        178 input +
                                        75 output =
                                        253 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259-261, 273-274, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_include_test_files_when_not_configured</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that test files are included when omit_tests_from_coverage is False.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case the `omit_tests_from_coverage` configuration flag is set to True without specifying a custom list of test files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `covered` attribute of the first result should be equal to 2 (i.e., all test files are included).</li>
                                            <li>The `missed` attribute of the first result should be equal to 1 (i.e., only one test file is missed).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        123 output =
                                        445 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_non_python_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_skip_non_python_files</p>
                                    <p><strong>Why Needed:</strong> Skip non-Python files to ensure accurate coverage reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': {}, 'actual_result': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        56 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 44-45, 243-244, 246-249, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestMapSourceCoverage::test_skip_test_files_when_configured</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that test files are skipped when omit_tests_from_coverage is True.</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that test files are correctly skipped from the coverage report when `omit_tests_from_coverage` is set to `True`. This helps prevent false positives and ensures accurate reporting of covered code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'Test files are skipped when omit_tests_from_coverage is True.', 'actual_value': 'The test files are included in the coverage report.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        182 input +
                                        126 output =
                                        308 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 243-244, 246-248, 250, 252-255, 257, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_all_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all phases are accepted when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in phase filtering functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mapper should return the nodeid for any phase.</li>
                                            <li>The mapper should match the expected nodeids with the given paths.</li>
                                            <li>All phases should be included in the coverage report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        305 input +
                                        80 output =
                                        385 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_empty_string</p>
                                    <p><strong>Why Needed:</strong> To test that an empty string does not return a node ID.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert mapper._extract_nodeid() returns None for empty string', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        85 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_none</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `_extract_nodeid` method handles `None` inputs correctly and returns `None` as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'mapper._extract_nodeid(None) == None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        93 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 44-45, 216-217)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_run_phase_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that run phase is the default filter.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the default filter does not match the expected node ID.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        120 output =
                                        417 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_setup_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that setup phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the test might fail due to incorrect filtering of nodeids in the setup phase.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        125 output =
                                        418 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_teardown_phase_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that teardown phase is correctly filtered when configured.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the teardown phase is not properly filtered, leading to incorrect coverage reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|teardown') == 'test_foo.py::test_bar'</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|run') is None</li>
                                            <li>mapper._extract_nodeid('test_foo.py::test_bar|setup') is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        125 output =
                                        421 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231, 233-234, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_coverage.py::TestPhaseFiltering::test_extract_nodeid_without_pipe</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the current implementation of `CoverageMapper` does not correctly handle node IDs without phase delimiters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'value', 'expected_value': 'test_foo.py::test_bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        93 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 44-45, 216, 220, 224, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_coverage_map_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_full_logic</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Should exercise all paths in _extract_contexts to ensure full logic coverage.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by verifying that the mapper extracts all necessary contexts for full logic coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'test_app.py::test_one' in result</li>
                                            <li>assert 'test_app.py::test_two' in result</li>
                                            <li>assert len(one_cov) == 1 and one_cov[0].line_count == 2</li>
                                            <li># Verify app.py is in test_one's coverage</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        118 output =
                                        531 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 137-140, 144, 148, 150, 152-153, 156, 160-163, 165, 167-168, 173, 176, 178-184, 187-189, 191-194, 196, 199-200, 202, 216, 220, 224-225, 228-229, 231, 233, 236)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_no_contexts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_contexts_no_contexts</p>
                                    <p><strong>Why Needed:</strong> To test the coverage mapper's behavior when there are no test contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {}, 'actual': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        174 input +
                                        73 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 118, 121-122, 127, 131-135, 144-146)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_extract_nodeid_variants</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `CoverageMapper` correctly extracts node IDs for a scenario where there are missing lines in the code.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the coverage map is not accurately reporting the number of covered lines due to missing or filtered code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `_extract_nodeid` method should return the expected node ID for each line in the given phase.</li>
                                            <li>If the line is filtered, the method should return `None`.</li>
                                            <li>The method should handle cases where there are no lines in the given phase.</li>
                                            <li>The method should correctly extract node IDs from code without a pipe (|) separating different phases.</li>
                                            <li>The `_extract_nodeid` method should be able to distinguish between missing and filtered lines.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        171 output =
                                        494 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 44-45, 216, 220, 224-225, 228-229, 231-234, 236, 239)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_no_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the function correctly handles the case when no coverage files exist.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function would silently fail to load coverage data without raising an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return None for _load_coverage_data() when no .coverage files are found.</li>
                                            <li>There should be exactly one warning message with code 'W001' in mapper.warnings.</li>
                                            <li>All warnings should have the same code 'W001'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        113 output =
                                        389 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 44-45, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_read_error</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_load_coverage_data_read_error function handles errors reading coverage files correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the CoverageMapper class fails to handle errors when loading coverage data from corrupted or invalid files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return None when trying to load coverage data from a corrupt .coverage file.</li>
                                            <li>Any warnings generated by the mapper should contain 'Failed to read coverage data' in their message.</li>
                                            <li>The mapper's warnings should not be None, indicating that no errors were found during loading.</li>
                                            <li>The function should raise an exception when trying to load coverage data from a corrupted or invalid file.</li>
                                            <li>A mock CoverageData instance with a side effect of raising an Exception on read should be used for mocking purposes.</li>
                                            <li>The mocked CoverageData instance's read method should return an Exception object.</li>
                                            <li>Any assertions made within the try block should not raise any AssertionError, indicating that no errors were found during loading.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        211 output =
                                        554 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94-96, 107-111, 114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_load_coverage_data_with_parallel_files</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should handle parallel coverage files from xdist and verify that the CoverageMapper correctly updates its data.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the CoverageMapper does not update its data when loading coverage files from parallel directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mock instances of `CoverageData` returned by `mock_data_cls.side_effect` should have been updated with at least two calls to `update()`.</li>
                                            <li>The `update()` method should be called on the mock instance of `CoverageData` that was created in the test fixture.</li>
                                            <li>The `update()` method should not be called on any other mock instances of `CoverageData` returned by `mock_data_cls.side_effect`.</li>
                                            <li>Any mock instances of `CoverageData` that were not part of the parallel data (i.e., `mock_parallel_data1` and `mock_parallel_data2`) should not have been updated.</li>
                                            <li>The `update()` method should be called on any mock instance of `CoverageData` that was created in the test fixture, even if it is not a part of the parallel data.</li>
                                            <li>Any mock instances of `CoverageData` that were created in the test fixture but are not part of the parallel data should not have been updated.</li>
                                            <li>The `update()` method should be called on any mock instance of `CoverageData` that was created in the test fixture, even if it is a part of the parallel data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        378 input +
                                        304 output =
                                        682 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 44-45, 72-73, 83, 86, 88, 92, 94, 98, 101-104, 106)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_coverage_no_data</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `map_coverage` method returns an empty dictionary when `_load_coverage_data` returns None.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the `map_coverage` method does not handle cases where there is no coverage data to map.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `_load_coverage_data` method of the `CoverageMapper` class should be called with `None` as its argument when no data is available.</li>
                                            <li>The `map_coverage` method should return an empty dictionary (`{}`) when no data is found.</li>
                                            <li>No exception should be raised if no coverage data is loaded by `_load_coverage_data`.</li>
                                            <li>The `map_coverage` method should not throw any errors or exceptions when there is no data to map.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        167 output =
                                        395 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-45, 58-60)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_analysis_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the CoverageMapper handles analysis errors during source coverage analysis.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where an error in analysis2 causes all files to be skipped without any meaningful output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The mock_cov.analysis2 side effect is called with an exception 'Analysis failed'.</li>
                                            <li>mock_data.measured_files returns ['app.py'] as expected.</li>
                                            <li>mock_cov.get_data returns the mocked data.</li>
                                            <li>entries is empty after calling mapper.map_source_coverage(mock_cov).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        118 output =
                                        392 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 44-45, 243-244, 246-248, 250, 252-254, 259, 261, 263-268, 271, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_coverage_map_maximal.py::TestCoverageMapperMaximal::test_map_source_coverage_comprehensive</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test covers all paths in map_source_coverage with comprehensive coverage.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that all possible source files are covered under the given configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function mapper.map_source_coverage returns exactly one entry for 'app.py'.</li>
                                            <li>The file path of the first entry is correct ('app.py').</li>
                                            <li>The number of statements in the first entry is correct (3).</li>
                                            <li>The coverage percentage of the first entry is correct (66.67%).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        345 input +
                                        123 output =
                                        468 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 44-45, 243-244, 246-248, 250, 252, 259-261, 273, 276-279, 281-283, 285-293, 295, 299-300)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">3 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_make_warning</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the `make_warning` factory function to verify it returns a WarningCode.W001_NO_COVERAGE warning with the specified detail.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `make_warning` function does not correctly identify warnings without coverage files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `make_warning` should return a WarningCode.W001_NO_COVERAGE warning with the specified detail.</li>
                                            <li>The message of the warning should contain 'No .coverage file found'.</li>
                                            <li>The detail of the warning should be set to 'test-detail'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        128 output =
                                        364 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_code_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that warning codes have correct values.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the warning code values are incorrect, potentially leading to unexpected behavior or errors in the application.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Assertion failed: WarningCode.W001_NO_COVERAGE.value == "W001"'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W101_LLM_ENABLED.value == "W101"'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W201_OUTPUT_PATH_INVALID.value == "W201"'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W301_INVALID_CONFIG.value == "W301"'}</li>
                                            <li>{'message': 'Assertion failed: WarningCode.W401_AGGREGATE_DIR_MISSING.value == "W401"'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        167 output =
                                        407 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors.py::test_warning_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWarning.to_dict() method.</p>
                                    <p><strong>Why Needed:</strong> Prevents a warning that is not properly formatted in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'code' key should contain the correct value.</li>
                                            <li>The 'message' key should contain the correct value.</li>
                                            <li>The 'detail' key should be present and have the correct value.</li>
                                            <li>The 'code' key should match the expected value of ReportWarning.W001_NO_COVERAGE.</li>
                                            <li>The 'message' key should match the expected value of ReportWarning.W001_NO_COVERAGE.</li>
                                            <li>The 'detail' key should match the expected value of some/path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        144 output =
                                        420 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_errors_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_known_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a warning is created with the correct code and message for known code.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where warnings are not correctly generated when using known code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `make_warning` returns an instance of `WarningCode.W101_LLM_ENABLED` with the correct code.</li>
                                            <li>The warning message is set to `WARNING_MESSAGES[WarningCode.W101_LLM_ENABLED]`.</li>
                                            <li>The detail attribute is not provided for warnings with code `WarningCode.W101_LLM_ENABLED`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        125 output =
                                        347 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_unknown_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_unknown_code</p>
                                    <p><strong>Why Needed:</strong> To handle unknown WarningCode values that are not part of the enum.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'missing_code', 'expected_type': 'WarningCode', 'actual_type': 'str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        202 input +
                                        83 output =
                                        285 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_errors_maximal.py::TestMakeWarning::test_make_warning_with_detail</p>
                                    <p><strong>Why Needed:</strong> To test the creation of a warning with detail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'w.code == WarningCode.W301_INVALID_CONFIG', 'expected_result': 'True'}</li>
                                            <li>{'name': 'w.detail == "Bad value"', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        102 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningCodes::test_codes_are_strings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests failed</p>
                                    <p><strong>Why Needed:</strong> The test 'test_codes_are_strings' is expected to pass. However, it has raised a warning.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Enum values should be strings.', 'expected_type': 'str'}</li>
                                            <li>{'message': "WarningCode.value.startswith('W').", 'expected_type': 'str'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        95 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_no_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for ReportWarning class</p>
                                    <p><strong>Why Needed:</strong> To ensure that the warning is correctly serialized to a dictionary without any additional details.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "data == {'code': 'W001', 'message': 'No coverage'}", 'expected_result': {'code': 'W001', 'message': 'No coverage'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        91 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_errors_maximal.py::TestWarningDataClass::test_warning_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_non_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_non_python_file</p>
                                    <p><strong>Why Needed:</strong> The test is checking if the function correctly identifies non-.py files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_python_file() should return False for non-.py files', 'description': 'The function should return False for non-.py files', 'expected_result': False}</li>
                                            <li>{'name': 'is_python_file() should return False for non-.pyc files', 'description': 'The function should return False for non-.pyc files', 'expected_result': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        144 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestIsPythonFile::test_python_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestIsPythonFile::test_python_file</p>
                                    <p><strong>Why Needed:</strong> The function `is_python_file()` should be able to identify .py files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assertion', 'description': 'The function `is_python_file()` should return True for .py files.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        85 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_makes_path_relative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_makes_path_relative</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of making a path relative to the current working directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_output': 'subdir/file.py', 'actual_output': 'subdir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        79 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestMakeRelative::test_returns_normalized_with_no_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function returns a normalized path when no base is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'foo/bar', 'actual_value': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        80 output =
                                        187 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_already_normalized</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_already_normalized</p>
                                    <p><strong>Why Needed:</strong> The current implementation of `normalize_path` does not correctly handle already-normalized paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'foo/bar', 'actual': 'foo/bar'}</li>
                                            <li>{'expected': 'normalized', 'actual': 'already normalized'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        82 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_forward_slashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_forward_slashes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly handles paths with forward slashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '/foo/bar', 'actual_value': 'foo\\bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        76 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestNormalizePath::test_strips_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly removes trailing slashes from file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '/foo/bar/', 'actual_value': 'foo/bar'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        79 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_custom_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `should_skip_path` function correctly handles custom pattern exclusion.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'custom patterns should be excluded', 'description': "The path 'tests/conftest.py' should be skipped due to custom patterns."}</li>
                                            <li>{'name': 'module.py should not be skipped', 'description': "The path 'src/module.py' should not be skipped due to custom patterns."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        129 output =
                                        255 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_normal_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_normal_path</p>
                                    <p><strong>Why Needed:</strong> The test should be able to pass without skipping any path.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should not skip normal paths', 'expected': True, 'actual': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        76 output =
                                        172 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_git</p>
                                    <p><strong>Why Needed:</strong> The current implementation of `should_skip_path` does not correctly handle `.git` directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert should_skip_path is True for .git/objects/foo', 'expected_result': True, 'message': 'Expected should_skip_path to return True for the path .git/objects/foo'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        106 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_pycache</p>
                                    <p><strong>Why Needed:</strong> Because the test case is testing the functionality of skipping __pycache__ directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is True', 'expected_value': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        77 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs.py::TestShouldSkipPath::test_skips_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs.py::TestShouldSkipPath::test_skips_venv</p>
                                    <p><strong>Why Needed:</strong> Because the test case `should_skip_path` is trying to check if a specific directory should be skipped, but it's actually causing an issue with the venv directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Should skip venv directories', 'description': 'The function should return True for venv directories and False otherwise'}</li>
                                            <li>{'name': '.venv/lib/python/site.py', 'description': '.venv is a virtual environment directory, it should be skipped by the function.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        144 output =
                                        265 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_fs_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_false</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that a non-.py file does not match the expected behavior.</p>
                                    <p><strong>Why Needed:</strong> Prevents potential bugs where a non-.py file is incorrectly identified as Python code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `is_python_file` correctly returns False for non-.py files.</li>
                                            <li>The function `is_python_file` correctly returns False for non-.py files with the `.pyc` extension.</li>
                                            <li>The function `is_python_file` does not incorrectly identify a valid Python file as non-Python code.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        210 input +
                                        121 output =
                                        331 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestIsPythonFile::test_is_python_file_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing if a file is a Python file.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where a non-Python file is incorrectly identified as such.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'The function is_python_file() should return True for .py files.', 'description': 'The function should correctly identify .py files.'}</li>
                                            <li>{'message': 'The function is_python_file() should return True for path/to/.py files.', 'description': 'The function should correctly identify path-to/.py files.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        118 output =
                                        330 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 79)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_path_not_under_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test makes a relative path not under the base directory when it is not.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where make_relative fails to return normalized absolute paths for non-relative paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return a normalized absolute path as expected.</li>
                                            <li>The 'project1' should be present in the result.</li>
                                            <li>The 'file.py' should also be present in the result.</li>
                                            <li>The relative_to parameter should not cause make_relative to fail for non-relative paths.</li>
                                            <li>make_relative should correctly normalize the absolute path when the input is not under the base directory.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        301 input +
                                        135 output =
                                        436 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Make Relative</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of making a relative path to a file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected output', 'value': 'subdir/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        147 input +
                                        62 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 55, 58-60, 63-64)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_with_none_base</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestMakeRelative::test_make_relative_with_none_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `make_relative` function correctly handles cases where the base is None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'path/to/file.py', 'actual': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        82 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 30, 33, 36, 39, 42, 55-56)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_backslashes</p>
                                    <p><strong>Why Needed:</strong> To ensure that backslashes are correctly converted to forward slashes in file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': 'path/to/file.py', 'actual_result': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        80 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_path_object</p>
                                    <p><strong>Why Needed:</strong> To ensure the `normalize_path` function correctly normalizes path objects, specifically when dealing with file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': {'message': "Expected normalized path to be 'path/to/file.py'"}, 'expected_result': 'path/to/file.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        96 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestNormalizePath::test_normalize_path_trailing_slash</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `normalize_path` function correctly removes trailing slashes from file paths.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '/path/to/dir/', 'actual_value': 'path/to/dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        82 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 30, 33, 36, 39, 42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_not_skip_regular_path</p>
                                    <p><strong>Why Needed:</strong> Regular paths are not skipped by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "should_skip_path('src/module.py') is False", 'expected_result': True}</li>
                                            <li>{'assertion': "should_skip_path('tests/test_foo.py') is False", 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        107 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_git</p>
                                    <p><strong>Why Needed:</strong> The test should skip the .git directory because it contains a Git hook that may be causing issues with the test.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should skip .git directory', 'expected': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        83 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_path_starting_with_skip_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure that the function correctly handles paths starting with a skip directory name.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should be True for venv path', 'expected_value': True, 'message': 'The function should return True for paths starting with a skip directory name.'}</li>
                                            <li>{'name': 'should be True for .venv path', 'expected_value': True, 'message': 'The function should return True for paths starting with a skip directory name.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        146 output =
                                        270 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_pycache</p>
                                    <p><strong>Why Needed:</strong> Because the test module __pycache__ is being tested.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should skip the __pycache__ directory.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        62 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_site_packages</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> /usr/lib/python3.12/site-packages/pkg/mod.py</p>
                                    <p><strong>Why Needed:</strong> Because it's a site-package directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_site_package_directory', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        64 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_venv</p>
                                    <p><strong>Why Needed:</strong> The test is checking if venv directories are skipped by the `should_skip_path` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'path': 'venv/lib/python3.12/site.py', 'expected_result': True}</li>
                                            <li>{'path': '.venv/lib/python3.12/site.py', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        112 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-113)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_fs_coverage.py::TestShouldSkipPath::test_should_skip_with_exclude_patterns</p>
                                    <p><strong>Why Needed:</strong> Custom exclude patterns are needed to skip certain files that contain sensitive information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'should_skip_path', 'expected_result': True}</li>
                                            <li>{'name': 'assert_path', 'expected_result': False, 'message': 'Expected path to be excluded, but it was not.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        110 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/fs.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 30, 33, 36, 39, 42, 100, 103, 111-112, 116-117, 119-121, 123)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_gemini_provider.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">25 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotate_loop_daily_limit_hit</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_annotate_loop_daily_limit_hit function prevents a daily limit hit when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the provider would exceed its daily limit of requests per day, potentially causing unexpected behavior or errors in downstream applications.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function should return an error message indicating that the Gemini requests-per-day limit has been reached when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</li>
                                            <li>The function should not attempt to annotate the internal node as 'passed' when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</li>
                                            <li>The function should return an error message indicating that the Gemini requests-per-day limit has been reached when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</li>
                                            <li>The function should not attempt to annotate the internal node as 'passed' when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</li>
                                            <li>The function should return an error message indicating that the Gemini requests-per-day limit has been reached when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</li>
                                            <li>The function should not attempt to annotate the internal node as 'passed' when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</li>
                                            <li>The function should return an error message indicating that the Gemini requests-per-day limit has been reached when the provider is configured with an empty _models list and a mock limiter that returns None for the daily limit.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        393 output =
                                        760 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-227, 232-233, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_annotation_exceptions_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that _GeminiRateLimitExceeded is raised when a request exceeds the limit.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression where a request exceeds the rate limit and causes the model to be exhausted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Mocking the _call_gemini function with a side effect of raising _GeminiRateLimitExceeded.</li>
                                            <li>Setting the mock_call.side_effect to _GeminiRateLimitExceeded.</li>
                                            <li>Asserting that res.error contains 'requests-per-day' or 'rate limits reached'.</li>
                                            <li>_GeminiRateLimitExceeded is called with the correct arguments ('requests_per_day')</li>
                                            <li>The model is marked as exhausted and its status is updated correctly.</li>
                                            <li>The _model_exhausted_at dictionary contains the key 'm1' with a value set to True.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        730 input +
                                        181 output =
                                        911 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-236, 239-244, 263-265, 268, 293, 295, 299-303, 318-320, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_coverage_gaps</span>
                            <div class="test-meta">
                                <span>167ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Prevents regression in coverage gaps by ensuring that the rate limiters are correctly configured and annotated for different scenarios.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage gaps because it ensures that the rate limiters are correctly configured and annotated for different scenarios, such as prompt_override, context too long error, RPD in parse_rate_limits, fallback models, input limits logic (Flash vs Pro).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The _GeminiRateLimiter is correctly configured with a requests_per_minute value of 100.</li>
                                            <li>The _GeminiRateLimiter is annotated with the correct internal nodeid and outcome for each test scenario.</li>
                                            <li>The _parse_rate_limits function returns the correct number of requests per day.</li>
                                            <li>The mock_config.model is set to 'fallback' correctly after patching the provider._fetch_available_models function.</li>
                                            <li>The input limits logic (Flash vs Pro) works as expected, with the correct value being passed to the models.</li>
                                            <li>The _models attribute of the provider is correctly updated with the fallback models after patching the provider._ensure_models_and_limits function.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        821 input +
                                        238 output =
                                        1059 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">173 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181-182, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 254-255, 259, 340, 343, 346, 348-356, 358-361, 363-364, 366-367, 435, 437-439, 441-442, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-498, 502-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-564, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_parse_preferred_models_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProvider</p>
                                    <p><strong>Why Needed:</strong> To ensure the GeminiProvider correctly handles cases where the `model` parameter is not provided or is set to 'ALL'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_result': [], 'actual_result': ['[]', []]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        73 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 134-135, 137-141, 143-144, 524-527)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_prune_daily_requests</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProvider</p>
                                    <p><strong>Why Needed:</strong> To ensure the Gemini provider is correctly pruning daily requests that are older than 24 hours.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The length of limiter._daily_requests is equal to 0 after calling _prune(time.time())', 'expected_result': 0, 'actual_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        94 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 39-42, 81-82, 84, 87-89)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiCoverageGaps::test_tpm_available_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test_tpm_available_fallback function waits for a sufficient time before allowing token requests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the Gemini provider may not wait long enough for token requests to be processed after a previous request was made.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total remaining tokens should decrease by at least 30 seconds when the last requested token is used up.</li>
                                            <li>The function should return before `remaining` decreases below `tokens_used + 1` if `request_tokens <= limit`.</li>
                                            <li>If `request_tokens` is massive, the function should return immediately and not wait for a sufficient time.</li>
                                            <li>The remaining tokens should start at `tokens_used` when no requests are made.</li>
                                            <li>The function should handle cases where `request_tokens > limit` without returning prematurely.</li>
                                            <li>The test should pass even if `remaining + request_tokens <= limit` is true, indicating that the loop will not return.</li>
                                            <li>The last requested token should be used up before the function returns.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        524 input +
                                        220 output =
                                        744 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39-42)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_import_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_annotate_import_error function verifies when google-generativeai is not installed.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential import error caused by missing required dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `provider._annotate_internal` should return an error message indicating 'google-generativeai not installed' when the module is flagged as None in sys.modules.</li>
                                            <li>The function `provider._annotate_internal` should include the string 'google-generativeai' in its error message.</li>
                                            <li>The function `provider._annotate_internal` should raise a ValueError with the message 'google-generativeai not installed' when the module is not found in sys.modules.</li>
                                            <li>The function `provider._annotate_internal` should return None as expected when the module is flagged as None in sys.modules.</li>
                                            <li>The function `provider._annotate_internal` should include the nodeid and outcome of the test case in its error message.</li>
                                            <li>The function `provider._annotate_internal` should not raise an exception when the module is installed correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        259 input +
                                        224 output =
                                        483 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 134-135, 137-141, 143-144, 164-165, 167-169)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_no_token</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that annotation fails when token is missing from the environment.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the Gemini provider throws an error due to an unprovided GEMINI_API_TOKEN.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'GEMINI_API_TOKEN' key in the environment should be present.</li>
                                            <li>The error message should contain 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The annotation should fail with this error message when the token is missing.</li>
                                            <li>The provider should raise an exception instead of throwing a specific error.</li>
                                            <li>The error message should include the full path to the environment variable.</li>
                                            <li>The error message should be more informative than just 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The test should fail with this error message when the token is missing.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        178 output =
                                        491 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_rate_limit_retry</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider correctly annotates a rate limit retry scenario.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the GeminiProvider's ability to handle rate limit retries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by the provider matches the expected scenario.</li>
                                            <li>The mock_post call count is correct, indicating that the provider successfully retried the API after the first failure.</li>
                                            <li>The _parse_response method of the provider returns a Mock object with the correct scenario and error status code.</li>
                                            <li>The provider's internal state is updated correctly to reflect the retry attempt.</li>
                                            <li>The annotation does not contain any additional or incorrect information about the source.</li>
                                            <li>No other critical checks are performed by this test, but it ensures that the provider behaves as expected in this specific scenario.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        636 input +
                                        171 output =
                                        807 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">214 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-237, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_annotate_success</span>
                            <div class="test-meta">
                                <span>404ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the _annotate_success method returns a correct annotation when successful.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the GeminiProvider's _annotate_internal method, which may return an incorrect annotation if the response from _call_gemini is not in the expected format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation returned by _annotate_internal has the correct scenario 'Success Scenario'.</li>
                                            <li>The annotation does not have any error.</li>
                                            <li>The annotation's outcome is correctly set to 'passed'.</li>
                                            <li>_parse_response returns the correct text and tokens when called with a successful response from _call_gemini.</li>
                                            <li>The _build_prompt method is not mocked, which could potentially cause issues if it has complex dependencies.</li>
                                            <li>_annotate_internal calls _parse_response where the expected format is used.</li>
                                            <li>The annotation's error is None when it should be an error.</li>
                                            <li>The annotation's outcome is correctly set to 'passed' even though there was no error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        649 input +
                                        212 output =
                                        861 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">208 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-568, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProvider::test_availability</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verifies that the GeminiProvider class correctly checks for availability based on environment variables.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the provider may not be available due to missing or incorrect environment variables.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `GeminiProvider` instance is created with the correct `provider` set to 'gemini' when environment variable 'GEMINI_API_TOKEN' is present.</li>
                                            <li>The `_check_availability()` method returns False when environment variable 'GEMINI_API_TOKEN' is not present.</li>
                                            <li>The `_check_availability()` method returns True when environment variable 'GEMINI_API_TOKEN' is present and correct.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        235 input +
                                        147 output =
                                        382 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 134-135, 137-141, 143-144, 332-333, 335)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_exceptions</span>
                            <div class="test-meta">
                                <span>60.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider class correctly handles retry exceptions and model exhaustion when calling _annotate_internal with a mock ResourceExhausted exception.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the GeminiProvider class, where it may not handle retry exceptions or model exhaustion correctly when calling _annotate_internal.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the provider's _model_exhausted_at dictionary contains 'm1' after a mock ResourceExhausted exception is raised.</li>
                                            <li>Verify that the provider's _cooldowns dictionary contains 'm1' after a mock ResourceExhausted exception is raised and the cooldown period exceeds 5.5 seconds.</li>
                                            <li>Verify that the provider correctly handles retry after cleanup by checking if the cooldown period for 'm1' has exceeded 5.5 seconds.</li>
                                            <li>Verify that the provider's _rate_limiters are properly set up to avoid network calls when calling _get_rate_limiter -> _ensure_rate_limits.</li>
                                            <li>Verify that the provider raises a MockResourceExhausted exception with the correct message and error code when calling _call_gemini.</li>
                                            <li>Verify that the provider correctly handles model exhaustion by checking if 'm1' is in the _model_exhausted_at dictionary after a mock ResourceExhausted exception is raised.</li>
                                            <li>Verify that the provider's cooldowns are properly set up to handle retry after cleanup.</li>
                                            <li>Verify that the provider does not raise an error when calling _call_gemini with a mock ResourceExhausted exception.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        651 input +
                                        317 output =
                                        968 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 221-224, 228-230, 232-233, 235-237, 239-244, 263-265, 268, 272-276, 279-281, 283-286, 288-292, 318-320, 322-323, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_annotate_retry_loop_coverage</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the GeminiProvider correctly clears _model_exhausted_at when annotating with a successful call to _call_gemini.</p>
                                    <p><strong>Why Needed:</strong> The test prevents regression where the _model_exhausted_at is not cleared after a successful annotation, potentially leading to incorrect assertions in other tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>provider._model_exhausted_at[model] = None</li>
                                            <li>provider._models[model] == [model]</li>
                                            <li>provider._rate_limiters[model].next_available_in.return_value == 0</li>
                                            <li>mock_call.return_value[0][0] == 'response'</li>
                                            <li>mock_call.return_value[1][0] == LlmTokenUsage(10, 10, 20)</li>
                                            <li>assert mock_limiter.next_available_in.called_once_with(0)</li>
                                            <li>assert provider._rate_limiters[model].next_available_in.called_once_with(0)</li>
                                            <li>assert provider._model_exhausted_at[model] is None</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        482 input +
                                        210 output =
                                        692 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-94, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 254, 259, 340, 343, 471-473)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_ensure_rate_limits_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProviderDetailed::test_ensure_rate_limits_error</p>
                                    <p><strong>Why Needed:</strong> To test that the ` GeminiProvider` raises an exception when rate limiting is attempted with a non-numeric value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected error to be raised', 'description': 'The test should expect an exception to be raised when attempting to limit rate with a non-numeric value.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        100 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 134-135, 137-141, 143-144, 346, 348-356, 358-361, 363-364, 366-367)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestGeminiProviderDetailed.test_fetch_available_models_error</p>
                                    <p><strong>Why Needed:</strong> To test the error handling of fetching available models when a network error occurs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'models', 'expected_value': [], 'type': 'list'}</li>
                                            <li>{'name': 'limit_map', 'expected_value': {}, 'type': 'dict'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        98 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_fetch_available_models_invalid_json</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fetching available models with invalid JSON data prevents a bug related to model validation.</p>
                                    <p><strong>Why Needed:</strong> This test verifies that the GeminiProvider class correctly handles invalid JSON input when fetching available models.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'm1' model should not be included in the list of available models.</li>
                                            <li>The 'm2' model should not be included in the list of available models.</li>
                                            <li>The 'm3' model should be included in the list of available models.</li>
                                            <li>The 'inputTokenLimit' field of the 'm3' model should match the expected value.</li>
                                            <li>The 'supportedGenerationMethods' field of the 'm3' model should only contain 'generateContent'.</li>
                                            <li>The 'limitMap' dictionary should not contain the 'm1', 'm2', or 'm3' models.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        187 output =
                                        527 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 476-477, 537, 539-543, 547-548, 550-559, 562-563, 567, 569, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_get_max_context_tokens_calls_ensure</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_get_max_context_tokens_calls_ensure</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method of the GeminiProvider class calls the mock function correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_ensure was called once', 'expected_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        91 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 65-66, 163)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 134-135, 137-141, 143-144, 486, 488-491, 493)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_parse_rate_limits_types</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiProviderDetailed::test_parse_rate_limits_types</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the GeminiProvider can correctly parse rate limits from a JSON configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.requests_per_minute', 'expected_value': 'None'}</li>
                                            <li>{'name': 'config.tokens_per_minute', 'expected_value': 100}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        156 input +
                                        103 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 134-135, 137-141, 143-144, 449-457, 459-460, 463-466)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_prune_logic</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `prune_logic` method correctly removes old requests and updates token usage when a new request is added.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the `prune_logic` method, which may cause outdated data to be returned for existing requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `_request_times` should be equal to 1 after pruning.</li>
                                            <li>The length of `_token_usage` should be equal to 1 after pruning.</li>
                                            <li>The value of `now - 10.0` in `_request_times[0]` should match the current time.</li>
                                            <li>_request_times[-1] == now - 61.0</li>
                                            <li>_token_usage[-1][0] == now - 61.0</li>
                                            <li>_token_usage[-1][1] == 10</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        323 input +
                                        180 output =
                                        503 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 39-42, 81-85, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_record_tokens_invalid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_gemini_provider.py::TestGeminiRateLimiter::test_record_tokens_invalid</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the rate limiter is not correctly handling invalid token records.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'len(limiter._token_usage) == 0', 'expected_result': 0, 'actual_result': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        95 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39-42, 66-67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpd_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the rate limiter does not exceed the limit when no requests are made.</p>
                                    <p><strong>Why Needed:</strong> The test ensures that the rate limiter does not allow more requests than allowed by the configuration, which would result in a 'RateLimitExceeded' error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'limiter.record_request() should not be called when no requests are made', 'expected_result': 'None'}</li>
                                            <li>{'name': 'next_available_in() should return None for 100 requests', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        133 output =
                                        262 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 45-46, 48-50, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_rpm_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter does not block the third request after two successful requests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the third request is blocked due to insufficient available time for subsequent requests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `next_available_in` method returns 0.0 when there are no more available slots.</li>
                                            <li>The `next_available_in` method returns a value between 0 and 60.0 when there are still available slots.</li>
                                            <li>The `record_request` method is called before the third request waits for an available slot.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        130 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-97, 100-102)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_seconds_until_tpm_available_branches</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the rate limiter correctly handles requests exceeding the limit when there are no tokens available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the rate limiter does not properly handle scenarios where there are no tokens available and more than one minute has passed since the last request.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert wait > 0</li>
                                            <li>assert wait <= 60.0 + 1e-9</li>
                                            <li># Tokens have been exhausted, but usage is still within limit</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        377 input +
                                        114 output =
                                        491 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 100-101, 103-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_daily_limit_exceeded</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `wait_for_slot` method raises an exception when the daily limit is exceeded.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the rate limiter does not raise an exception when the daily limit is exceeded, potentially causing unexpected behavior or errors in downstream systems.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `wait_for_slot` method raises an instance of `_GeminiRateLimitExceeded` with the correct `limit_type` attribute.</li>
                                            <li>The `limit_type` attribute of the exception raised by `wait_for_slot` is set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        126 output =
                                        389 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 32-34, 39-42, 45-46, 48-50, 58-60, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_gemini_provider.py::TestGeminiRateLimiter::test_wait_for_slot_sleeps</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `wait_for_slot` method sleeps for a sufficient amount of time when waiting for an available slot.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the rate limiter does not sleep long enough to allow subsequent requests to wait their turn, potentially leading to performance issues or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>...</li>
                                            <li>...</li>
                                            <li>...</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        86 output =
                                        411 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 39-42, 58-59, 61-63, 73, 76-78, 81-82, 84, 87-88)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_hashing.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_different_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_different_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that different configurations of the Compute API produce different hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'compute_config_hash(config1) != compute_config_hash(config2)', 'expected_result': 'different'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        82 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeConfigHash::test_returns_short_hash</p>
                                    <p><strong>Why Needed:</strong> To ensure the computed hash is short and does not exceed 16 characters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'The length of the hash should be equal to 16'}</li>
                                            <li>{'message': 'The hash should not be longer than 16 characters'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        87 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-101, 103-104)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_consistent_with_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> File hashing consistency</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash of a file matches its content.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'file_hash', 'expected_value': 'content_hash'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        60 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 32, 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeFileSha256::test_hashes_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Hashing a file</p>
                                    <p><strong>Why Needed:</strong> To test the correctness of the hash computation function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The computed SHA-256 hash should be 64 bytes long.', 'expected_value': 64, 'actual_value': 0}</li>
                                            <li>{'description': 'The file contents should not be modified during the test.', 'expected_value': 'hello world', 'actual_value': 'hello world'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        114 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 44-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_different_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_different_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that different keys produce different signatures.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'different', 'actual': 'same'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        65 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeHmac::test_with_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeHmac::test_with_key</p>
                                    <p><strong>Why Needed:</strong> To verify the correctness of HMAC computation with a key.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected length of signature', 'value': 64}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        70 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 61)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_consistent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_consistent</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hash function is consistent and produces the same output for the same input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'hash': '...'}, 'actual': {'hash': '...'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        80 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestComputeSha256::test_length</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestComputeSha256::test_length</p>
                                    <p><strong>Why Needed:</strong> To ensure the length of the computed SHA-256 hash is 64 characters (64 hexadecimal digits).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The length of the hash should be equal to 64.', 'expected_result': 64}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        88 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</span>
                            <div class="test-meta">
                                <span>81ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_includes_pytest</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'pytest' package is included in the dependency snapshot.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'includes pytest package', 'description': "The 'pytest' package should be present in the dependency snapshot."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        86 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</span>
                            <div class="test-meta">
                                <span>82ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestGetDependencySnapshot::test_returns_dict</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_dependency_snapshot` function returns a dictionary as expected.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'snapshot is a dict', 'expected': 'dict', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        82 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 113-114, 116-121)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_loads_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_loads_key</p>
                                    <p><strong>Why Needed:</strong> To test that the hmac.load function correctly loads a key from a file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'my-secret-key\n', 'actual_value': '', 'error_message': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        82 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 73, 76-77, 80-81)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_missing_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_missing_key_file</p>
                                    <p><strong>Why Needed:</strong> The test should return None if the key file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Expected the function to return None when the key file does not exist.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        76 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 73, 76-78)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_hashing.py::TestLoadHmacKey::test_no_key_file</p>
                                    <p><strong>Why Needed:</strong> Because the test case requires a valid HMAC key to be loaded.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert is None', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        74 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/hashing.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 73-74)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_integration_gate.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">16 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_aggregation_defaults</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify aggregation configuration defaults.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where aggregation settings are not properly initialized with default values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>config.aggregate_dir is None</li>
                                            <li>config.aggregate_policy == 'latest'</li>
                                            <li>config.aggregate_include_history is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        70 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_capture_failed_output_default_true</p>
                                    <p><strong>Why Needed:</strong> The test captures failed output by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert config.capture_failed_output is True', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        73 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_context_mode_default_minimal</p>
                                    <p><strong>Why Needed:</strong> To ensure the context mode is set to 'minimal' by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.llm_context_mode', 'expected_value': 'minimal'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        77 output =
                                        184 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_llm_not_enabled_by_default</p>
                                    <p><strong>Why Needed:</strong> LLM is currently disabled by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_llm_enabled', 'expected_value': False, 'actual_value': 'not_llm_enabled'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        81 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 123, 171, 284, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_omit_tests_default_true</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks the default behavior of omitting tests from coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'config.omit_tests_from_coverage', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        80 output =
                                        189 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestConfigDefaults::test_provider_default_none</p>
                                    <p><strong>Why Needed:</strong> The provider is set to 'none' by default, which may not be suitable for all use cases.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>config.provider == 'none'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        64 output =
                                        165 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestConfigDefaults::test_secret_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Integration test of gate configuration</p>
                                    <p><strong>Why Needed:</strong> To ensure that secret files are excluded from the LLM context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Exclude secret files by default', 'description': "The function should exclude 'secret' files and '.env' files from the list of excludes."}</li>
                                            <li>{'name': 'Exclude .env files', 'description': ".env files are a common source of sensitive information, so it's essential to exclude them."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        118 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_deterministic_output</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the deterministic output of the integration gate is correctly reported.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the deterministic output may not be reported correctly due to changes in the test data or configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>nodeids are sorted by nodeid</li>
                                            <li>tests are passed</li>
                                            <li>output is deterministic</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        84 output =
                                        397 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_empty_test_suite</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that an empty test suite produces a valid report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case the test suite is empty.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of tests should be zero.</li>
                                            <li>The summary section should have no data.</li>
                                            <li>No error messages or warnings should be printed.</li>
                                            <li>The output file should not contain any report content.</li>
                                            <li>The report writer should not raise an exception when writing to a non-existent file.</li>
                                            <li>The test suite should not produce any invalid JSON data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        240 input +
                                        121 output =
                                        361 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_html_report_generation</span>
                            <div class="test-meta">
                                <span>45ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the full pipeline generates an HTML report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the pipeline does not generate an HTML report even when all tests pass.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file named `report.html` exists in the temporary directory.</li>
                                            <li>The string '<html>' is present in the content of the `report.html` file.</li>
                                            <li>The string 'test_pass' is present in the content of the `report.html` file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        108 output =
                                        378 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">118 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestFullPipeline::test_json_report_generation</span>
                            <div class="test-meta">
                                <span>67ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that a full pipeline generates a valid JSON report with the correct schema version, summary statistics, and skipped tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the integration gate by ensuring that the full pipeline correctly generates a JSON report with the expected structure and content.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'schema_version' key is present in the JSON report and has the correct value.</li>
                                            <li>The 'summary' key contains the correct total, passed, failed, and skipped counts.</li>
                                            <li>The 'passed', 'failed', and 'skipped' keys contain the expected values for each type of test.</li>
                                            <li>The number of tests with a status of 'skipped' is equal to the number of tests that were not executed (i.e., 'skipped' tests).</li>
                                            <li>The total count of all tests is 3, as specified in the test results.</li>
                                            <li>The passed count is 1, as specified in the test results.</li>
                                            <li>The failed count is 1, as specified in the test results.</li>
                                            <li>The skipped count is 1, as specified in the test results.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        240 output =
                                        659 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/_git_info.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 2-3)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">138 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_report_root_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests ReportRoot has required fields.</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the report root contains all necessary fields for a valid schema.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>'schema_version' is present in `data`</li>
                                            <li>'run_meta' is present in `data`</li>
                                            <li>'summary' is present in `data`</li>
                                            <li>'tests' is present in `data`</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        250 input +
                                        92 output =
                                        342 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_aggregation_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> {'description': 'RunMeta has aggregation fields.', 'expected_result': {'schema': {'type': 'object', 'properties': {'is_aggregated': {'type': 'boolean'}, 'run_count': {'type': 'integer'}}}, 'assertions': [{'key_assertion': ['is_aggregated'], 'expected_result': True}, {'key_assertion': ['run_count'], 'expected_result': 0}]}}</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the RunMeta object does not have an 'aggregation_fields' property. The presence of this property in the schema indicates that aggregation fields are required for a RunMeta object to be valid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'is_aggregated', 'expected_result': True}</li>
                                            <li>{'name': 'run_count', 'expected_result': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        246 output =
                                        382 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_run_meta_has_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'RunMeta has run status fields' verifies that the RunMeta object contains status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the RunMeta object is missing required status fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' field should be present in the data.</li>
                                            <li>The 'interrupted' field should be present in the data.</li>
                                            <li>The 'collect_only' field should be present in the data.</li>
                                            <li>The 'collected_count' field should be present in the data.</li>
                                            <li>The 'selected_count' field should be present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        135 output =
                                        372 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_integration_gate.py::TestSchemaCompatibility::test_schema_version_defined</p>
                                    <p><strong>Why Needed:</strong> The schema version is defined to ensure compatibility with gate APIs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'SCHEMA_VERSION', 'type': 'string'}</li>
                                            <li>{'name': '.', 'type': 'boolean'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        87 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_integration_gate.py::TestSchemaCompatibility::test_test_case_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_case_has_required_fields' verifies that the TestCaseResult object has required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where a TestCaseResult object is created without all necessary fields (nodeid, outcome, duration).</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'nodeid' field should be present in the TestCaseResult object.</li>
                                            <li>The 'outcome' field should be present in the TestCaseResult object.</li>
                                            <li>The 'duration' field should be present in the TestCaseResult object.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        116 output =
                                        339 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_litellm_retry_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">4 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_all_retries_exhausted</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that all retries are exhausted when API calls fail.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where LiteLLMProvider fails to retry after exhausting all retries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `result` variable should be `None`.</li>
                                            <li>The `error` attribute of the `result` object should not be `None`.</li>
                                            <li>The `test_source` field of the `result` object should be an empty string.</li>
                                            <li>The `context_files` dictionary of the `result` object should be an empty dictionary.</li>
                                            <li>The `provider.annotate()` method should raise an exception when API calls fail.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        140 output =
                                        486 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_non_401_error_no_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that non-401 errors don't force token refresh.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of non-401 error without forcing token refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The API call should fail with a 500 status code.</li>
                                            <li>The annotation should contain an error message.</li>
                                            <li>The annotation should not have any retries set.</li>
                                            <li>The number of retries should be less than or equal to the maximum retries (1 in this case).</li>
                                            <li>No force refresh is triggered when the API call fails with a 500 status code.</li>
                                            <li>The test source does not contain any function that triggers token refresh.</li>
                                            <li>The context files are empty, which means no external dependencies are being refreshed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        367 input +
                                        159 output =
                                        526 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141, 144-145, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_retry_succeeds_after_transient_error</span>
                            <div class="test-meta">
                                <span>6.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that retry succeeds after transient error.</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLM can recover from transient errors and still complete successfully.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The API call is mocked to fail twice, then succeed with a successful response.</li>
                                            <li>The test scenario is asserted as 'test scenario'.</li>
                                            <li>The error message is None after the retry attempt.</li>
                                            <li>The LLM completes successfully with a valid response.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        433 input +
                                        102 output =
                                        535 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_litellm_retry_coverage.py::TestLiteLLMTokenRefreshRetry::test_token_refresh_on_401</span>
                            <div class="test-meta">
                                <span>6.40s</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 401 error triggers token refresh when API call fails first, then succeeds.</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLMTokenRefreshRetry test suite covers cases where the API call fails before a retry attempt.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The test verifies that the LLM is retried after a 401 error has been encountered.</li>
                                            <li>The test verifies that the LLM will not be retried if the API call succeeds first.</li>
                                            <li>The test verifies that the LLMTokenRefreshRetry test suite catches and reports the retry attempt.</li>
                                            <li>The test verifies that the LLMTokenRefreshRetry test suite ensures the token is refreshed after a 401 error has been encountered.</li>
                                            <li>The test verifies that the LLMTokenRefreshRetry test suite prevents regression in API call handling.</li>
                                            <li>The test verifies that the LLMTokenRefreshRetry test suite handles 401 errors correctly and does not retry without a valid token.</li>
                                            <li>The test verifies that the LLMTokenRefreshRetry test suite reports the retry attempt to the user or logs an error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        473 input +
                                        229 output =
                                        702 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-188, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_gemini_returns_provider</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the Gemini model requires a specific provider to be used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected': 'GeminiProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        80 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 65-66, 384, 386, 388, 391, 396, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_litellm_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLMProvider class is correctly instantiated when a specific provider is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.__class__.__name__', 'expected_value': 'LiteLLMProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        86 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_none_returns_noop</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_none_returns_noop</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the LLM's GetProvider method returns a NoopProvider when the provider is None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider should be NoneType', 'description': 'The provider returned by the GetProvider method should be NoneType.'}</li>
                                            <li>{'name': 'provider should not be an instance of LLMProvider', 'description': 'The provider returned by the GetProvider method should not be an instance of LLMProvider.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        138 output =
                                        253 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestGetProvider::test_ollama_returns_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the OllamaProvider is correctly returned when a specific provider is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'expected_value': 'OllamaProvider'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        154 input +
                                        80 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 384, 386, 388, 391-392, 394)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestGetProvider::test_unknown_raises</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 384, 386, 388, 391, 396, 401, 406)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestLlmProviderContract::test_noop_implements_interface</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that NoopProvider implements LlmProvider contract.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the NoopProvider does not implement all required methods of LlmProvider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>provider should have annotate method</li>
                                            <li>provider should have is_available method</li>
                                            <li>provider should have get_model_name method</li>
                                            <li>provider should have config attribute</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        90 output =
                                        322 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_annotate_returns_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the NoopProvider returns an empty annotation when no annotation is specified.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the NoopProvider does not return any annotation for a function with no annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>annotation is of type LlmAnnotation</li>
                                            <li>annotation scenario is an empty string</li>
                                            <li>annotation why_needed is an empty string</li>
                                            <li>annotation key_assertions are an empty list</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        249 input +
                                        103 output =
                                        352 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_get_model_name_empty</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the model name is not being returned correctly when an empty string is passed to get_model_name.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert get_model_name() == ''", 'expected_result': '', 'actual_result': 'NoopProvider.get_model_name()'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        114 input +
                                        100 output =
                                        214 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 67)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm.py::TestNoopProvider::test_is_available</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm.py::TestNoopProvider::test_is_available</p>
                                    <p><strong>Why Needed:</strong> The LLM is not available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider.is_available()', 'expected_value': True, 'actual_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        74 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 59)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_contract.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> This test is designed to ensure that the `ANNOTATION_JSON_SCHEMA` correctly requires certain fields.</p>
                                    <p><strong>Why Needed:</strong> The purpose of this test is to verify that the schema does not allow optional fields and that required fields are present.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'required', 'description': "The field 'scenario' must be present in the annotation.", 'type': 'assertion'}</li>
                                            <li>{'name': 'why_needed', 'description': 'The schema does not allow optional fields, and required fields are present.', 'type': 'assertion'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        160 output =
                                        275 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_from_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that AnnotationSchema.from_dict parses a dictionary correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents incorrect parsing of user data from a dict.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>checks password</li>
                                            <li>checks username</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        274 input +
                                        55 output =
                                        329 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> This test checks if the AnnotationSchema can handle an empty input.</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the AnnotationSchema requires a non-empty string for the scenario and why-neededs fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'schema.scenario', 'value': '', 'expected_value': ''}</li>
                                            <li>{'name': 'schema.why_needed', 'value': '', 'expected_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        108 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_handles_partial</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case for testing AnnotationSchema</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure the AnnotationSchema handles partial input correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "schema.scenario should be equal to 'Partial only'", 'expected_result': 'Partial only'}</li>
                                            <li>{'assertion': 'schema.why_needed should be empty', 'expected_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        98 output =
                                        217 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_has_required_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the schema has required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the schema is missing required fields, potentially leading to errors or inconsistencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'scenario' in ANNOTATION_JSON_SCHEMA['properties']</li>
                                            <li>assert 'why_needed' in ANNOTATION_JSON_SCHEMA['properties']</li>
                                            <li>assert 'key_assertions' in ANNOTATION_JSON_SCHEMA['properties']</li>
                                            <li>assert isinstance(ANNOTATION_JSON_SCHEMA, dict)</li>
                                            <li>assert len(ANNOTATION_JSON_SCHEMA) > 0</li>
                                            <li>assert all(key in ANNOTATION_JSON_SCHEMA for key in ['scenario', 'why_needed', 'key_assertions'])</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        157 output =
                                        372 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestAnnotationSchema::test_schema_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestAnnotationSchema::test_schema_to_dict verifies that the AnnotationSchema instance correctly serializes to a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the AnnotationSchema instance can be serialized and deserialized correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assertion 1: The 'scenario' key in the data dictionary matches the expected value.</li>
                                            <li>assertion 2: The 'why_needed' key in the data dictionary matches the expected value.</li>
                                            <li>assertion 3: The 'key_assertions' list in the data dictionary contains all expected assertions.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        129 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 90-92, 94-96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_from_factory</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the factory returns a NoopProvider for provider='none'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider', 'expected': 'None', 'got': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        86 output =
                                        204 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 65-66, 384, 386, 388-389)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestNoopProvider::test_noop_is_llm_provider</p>
                                    <p><strong>Why Needed:</strong> To ensure that the NoopProvider class correctly implements the LlmProvider interface.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'isinstance(provider, LlmProvider)', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        84 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestNoopProvider::test_noop_returns_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The NoopProvider returns an empty annotation when the test function does not have any annotations.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the NoopProvider incorrectly returns an empty annotation for tests with no annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result.scenario == "" (empty string)</li>
                                            <li>assert result.why_needed == "" (empty string)</li>
                                            <li>assert result.key_assertions == [] (no key assertions performed)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        104 output =
                                        357 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_annotate_returns_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `annotate` method returns a `TestCaseResult` object with the correct attributes.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the `annotate` method does not return an expected `TestCaseResult` object.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `result` attribute is present and has the correct name (`scenario`, `why_needed`, and `key_assertions`) on the `TestCaseResult` object.</li>
                                            <li>The `result` attribute has the correct type (e.g., a dictionary or an instance of `TestCaseResult`)</li>
                                            <li>The `outcome` attribute is set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        138 output =
                                        401 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_empty_code</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Provider handles empty code gracefully</p>
                                    <p><strong>Why Needed:</strong> Test case to ensure the provider can handle scenarios with empty code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The provider should return a valid TestCaseResult object even when the test has an empty code.', 'expected_result': "TestCaseResult(nodeid='test::nodeid', outcome='passed')", 'actual_result': {'nodeid': 'test::nodeid', 'outcome': 'passed'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        111 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_handles_none_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Provider handles None context gracefully</p>
                                    <p><strong>Why Needed:</strong> To ensure the provider can handle None context without throwing an error.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The annotate method should return a non-None result even when the test case has no outcome.', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        78 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 65-66, 87-89, 97-98, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 32, 51)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_contract.py::TestProviderContract::test_provider_has_annotate_method</p>
                                    <p><strong>Why Needed:</strong> To ensure that all providers have an annotate method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "has attribute 'annotate'", 'expected_result': 'True'}</li>
                                            <li>{'name': 'is callable on provider.annotate', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        96 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 65-66, 384, 386, 388-389, 391-392, 394, 396-397, 399, 401-402, 404)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 134-135, 137-141, 143-144)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/noop.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 32)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_providers.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">52 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_handles_context_too_large</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_handles_context_too_large</p>
                                    <p><strong>Why Needed:</strong> Because the annotation process is too resource-intensive for large contexts.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'expected_exception', 'message': 'An exception was raised when annotating a context that was too large.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        90 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">187 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 263-265, 299, 311-312, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 435, 437-439, 441-444, 449-452, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524-525, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLMProvider annotates a missing dependency correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider does not report an error for missing dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation message contains the correct error message indicating that 'litellm' is missing and how to install it.</li>
                                            <li>The annotation message includes the correct path to install 'litellm'.</li>
                                            <li>The annotation message includes the correct provider name ('litellm') in the error message.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        116 output =
                                        386 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-195, 471-473, 497-498, 502-503, 537)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_missing_token</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `annotate` method of a GeminiProvider object raises an error when no API token is provided.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the `annotate` method fails to raise an error when an API token is missing, allowing the test case to pass even if the provider is not properly configured.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `error` attribute of the annotation object should be set to 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The `annotation.error` attribute should contain the string 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The `provider.annotate` method should raise an error with the message 'GEMINI_API_TOKEN is not set' when no API token is provided.</li>
                                            <li>The `annotation.error` attribute should be a string containing the message 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The `annotation.error` attribute should contain the exact phrase 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The `provider.annotate` method should raise an exception with the specified error message when no API token is provided.</li>
                                            <li>The `annotation.error` attribute should be a string that starts with 'GEMINI_API_TOKEN is not set'.</li>
                                            <li>The `annotation.error` attribute should contain the exact phrase 'GEMINI_API_TOKEN is not set' followed by a colon and a space.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        440 input +
                                        295 output =
                                        735 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-188)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_records_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `annotate_records_tokens` test prevents regressions by ensuring tokens are recorded correctly.</p>
                                    <p><strong>Why Needed:</strong> To prevent regressions caused by a change in how token usage is handled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `.annotate` method of the `GeminiProvider` instance records the specified number and type of tokens.</li>
                                            <li>The `annotate_records_tokens` test verifies that the `annotate` method does not raise an exception when called with a valid input.</li>
                                            <li>The rate limits logic is tested to ensure it runs without error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        783 input +
                                        124 output =
                                        907 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 39-42, 45-46, 48, 52-54, 66, 68-70, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246-247, 249-252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-430, 432, 435, 437-439, 441-444, 449-455, 457, 459-460, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_retries_on_rate_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider can correctly handle rate limiting and retry logic.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocked API call with rate limit exceeded error', 'expected_output': {'error_code': 429, 'message': 'Rate limit exceeded'}, 'actual_output': {}}</li>
                                            <li>{'name': 'Mocked API call with retry logic executed', 'expected_output': {'retry_count': 1}, 'actual_output': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        128 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 32-34, 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 263-265, 299-300, 304-306, 308-309, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413-416, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_rotates_models_on_daily_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the model rotation is applied correctly on a daily limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'model_rotation', 'expected_value': 'True'}</li>
                                            <li>{'name': 'daily_limit', 'expected_value': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        100 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">210 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526-527, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_skips_on_daily_limit</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestGeminiProvider::test_annotate_skips_on_daily_limit</p>
                                    <p><strong>Why Needed:</strong> Because the `annotate` method is skipping annotations on a daily limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The annotate method should not skip any annotations when there are no annotations to skip.', 'expected_result': {}, 'actual_result': {}}</li>
                                            <li>{'name': 'The annotate method should skip all annotations when the daily limit is reached.', 'expected_result': {'annotations_skipped': []}, 'actual_result': {'annotations_skipped': ['annotation_1', 'annotation_2']}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        98 input +
                                        151 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">216 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider annotates a successful response with the correct key assertions and confidence level.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring the annotation is accurate for valid responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>status ok</li>
                                            <li>redirect</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        474 input +
                                        65 output =
                                        539 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">209 lines (ranges: 39-42, 45-46, 48-49, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-101, 103, 105, 107-109, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-466, 471-473, 476-478, 497-498, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_exhausted_model_recovers_after_24h</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> The LLM provider's model should recover from being exhausted after 24 hours.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'model recovered within 24h', 'description': 'The model should be available and functional again after 24 hours.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        81 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">222 lines (ranges: 39-42, 45-46, 48-50, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-210, 212-213, 215-216, 218, 222-230, 232-233, 235-236, 239-244, 246, 249-250, 252, 261, 318-320, 340-343, 346-349, 352-356, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457, 459, 461-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_fetch_available_models_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `fetch_available_models` method raises an error when no models are available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected a KeyError to be raised', 'description': 'When no models are available, the `fetch_available_models` method should raise a KeyError.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        89 output =
                                        181 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 134-135, 137-141, 143-144, 346, 348-349, 352-356, 358-361, 363-364, 366-367, 435, 437-439, 441-444, 449-452, 463-466, 476, 478, 497-498, 502-508, 511, 514-516, 518-521, 524-525, 537, 539-541, 544-545)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestGeminiProvider::test_model_list_refreshes_after_interval</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for LLM providers</p>
                                    <p><strong>Why Needed:</strong> To ensure that the model list refreshes after a specified interval.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Model list should be refreshed after interval', 'description': 'The model list should be updated with new data after the specified interval.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        78 output =
                                        174 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/gemini.py</span>
                                        <span style="color: var(--text-secondary)">201 lines (ranges: 39-42, 45-46, 48, 52-54, 73, 76-78, 81-82, 84, 87-88, 92-93, 95-96, 100-102, 134-135, 137-141, 143-144, 164-166, 173-175, 178, 181, 184, 186-187, 189, 191-192, 198-206, 208-209, 222-224, 228-230, 232, 235-236, 239-244, 246, 249-250, 252, 261, 340-343, 346-349, 352, 358-361, 363-364, 366-367, 383, 385-388, 390-403, 406, 410-411, 413, 418-422, 424-425, 432, 435, 437-439, 441-444, 449-455, 457-458, 463-466, 471-473, 476-478, 497-499, 502-505, 507-508, 511, 514-516, 518-521, 524, 526, 528-531, 537, 539-543, 547-548, 550-552, 554-555, 557-559, 562-563, 567, 569-571, 574)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_401_retry_with_token_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider retries on 401 after refreshing token.</p>
                                    <p><strong>Why Needed:</strong> Reason: The current implementation does not retry when the token is refreshed, causing a failure in test_401_retry_with_token_refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the provider retries after refreshing the token.</li>
                                            <li>Verify that the first failed attempt is due to a 401 Unauthorized error.</li>
                                            <li>Verify that the second successful attempt is obtained with the refreshed token.</li>
                                            <li>Verify that the captured keys match the expected values (token-1 and token-2).</li>
                                            <li>Verify that the provider correctly sets the `litellm_token_refresh_command` and `litellm_token_refresh_interval` attributes.</li>
                                            <li>Verify that the `fake_completion` function is called with a valid API key for the first attempt, and an error for the second attempt.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        580 input +
                                        186 output =
                                        766 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_handles_completion_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider annotates completion errors correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the provider does not surface completion errors in annotations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation should contain an error message indicating a completion error.</li>
                                            <li>The error message should contain the string 'boom'.</li>
                                            <li>The annotation should raise a RuntimeError exception when trying to annotate a test with a completion error.</li>
                                            <li>The provider should be able to surface completion errors in annotations by setting the litellm module in sys.modules.</li>
                                            <li>The config should be created with the correct provider (in this case, LiteLLMProvider).</li>
                                            <li>The LiteLLMProvider should create an instance of SimpleNamespace with a completion function set to fake_completion.</li>
                                            <li>The annotation should contain the correct key ('def test_case(): assert True').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        188 output =
                                        495 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider rejects invalid key_assertions payloads.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression and ensure the correct behavior of LiteLLMProvider when receiving invalid key_assertions payloads.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'response_data' dictionary should be a list.</li>
                                            <li>The 'response_data' dictionary should contain only string keys.</li>
                                            <li>Invalid response: key_assertions must be a list</li>
                                            <li>The 'response_data' dictionary should not have any non-string keys.</li>
                                            <li>The 'response_data' dictionary should not have any non-string values.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        135 output =
                                        481 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 206, 211)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_missing_dependency</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The LiteLLMProvider annotates the missing dependency 'litellm' in the test case.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the provider reports an error due to a missing required library, causing the test to fail or produce incorrect results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error == 'litellm not installed. Install with: pip install litellm'</li>
                                            <li>assert annotation.provider is None</li>
                                            <li># The provider should be None when annotating a missing dependency</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        271 input +
                                        116 output =
                                        387 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 37-38, 41, 82-86)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_success_with_mock_response</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLMProvider annotates a valid response payload successfully.</p>
                                    <p><strong>Why Needed:</strong> Prevents regressions by ensuring the annotation is correct for successful responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>status ok</li>
                                            <li>redirect</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        475 input +
                                        61 output =
                                        536 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLMProvider overrides the prompt when provided.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM provider uses the custom prompt instead of the default one.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'prompt_override' key in the annotation should be set to 'CUSTOM PROMPT'.</li>
                                            <li>The content of the 'messages' field in the captured messages should match the expected value.</li>
                                            <li>The error message should not have any issues or warnings.</li>
                                            <li>The custom prompt should override the default one used by LiteLLMProvider.</li>
                                            <li>The key 'why_needed' in the annotation should contain the expected message.</li>
                                            <li>The key 'key_assertions' in the annotation should contain the expected assertion.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        159 output =
                                        532 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test LiteLLM provider to annotate with token usage.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in token usage extraction from responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `token_usage` attribute of the annotation returned by `provider.annotate(test, 'src')` is not None.</li>
                                            <li>The value of `prompt_tokens` in `annotation.token_usage` is set to 100.</li>
                                            <li>The value of `completion_tokens` in `annotation.token_usage` is set to 50.</li>
                                            <li>The total number of tokens extracted from the response is 150.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        127 output =
                                        553 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196-201, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_base_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLM provider passes `api_base` to completion call.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case where `api_base` is not set correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `api_base` should be 'https://proxy.corp.com/v1'.</li>
                                            <li>The `litellm_api_base` attribute should have been updated with the correct value.</li>
                                            <li>The `api_base` key in the response data should match the expected value.</li>
                                            <li>The `key_assertions` list should contain only one assertion.</li>
                                            <li>The `response_data` dictionary should have a single key-value pair.</li>
                                            <li>The `json.dumps(response_data)` function should return a string representation of the dictionary.</li>
                                            <li>The `FakeLiteLLMResponse` class should create a response object with the expected data.</li>
                                            <li>The `litellm_api_base` attribute of the `FakeLiteLLMResponse` object should be set to 'https://proxy.corp.com/v1'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        387 input +
                                        222 output =
                                        609 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182-183, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_api_key_passthrough</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider passes a static API key to the completion call.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in passing an API key through the completion call, ensuring consistent behavior with previous tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the captured API key matches the expected value.</li>
                                            <li>Check if the `litellm_api_key` attribute of the `fake_litellm` object is set to 'static-key-placeholder'.</li>
                                            <li>Verify that the `response_data` dictionary contains the expected keys ('scenario', 'why_needed', and 'key_assertions').</li>
                                            <li>Check if the `response_data` dictionary has a key named 'api_key' with value 'static-key-placeholder'.</li>
                                            <li>Verify that the `FakeLiteLLMResponse` object created by `fake_completion` returns a JSON response with the expected structure.</li>
                                            <li>Check if the captured API key is not set to an empty string or None.</li>
                                            <li>Verify that the `litellm_api_key` attribute of the `config` object has been updated correctly.</li>
                                            <li>Check if the `provider` object created by `LiteLLMProvider` has a valid `litellm_api_key` attribute.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        384 input +
                                        260 output =
                                        644 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_error_without_refresher</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLM provider returns an authentication error when no refresher is configured.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider does not raise an exception for authentication errors without token refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `fake_completion` raises a `FakeAuthError` exception with message '401 Unauthorized'.</li>
                                            <li>The error message returned by the LiteLLMProvider is 'Authentication failed'.</li>
                                            <li>The test case passes if the annotation of the provider contains an error message.</li>
                                            <li>The error message is not None.</li>
                                            <li>The error message contains the string 'Authentication failed'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        338 input +
                                        141 output =
                                        479 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">36 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 132-133, 170-174, 176-178, 182, 186-187, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_auth_retry_fails_on_second_attempt</span>
                            <div class="test-meta">
                                <span>2.00s</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the LiteLLMProvider reports an authentication error when retrying after a second failure.</p>
                                    <p><strong>Why Needed:</strong> To prevent the test from passing if the LiteLLMProvider fails to report an authentication error on subsequent retries.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The provider should raise an AuthenticationError with message 'Authentication failed' when the refresh operation fails.</li>
                                            <li>The provider should set the annotation.error attribute to a string containing 'Authentication failed'.</li>
                                            <li>The provider's completion function should not be called after a second failure.</li>
                                            <li>The provider's authentication error should be raised with a message of 'Authentication failed'.</li>
                                            <li>The provider's auth error should contain the token as an attribute.</li>
                                            <li>The provider's refresh command should return a non-zero exit code when the auth error is raised.</li>
                                            <li>The provider's llm_max_retries attribute should not be exceeded after a second failure.</li>
                                            <li>The test case should fail if the LiteLLMProvider does not raise an AuthenticationError on subsequent retries.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        419 input +
                                        218 output =
                                        637 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">51 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 122, 124-127, 129-130, 132-133, 141-142, 170-174, 176-178, 182, 186-188, 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_context_too_long_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider class handles a context too long error correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider throws an exception when given an invalid response containing a key assertion with no value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error is not None</li>
                                            <li>assert 'Context too long for this model' in str(annotation)</li>
                                            <li>assert 'scenario' in str(annotation)</li>
                                            <li>assert 'why_needed' in str(annotation)</li>
                                            <li>assert 'key_assertions' in str(annotation)</li>
                                            <li>assert 'error' in str(annotation)</li>
                                            <li>assert 'json.dumps(...)' in str(annotation)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        370 input +
                                        144 output =
                                        514 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 37-38, 41)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_dict_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_dict_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM provider correctly handles dict format from get_max_tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 16384, 'actual_value': 16384}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        218 input +
                                        84 output =
                                        302 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227-228, 230-231)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure the LLM provider returns a valid JSON response when an error occurs.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected JSON response', 'value': {'scenario': 'tests/test_llm_providers.py', 'why_needed': 'To ensure the LLM provider returns a valid JSON response when an error occurs.'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        98 output =
                                        199 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 37-38, 41, 221-222, 224, 227, 232-234)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_get_max_context_tokens_success</p>
                                    <p><strong>Why Needed:</strong> To test the get_max_context_tokens method of LiteLLMProvider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected return value', 'value': 8192, 'description': 'The expected return value of get_max_context_tokens should be 8192.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        99 output =
                                        312 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 37-38, 41, 221-222, 224, 227-229)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestLiteLLMProvider::test_is_available_with_module</p>
                                    <p><strong>Why Needed:</strong> To ensure the LiteLLM provider can detect installed modules.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'fake_litellm', 'expected_type': 'SimpleNamespace'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        160 input +
                                        78 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 65-66, 134, 137-138)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 37-38, 41, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_token_refresh_integration</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the LiteLLMProvider's token refresh integration.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a potential bug where the TokenRefresher is not able to refresh tokens for a long time, causing the LLM provider to fail to authenticate.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the 'api_key' attribute of the case result matches the expected token value.</li>
                                            <li>Check if the 'why_needed' key in the test result contains the correct reason for the bug.</li>
                                            <li>Verify that the 'key_assertions' list in the test result includes the expected assertion.</li>
                                            <li>Check if the captured data from the subprocess is correctly updated with the fake completion function call.</li>
                                            <li>Verify that the subprocess returns a CompletedProcess object with returncode 0 and stdout 'dynamic-token-789'.</li>
                                            <li>Check if the subprocess returns an empty string for stderr.</li>
                                            <li>Verify that the config object passed to the provider has the correct values.</li>
                                            <li>Check if the provider is correctly set up to use the fake LitellmResponse object.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        442 input +
                                        222 output =
                                        664 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">41 lines (ranges: 37-38, 41-42, 44-48, 60-61, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-188, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestLiteLLMProvider::test_transient_error_retry</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the LiteLLMProvider retries transient errors and passes with the correct number of calls.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the provider fails to retry on transient errors, potentially leading to unexpected behavior or failures in critical applications.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the provider raises ConnectionError when it encounters a network error.</li>
                                            <li>Verify that the provider retries at least once before raising an exception.</li>
                                            <li>Verify that the provider does not raise an exception for non-network errors (e.g., authentication errors).</li>
                                            <li>Verify that the provider returns a successful response with a specific JSON payload after retrying transient errors.</li>
                                            <li>Verify that the test passes with the correct number of calls (3) when encountering 2 failures and 1 success.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        171 output =
                                        597 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95, 98, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 139, 141-142, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_fallbacks_on_context_length_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider correctly handles context length errors during annotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'Context Length Error', 'expected_result': 'A fallback strategy should be applied to handle context length errors.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        79 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">70 lines (ranges: 65-66, 87-89, 97-99, 101, 103, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 243, 245, 264, 266-267, 270-272, 274, 277, 279-280, 283, 286, 290-291, 294-295, 298-299, 305, 307-308, 312, 314, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 85-86, 92, 138, 140, 142-144, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_handles_call_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test OllamaProvider::test_annotate_handles_call_error verifies that the annotate method handles call errors by returning an appropriate error message.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the annotation fails with a generic 'Failed after X retries. Last error: <error>' when a call to Ollama raises an exception.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation should return an error message indicating that the annotation failed due to a call error.</li>
                                            <li>The error message should include the last error raised by Ollama.</li>
                                            <li>The error message should indicate that the annotation was unable to handle the call error within the specified retries.</li>
                                            <li>The error message should not be generic but specific to the call error.</li>
                                            <li>The annotation should raise an exception when a call to Ollama raises an exception.</li>
                                            <li>The annotation should log or report the call error in some way.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        347 input +
                                        193 output =
                                        540 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 65-66, 87-89, 97-99, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">18 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 97-98, 100-101, 103-104)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_missing_httpx</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The Ollama provider should report an error when the httpx dependency is missing.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the provider incorrectly reports a missing dependency without providing any useful information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert annotation.error == 'httpx not installed. Install with: pip install httpx'</li>
                                            <li>assert annotation.nodeid == 'tests/test_sample.py::test_case'</li>
                                            <li>assert annotation.outcome == 'passed'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        268 input +
                                        105 output =
                                        373 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 65-66, 87-89, 97-99, 105)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 42-46)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_runtime_error_immediate_fail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM provider can correctly annotate runtime errors and immediately fail.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'LLM provider should return a JSON response with the expected key assertions', 'value': {'scenario': 'tests/test_llm_providers.py', 'why_needed': 'To ensure that the LLM provider can correctly annotate runtime errors and immediately fail.'}}</li>
                                            <li>{'name': 'JSON response should contain the correct keys', 'value': {'scenario': 'tests/test_llm_providers.py', 'why_needed': 'To ensure that the JSON response is correctly formatted and contains the expected keys.'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        162 output =
                                        261 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">22 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-65, 94, 96)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_success_full_flow</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the Ollama provider's full annotation flow with mocked HTTP responses.</p>
                                    <p><strong>Why Needed:</strong> Prevents authentication-related bugs in the Ollama provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the response status code is 200 (OK) and contains a JSON object with the expected scenario, why-need, and key assertions.</li>
                                            <li>Check if the token is valid by validating its presence and correctness in the response.</li>
                                            <li>Ensure that the response includes the required 'response' field in the JSON structure.</li>
                                            <li>Verify that the 'scenario', 'why-need', and 'key_assertions' fields are present in the response as expected.</li>
                                            <li>Test that the provider correctly raises an exception for a 401 Unauthorized status code when attempting to login with invalid credentials.</li>
                                            <li>Check if the error message is properly formatted and contains relevant information about the authentication process.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        414 input +
                                        190 output =
                                        604 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_prompt_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LiteLLM provider uses prompt_override when provided.</p>
                                    <p><strong>Why Needed:</strong> To ensure the correct behavior of the LiteLLM provider, where it overrides prompts with custom ones.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The annotation should not contain any error messages.</li>
                                            <li>The custom prompt should be included in the output messages.</li>
                                            <li>The custom prompt should override the original prompt specified in the config.</li>
                                            <li>The custom prompt should be present in the LiteLLM response.</li>
                                            <li>The custom prompt should have a content that is different from the original prompt.</li>
                                            <li>The custom prompt should not cause any error messages to be generated.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        373 input +
                                        141 output =
                                        514 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 42-43, 49, 52-53, 58, 60-61, 63-67, 71-72, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_annotate_with_token_usage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the `annotate` method of `LiteLLMProvider` with token usage data.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in handling token usage from LiteLLM responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `token_usage` attribute is populated with correct values.</li>
                                            <li>The `prompt_tokens` value matches the expected number of tokens (100).</li>
                                            <li>The `completion_tokens` value matches the expected number of tokens (50).</li>
                                            <li>The `total_tokens` value matches the expected total number of tokens (150).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        123 output =
                                        549 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 65-66, 87-89, 97-98, 105, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 264, 266-267, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 42-43, 49, 52, 55, 58, 60-61, 63-67, 71, 74-80, 83, 92, 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Ollama provider makes correct API call when calling OLLAMA successfully.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where OLLAMA fails to make the API call with a valid response.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'response' key in the result dictionary should be equal to 'test response'.</li>
                                            <li>The 'url' key in the captured dictionary should match the URL of the API call.</li>
                                            <li>The 'json' key in the captured dictionary should contain the expected JSON data.</li>
                                            <li>The 'model' key in the captured dictionary should be set to the correct model name.</li>
                                            <li>The 'prompt' key in the captured dictionary should be equal to the provided prompt.</li>
                                            <li>The 'system' key in the captured dictionary should be equal to the provided system prompt.</li>
                                            <li>The 'stream' key in the captured dictionary should be False (indicating no stream is being generated).</li>
                                            <li>The 'timeout' key in the captured dictionary should match the expected timeout value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        470 input +
                                        217 output =
                                        687 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_call_ollama_uses_default_model</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Ollama provider uses default model when not specified.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the Ollama provider defaults to the 'llama3.2' model even if no model is provided in the config.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The captured JSON response contains the expected default model.</li>
                                            <li>The captured JSON response does not contain any custom model specified by the user.</li>
                                            <li>The captured JSON response has a 'model' key with value 'llama3.2'.</li>
                                            <li>The captured JSON response does not have a 'model' key or its value is different from 'llama3.2'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        344 input +
                                        145 output =
                                        489 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 190, 192-200, 204-207, 209, 211-212)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestOllamaProvider::test_check_availability_failure</p>
                                    <p><strong>Why Needed:</strong> The test checks if the Ollama provider correctly returns False when the server is unavailable.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider._check_availability() should return False', 'expected_value': False, 'actual_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        183 input +
                                        87 output =
                                        270 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 113-114, 116-117, 119-120)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_non_200</p>
                                    <p><strong>Why Needed:</strong> The test checks if the Ollama provider returns False for non-200 status codes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider._check_availability() is False', 'expected_value': False, 'message': 'Expected provider._check_availability() to return False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        197 input +
                                        104 output =
                                        301 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_check_availability_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the Ollama provider checks availability successfully by making a GET request to /api/tags.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case the API endpoint changes or is down, ensuring the Ollama provider can still function correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The response status code should be 200 (OK).</li>
                                            <li>The URL '/api/tags' should be present in the request URL.</li>
                                            <li>A valid HTTP response from the server should be received.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        296 input +
                                        113 output =
                                        409 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 113-114, 116-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_context_length_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method returns the correct context length key for a given scenario.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'context_length_key', 'expected_value': 'max_context_tokens'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        76 output =
                                        175 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_fallback_on_error</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To handle cases where the maximum context tokens are exceeded during training.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'The maximum number of context tokens is exceeded. This may be due to various reasons such as insufficient memory, excessive model complexity or incorrect hyperparameter settings.', 'expected_value': 1000}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        92 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 138, 140, 142-147, 175-176, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_model_info</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_max_context_tokens` method returns the correct number of context tokens for a given model info.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 32, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        84 output =
                                        183 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 138, 140, 142-147, 149-150, 156, 165-167, 172-173)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_from_parameters</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for LLM providers</p>
                                    <p><strong>Why Needed:</strong> To ensure the correct number of context tokens is returned from the `get_max_context_tokens_from_parameters` method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'max_context_tokens', 'expected_value': 32, 'actual_value': 0}</li>
                                            <li>{'name': 'context_token_type', 'expected_value': 'text', 'actual_value': 'token'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        97 input +
                                        97 output =
                                        194 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">15 lines (ranges: 138, 140, 142-147, 149-150, 156, 158, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_non_200_status</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_get_max_context_tokens_non_200_status</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the `get_max_context_tokens` method returns a status of 200 when there are less than 200 context tokens, but it should return an error message instead.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'status code', 'expected': 200, 'actual': 'None'}</li>
                                            <li>{'name': 'error message', 'expected': 'Error: max_context_tokens exceeded', 'actual': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        140 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 138, 140, 142-147, 149, 178)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_is_local_returns_true</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider always returns `is_local=True`.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'provider is not None', 'expected_result': 'True'}</li>
                                            <li>{'name': 'provider.is_local() is True', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        104 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/ollama.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 128)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Ollama provider reports invalid JSON responses</p>
                                    <p><strong>Why Needed:</strong> To ensure the Ollama provider correctly handles and reports invalid JSON responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'annotation.error', 'value': 'Failed to parse LLM response as JSON'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        73 output =
                                        211 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 65-66, 325-326, 329-331)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-52, 55)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_invalid_key_assertions</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> {'description': 'Test case for Ollama provider when invalid key_assertions are provided in the response data.', 'expected_output': {'error': 'Invalid response: key_assertions must be a list'}}</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the Ollama provider correctly handles invalid key_assertions payloads in its responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'test_parse_response_invalid_key_assertions', 'description': 'Test case for Ollama provider when invalid key_assertions are provided in the response data.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        174 input +
                                        209 output =
                                        383 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346-348)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_code_fence</p>
                                    <p><strong>Why Needed:</strong> To ensure that the Ollama provider correctly extracts JSON from markdown code fences.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'JSON is present in response', 'expected': 'The response contains a valid JSON string.'}</li>
                                            <li>{'name': 'JSON is properly formatted', 'expected': 'The JSON string is properly formatted and consistent with the expected format.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        127 input +
                                        121 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_json_in_plain_fence</p>
                                    <p><strong>Why Needed:</strong> to test the parsing of JSON responses from plain markdown fences (no language)</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'response is a string', 'expected': 'str', 'actual': 'response'}</li>
                                            <li>{'name': 'response contains an opening brace', 'expected': 'True', 'actual': '<br/>'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        118 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 38, 42-44, 46-47)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_providers.py::TestOllamaProvider::test_parse_response_success</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the Ollama provider's ability to parse valid JSON responses.</p>
                                    <p><strong>Why Needed:</strong> Prevents bugs in the LLM providers by ensuring that they correctly identify and extract relevant information from JSON responses.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert a is not None</li>
                                            <li>assert b is not None</li>
                                            <li>assert 'scenario' in annotation.scenario</li>
                                            <li>assert 'why_needed' in annotation.why_needed</li>
                                            <li>assert 'key_assertions' in annotation.key_assertions</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        292 input +
                                        113 output =
                                        405 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 65-66, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_llm_utils.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">6 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_constrained</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify water-fill algorithm satisfies smaller files first.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the algorithm does not satisfy the constraint of distributing tokens to smaller files first due to insufficient budget.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total content allocated to `small.py` should be approximately equal to its required content plus overhead.</li>
                                            <li>The total content allocated to `large.py` should be greater than or equal to its required content plus overhead, considering the remaining budget and available files.</li>
                                            <li>Both `small.py` and `large.py` should have their expected allocations within a reasonable range of each other.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        396 input +
                                        136 output =
                                        532 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">32 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_empty</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_empty</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `distribute_token_budget` function behaves correctly when given an empty input or no budget.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': {'message': 'Expected distribute_token_budget({}, 100) to return {}'}, 'expected_result': '{}'}</li>
                                            <li>{'assertion': {'message': "Expected distribute_token_budget({'f1': 'c'}, 0) to return {}"}, 'expected_result': '{}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        130 output =
                                        245 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 42-43)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_fair_share</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify fair sharing when neither fits.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where either L1 or L2 file gets more than half of the budget, leading to unfair token distribution.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `allocations['l1.py']` should be between 35 and 50 (inclusive).</li>
                                            <li>The value of `allocations['l2.py']` should also be between 35 and 50 (inclusive).</li>
                                            <li>The absolute difference between the values of `allocations['l1.py']` and `allocations['l2.py']` should not exceed 1.</li>
                                            <li>Both `allocations['l1.py']` and `allocations['l2.py']` should be roughly equal.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        170 output =
                                        497 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 90-91, 93-94, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_max_files</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_llm_utils.py::test_distribute_token_budget_max_files</p>
                                    <p><strong>Why Needed:</strong> Verify max_files limit.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert len(allocations) is equal to 3', 'expected_value': 3, 'actual_value': 0}</li>
                                            <li>{'name': 'assert allocations contains exactly three files', 'expected_value': 3, 'actual_value': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        110 output =
                                        243 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_distribute_token_budget_sufficient</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `distribute_token_budget` function allocates tokens to files in a sufficient manner.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the token budget is insufficient, leading to incomplete or corrupted file contents.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of allocations for each file should be equal to the total needed tokens.</li>
                                            <li>Each allocation should contain exactly 10 tokens (i.e., ~40 characters).</li>
                                            <li>All files should have their full content allocated with sufficient token budget.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        332 input +
                                        116 output =
                                        448 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 20, 42, 46-47, 51-53, 55-60, 66-67, 70-71, 73, 75, 77, 79, 81-82, 84, 86-87, 96, 98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_llm_utils.py::test_estimate_tokens</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify the rough token estimation (chars / 4) for an empty string.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential division by zero error when estimating tokens.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert estimate_tokens('') == 1</li>
                                            <li>assert estimate_tokens('a') == 1</li>
                                            <li>assert estimate_tokens('aaaa') == 1</li>
                                            <li>assert estimate_tokens('aaaa' * 10) == 10</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        103 output =
                                        320 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/utils.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 20)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">29 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestArtifactEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage entry serialization.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the `CoverageEntry` object is not properly serialized to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should match the expected value.</li>
                                            <li>The 'line_ranges' key in the dictionary should match the expected value.</li>
                                            <li>The 'line_count' key in the dictionary should match the expected value.</li>
                                            <li>The `to_dict()` method of the `CoverageEntry` object returns a dictionary with the correct keys and values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        123 output =
                                        378 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 263-266)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCollectionError::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `CoverageEntry.to_dict()` returns the expected dictionary structure.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `CoverageEntry` object is not properly serialized to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `file_path` key should contain the correct file path.</li>
                                            <li>The `line_ranges` key should contain the correct line ranges in the format 'start-end'.</li>
                                            <li>The `line_count` key should contain the correct number of lines.</li>
                                            <li>Each assertion should match the expected values exactly.</li>
                                            <li>The dictionary structure should be consistent and follow the standard JSON format.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        136 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 241-243)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage serialization for CoverageEntry.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the coverage entry is not properly serialized to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should be equal to 'src/foo.py'.</li>
                                            <li>The 'line_ranges' key in the dictionary should be equal to '1-3, 5, 10-15'.</li>
                                            <li>The 'line_count' key in the dictionary should be equal to 10.</li>
                                            <li>The 'file_path' value is not a string.</li>
                                            <li>The 'line_ranges' value is not a list or tuple of strings.</li>
                                            <li>The 'line_ranges' value contains non-string values (e.g., integers).</li>
                                            <li>The 'line_count' value is not an integer.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        177 output =
                                        432 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 65-68)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_empty_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> An empty annotation should be created with default values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where an empty annotation would result in a `NoneType` attribute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'annotation.scenario', 'value': ''}</li>
                                            <li>{'name': 'annotation.why_needed', 'value': ''}</li>
                                            <li>{'name': 'annotation.key_assertions', 'value': []}</li>
                                            <li>{'name': 'annotation.confidence', 'value': 'None'}</li>
                                            <li>{'name': 'annotation.error', 'value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        124 output =
                                        336 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `LlmAnnotation` object can be serialized into a dictionary with required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the minimal annotation is properly serialized without any optional fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'scenario' field should be present in the dictionary.</li>
                                            <li>The 'why_needed' field should also be present in the dictionary.</li>
                                            <li>The 'key_assertions' field should not include the 'confidence' key, as it is an optional field.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        230 input +
                                        117 output =
                                        347 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 130-133, 135, 137, 139, 141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestLlmAnnotation::test_to_dict_with_all_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to dictionary with all fields</p>
                                    <p><strong>Why Needed:</strong> Prevents incorrect data representation in API responses</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Assert scenario is set correctly</li>
                                            <li>Assert confidence value matches expected</li>
                                            <li>Assert context summary contains required mode and bytes properties</li>
                                            <li>Assert error is None or empty</li>
                                            <li>Assert token presence in response body is verified</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        284 input +
                                        87 output =
                                        371 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 130-133, 135-137, 139-141, 143)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_default_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the default report has a schema version and empty lists.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring the default report is correctly defined with required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'schema_version' field should be set to SCHEMA_VERSION.</li>
                                            <li>The 'tests' field should be an empty list.</li>
                                            <li>The 'warnings' field should not be included in the dictionary.</li>
                                            <li>The 'collection_errors' field should not be included in the dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        111 output =
                                        342 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Report Root with collection errors should be verified.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report does not include all collection errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `collection_errors` in the report should be 1.</li>
                                            <li>The nodeid of the first error in `collection_errors` should be 'test_bad.py'.</li>
                                            <li>All collection errors in `collection_errors` should have a valid nodeid.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        237 input +
                                        104 output =
                                        341 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_report_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestReportRoot::test_report_with_warnings</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the ReportWarning class correctly identifies and includes warnings in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'length', 'expected_value': 1, 'actual_value': 1}</li>
                                            <li>{'assertion_type': 'code', 'expected_value': 'W001', 'actual_value': 'W001'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        144 input +
                                        112 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportRoot::test_tests_sorted_by_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests should be sorted by nodeid in output.</p>
                                    <p><strong>Why Needed:</strong> Because the current implementation does not sort tests by nodeid, which can lead to incorrect test results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "nodeids == ['a_test.py::test_a', 'm_test.py::test_m', 'z_test.py::test_z']", 'expected_result': ['a_test.py::test_a', 'm_test.py::test_m', 'z_test.py::test_z']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        215 input +
                                        120 output =
                                        335 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_with_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The `to_dict()` method of the `ReportWarning` class is used to convert a warning object into a dictionary.</p>
                                    <p><strong>Why Needed:</strong> This test is needed because it checks if the detail attribute of the `ReportWarning` object is correctly populated in the returned dictionary.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'detail', 'expected': '/path/to/file', 'actual': '/path/to/file'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        116 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 70-71, 73-75, 77-79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestReportWarning::test_to_dict_without_detail</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to dictionary without detail should exclude it.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a warning about missing detailed information in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'detail' key is expected to be present in the dictionary.</li>
                                            <li>The value of 'detail' is not provided in this case.</li>
                                            <li>The presence of 'detail' does not prevent the test from passing.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        223 input +
                                        92 output =
                                        315 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_aggregation_fields_present</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that RunMeta has aggregation fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where RunMeta is not aggregated by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert d['run_id'] == 'run-123',</li>
                                            <li>assert d['run_group_id'] == 'group-456',</li>
                                            <li>assert d['is_aggregated'] is True,</li>
                                            <li>assert d['aggregation_policy'] == 'merge',</li>
                                            <li>assert d['run_count'] == 3,</li>
                                            <li>assert len(d['source_reports']) == 2</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        343 input +
                                        127 output =
                                        470 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 286-288, 290-292, 376-392, 394, 397, 399, 402, 405, 407, 409, 411-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_fields_excluded_when_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LLM fields are excluded when annotations are disabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where LLMs are enabled but annotations are disabled, causing unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_annotations_enabled' key should not be present in the data.</li>
                                            <li>The 'llm_provider' key should not be present in the data.</li>
                                            <li>The 'llm_model' key should not be present in the data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        232 input +
                                        105 output =
                                        337 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_llm_traceability_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM traceability fields are included when enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in LLM model tracing functionality.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>data['llm_annotations_enabled'] is True</li>
                                            <li>data['llm_provider'] == 'ollama'</li>
                                            <li>data['llm_model'] == 'llama3.2:1b'</li>
                                            <li>data['llm_context_mode'] == 'complete'</li>
                                            <li>data['llm_annotations_count'] == 10</li>
                                            <li>data['llm_annotations_errors'] == 2</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        327 input +
                                        128 output =
                                        455 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419-431, 433, 435, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong>  tests/test_models.py::TestRunMeta::test_non_aggregated_excludes_source_reports</p>
                                    <p><strong>Why Needed:</strong> It's necessary to ensure that non-aggregated reports do not include source_reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'source_reports is not in d', 'expected_result': {'source_reports': []}}</li>
                                            <li>{'name': 'is_aggregated is False', 'expected_result': {'is_aggregated': False}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        111 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_meta_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test RunMeta to dict with all optional fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of missing or outdated plugin version, as it would lead to incorrect data being populated.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'git_sha' field is set to the expected value.</li>
                                            <li>The 'git_dirty' field is set to True.</li>
                                            <li>The 'repo_version' field matches the expected value.</li>
                                            <li>The 'repo_git_sha' field matches the expected value.</li>
                                            <li>The 'repo_git_dirty' field is False.</li>
                                            <li>The 'plugin_git_sha' field matches the expected value.</li>
                                            <li>The 'plugin_git_dirty' field is False.</li>
                                            <li>The 'config_hash' field matches the expected value.</li>
                                            <li>The length of the data dictionary is 1 as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        483 input +
                                        175 output =
                                        658 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">49 lines (ranges: 286-288, 290-292, 376-392, 394-417, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestRunMeta::test_run_status_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the RunMeta class to ensure it includes all necessary run status fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the RunMeta object is missing certain critical fields that are required for proper functioning.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'exit_code' field should be set to 1.</li>
                                            <li>The 'interrupted' field should be True.</li>
                                            <li>The 'collect_only' field should be True.</li>
                                            <li>The 'collected_count' field should be equal to 10.</li>
                                            <li>The 'selected_count' field should be equal to 8.</li>
                                            <li>The 'deselected_count' field should be equal to 2.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        148 output =
                                        433 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Schema Version Format</p>
                                    <p><strong>Why Needed:</strong> To ensure the schema version is in a valid semver format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The number of parts should be 3', 'expected_value': 3, 'message': "The schema version should have exactly 3 parts (e.g., '1.2.3')."}</li>
                                            <li>{'name': 'Each part should be a digit', 'expected_value': [0, 1, 2], 'message': 'Each part of the schema version should be a digit (0-9).'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        144 output =
                                        259 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSchemaVersion::test_schema_version_in_report_root</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the ReportRoot class does not include a schema version by default.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'ReportRoot.schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                            <li>{'name': 'report.to_dict().schema_version', 'expected_value': 'SCHEMA_VERSION'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        107 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">54 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceCoverageEntry::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage entry serialization.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the `CoverageEntry` class does not properly serialize its internal data to JSON.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the serialized dictionary should match the original file path.</li>
                                            <li>The 'line_ranges' key in the serialized dictionary should match the expected range string.</li>
                                            <li>The 'line_count' key in the serialized dictionary should match the original value.</li>
                                            <li>All keys in the serialized dictionary should have unique values.</li>
                                            <li>Any missing keys in the serialized dictionary should raise an assertion error.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        134 output =
                                        390 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 96-103)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_minimal</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `to_dict` method of `LlmAnnotation` returns a dictionary with required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the minimal annotation is missing some required fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'scenario' field should be present in the dictionary.</li>
                                            <li>The 'why_needed' field should be present in the dictionary.</li>
                                            <li>The 'key_assertions' field should be present in the dictionary.</li>
                                            <li>The 'confidence' field should not be present in the dictionary when it is `None`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        229 input +
                                        128 output =
                                        357 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 286-288, 290, 292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSourceReport::test_to_dict_with_run_id</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestSourceReport::test_to_dict_with_run_id</p>
                                    <p><strong>Why Needed:</strong> To ensure that the SourceReport object is correctly serializing its run_id attribute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'run-1', 'actual_value': 'run-1'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        79 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 286-288, 290-292)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestSummary::test_to_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `CoverageEntry.to_dict()` correctly serializes the test summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the serialized test summary is not accurate due to incorrect formatting of line ranges.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'file_path' key in the dictionary should match the expected value.</li>
                                            <li>The 'line_ranges' key in the dictionary should match the expected value.</li>
                                            <li>The 'line_count' key in the dictionary should match the expected value.</li>
                                            <li>The 'start' and 'end' values of the line ranges should be correctly formatted (e.g., '1-3', '5, 10-15')</li>
                                            <li>Any missing or incorrect line ranges should raise an AssertionError</li>
                                            <li>Any invalid or malformed line ranges should raise an AssertionError</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        254 input +
                                        174 output =
                                        428 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_minimal_result</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a minimal result has the required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where a minimal result is not provided with all necessary information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'nodeid' field should match the expected node ID.</li>
                                            <li>The 'outcome' field should be set to 'passed'.</li>
                                            <li>The 'duration' field should be set to 0.0 (indicating no execution time).</li>
                                            <li>The 'phase' field should be set to 'call'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        244 input +
                                        117 output =
                                        361 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_coverage verifies that the `result` dictionary contains a single 'coverage' key with a list of coverage entries.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the `result` dictionary includes a 'coverage' key, which is necessary for calculating and displaying coverage statistics.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'coverage' key should be present in the `result` dictionary.</li>
                                            <li>The 'coverage' key should contain a list of coverage entries.</li>
                                            <li>Each coverage entry should have a 'file_path' attribute set to the expected file path ('src/foo.py').</li>
                                            <li>Each coverage entry should have a 'line_ranges' attribute set to a valid range (e.g., '1-5') and a 'line_count' attribute equal to the actual number of lines in the file.</li>
                                            <li>The list of coverage entries should not be empty.</li>
                                            <li>All file paths in the 'coverage' list should match the expected file path ('src/foo.py').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        256 input +
                                        223 output =
                                        479 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">24 lines (ranges: 65-68, 190, 194-199, 201, 203, 205, 207, 210-212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_with_llm_opt_out</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LLM opt-out flag is correctly set in the test result.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert llm_opt_out is True', 'expected_value': True, 'actual_value': 'is True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        145 input +
                                        90 output =
                                        235 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_with_rerun</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case 'test_result_with_rerun' has been executed.</p>
                                    <p><strong>Why Needed:</strong> The test result is not being recorded in the database because reruns are disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Rerun count', 'value': 2}</li>
                                            <li>{'name': 'Final outcome', 'value': 'passed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        93 output =
                                        255 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203, 205, 207-210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models.py::TestTestCaseResult::test_result_without_rerun_excludes_fields</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `result` dictionary excludes fields related to reruns.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'field_name': 'rerun_count', 'expected_value': 0, 'actual_value': 'Not applicable'}</li>
                                            <li>{'field_name': 'final_outcome', 'expected_value': 'passed', 'actual_value': 'passed'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        152 input +
                                        119 output =
                                        271 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_models_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_all_optional_fields</p>
                                    <p><strong>Why Needed:</strong> Prevents bar because llm_opt_out=True prevents the annotation from being generated for optional fields.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert result['param_id'] == 'a-b-c',</li>
                                            <li>assert result['param_summary'] == 'a=1, b=2, c=3',</li>
                                            <li>assert result['captured_stdout'] == 'stdout content',</li>
                                            <li>assert result['captured_stderr'] == 'stderr content',</li>
                                            <li>assert result['requirements'] == ['REQ-100'],</li>
                                            <li>assert result['llm_opt_out'] is True,</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        157 output =
                                        611 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 96-103, 241-243, 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_artifacts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>LLM error:</strong> Failed to parse LLM response as JSON</p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 263-266, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530-532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_collection_errors</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes collection_errors when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the to_dict method does not include collection_errors in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of collection_errors is 1.</li>
                                            <li>collection_errors[0].nodeid matches 'broken_test.py'.</li>
                                            <li>The nodeid value contains the string 'SyntaxError'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        243 input +
                                        92 output =
                                        335 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">58 lines (ranges: 241-243, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526-528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_custom_metadata</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes custom_metadata when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in cases where custom metadata is required but not properly handled by the default to_dict method.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>custom_metadata['project'] == 'myproject'</li>
                                            <li>custom_metadata['environment'] == 'staging'</li>
                                            <li>custom_metadata['build_number'] == 123</li>
                                            <li>custom_metadata does not contain any other metadata keys.</li>
                                            <li>result['custom_metadata']['project'] is equal to the expected value.</li>
                                            <li>result['custom_metadata']['environment'] is equal to the expected value.</li>
                                            <li>result['custom_metadata']['build_number'] is equal to the expected value.</li>
                                            <li>result does not contain any additional custom metadata keys.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        162 output =
                                        426 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534-536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_hmac_signature</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_hmac_signature</p>
                                    <p><strong>Why Needed:</strong> to ensure that the `report.to_dict()` method includes an HMAC signature when it is set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': 'signature123', 'actual_value': 'hmac_signature'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        85 output =
                                        213 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538-540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_sha256</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_sha256</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the `to_dict` method of the ReportRoot class includes a SHA-256 hash when it is set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'expected value', 'value': 'abcdef1234567890'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        92 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536-538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes source_coverage when set.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails if the 'source_coverage' key is not present in the report dictionary, potentially leading to incorrect coverage analysis.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'source_coverage' list contains exactly one entry.</li>
                                            <li>The first element of the 'source_coverage' list has the correct file path ('src/mod.py').</li>
                                            <li>All elements in the 'source_coverage' list have the correct keys (file_path, statements, missed, covered, coverage_percent, covered_ranges, missed_ranges).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        282 input +
                                        134 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 96-103, 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532-534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestReportRootToDict::test_to_dict_with_warnings</p>
                                    <p><strong>Why Needed:</strong> This test is necessary because the `to_dict()` method of ReportRoot includes warnings when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "len(result['warnings']) == 1", 'expected_value': 1, 'message': "Expected len(result['warnings']) to be equal to 1"}</li>
                                            <li>{'name': "result['warnings'][0]['code'] == 'W001'", 'expected_value': 'W001', 'message': "Expected result['warnings'][0]['code'] to be equal to 'W001'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        157 output =
                                        308 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 376-392, 394, 397, 399, 402, 405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_with_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> ...</p>
                                    <p><strong>Why Needed:</strong> ...</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>...</li>
                                            <li>{'assertion_name': '...', 'expected_value': '...', 'actual_value': '...', 'message': '...'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        153 input +
                                        125 output =
                                        278 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 467-475, 477-479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestSummaryToDict::test_to_dict_without_coverage_total_percent</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> ...</p>
                                    <p><strong>Why Needed:</strong> ...</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>...</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        267 output =
                                        398 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 467-475, 477, 479)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_all_optional_fields</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test to_dict includes all optional fields when set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in coverage calculation when llm_opt_out is True.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'param_id' field should be present and match 'a-b-c'.</li>
                                            <li>The 'param_summary' field should contain the correct values for 'a', 'b', and 'c'.</li>
                                            <li>The 'captured_stdout' field should not be empty.</li>
                                            <li>The 'captured_stderr' field should not be empty.</li>
                                            <li>The 'requirements' list should include 'REQ-100'.</li>
                                            <li>The 'llm_opt_out' field should be True.</li>
                                            <li>The 'llm_context_override' field should match the scenario name.</li>
                                            <li>The number of coverage entries should be 1.</li>
                                            <li>The 'llm_annotation' field should contain the correct scenario name.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        454 input +
                                        193 output =
                                        647 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">42 lines (ranges: 65-68, 130-133, 135, 137, 139, 141, 143, 190, 194-199, 201-207, 210-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stderr</p>
                                    <p><strong>Why Needed:</strong> to include captured_stderr in the JSON response when to_dict is used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'Error output here'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        80 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220-222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_captured_stdout</p>
                                    <p><strong>Why Needed:</strong> The `to_dict` method includes captured stdout when set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'captured_stdout', 'expected_value': 'Debug output here'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        78 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218-220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_param_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 190, 194-199, 201, 203-207, 210, 212, 214, 216, 218, 220, 222, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_models_coverage.py::TestTestCaseResultToDict::test_to_dict_with_requirements</p>
                                    <p><strong>Why Needed:</strong> The `to_dict` method includes requirements when set. This is necessary because the `requirements` key in the test result dictionary is not a standard JSON key, but rather an attribute of the TestCaseResult class.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `to_dict` method should include the `requirements` key and its value should be a list of strings.</li>
                                            <li>The `requirements` key should be present in the `test_result` dictionary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        124 output =
                                        275 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">21 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_exclude_globs</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the default exclude globs are correctly set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the default exclude globs are not correctly set, potentially leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `Config().llm_context_exclude_globs` returns a list of strings containing the specified globs.</li>
                                            <li>* The glob '*.pyc' is included in the list of default exclude globs.</li>
                                            <li>* The glob '__pycache__/*' is included in the list of default exclude globs.</li>
                                            <li>* The glob '*secret*' is included in the list of default exclude globs.</li>
                                            <li>* The glob '*password*' is included in the list of default exclude globs.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        222 input +
                                        161 output =
                                        383 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_redact_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the default redact patterns configuration.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential security vulnerability where sensitive information like passwords and tokens are not properly redacted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `--password` pattern is present in the default redact patterns.</li>
                                            <li>The `--token` pattern is present in the default redact patterns.</li>
                                            <li>The `--api[_-]?key` pattern is present in the default redact patterns.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        228 input +
                                        105 output =
                                        333 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_default_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that default values are set correctly for the test_default_values scenario.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the default values of the Config class are not set properly, potentially leading to unexpected behavior or errors in the application.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.provider == 'none'</li>
                                            <li>cfg.llm_context_mode == 'minimal'</li>
                                            <li>cfg.llm_max_tests == 0</li>
                                            <li>cfg.llm_max_retries == 10</li>
                                            <li>cfg.llm_context_bytes == 32000</li>
                                            <li>cfg.llm_context_file_limit == 10</li>
                                            <li>cfg.llm_requests_per_minute == 5</li>
                                            <li>cfg.llm_timeout_seconds == 30</li>
                                            <li>cfg.llm_cache_ttl_seconds == 86400</li>
                                            <li>cfg.include_phase == 'run'</li>
                                            <li>cfg.aggregate_policy == 'latest'</li>
                                            <li>cfg.is_llm_enabled() is False</li>
                                            <li>cfg.omit_tests_from_coverage is True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        209 output =
                                        527 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_get_default_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_get_default_config</p>
                                    <p><strong>Why Needed:</strong> To test the default configuration of the options.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg', 'expected_type': 'Config'}</li>
                                            <li>{'name': 'cfg.provider', 'expected_value': 'none'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        104 input +
                                        84 output =
                                        188 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 293)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_is_llm_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify the is_llm_enabled check for different providers.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the test fails when using an unsupported provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `is_llm_enabled` should return False for a provider without LLM (e.g., 'none')</li>
                                            <li>The function `is_llm_enabled` should return True for providers with LLMs (e.g., 'ollama', 'litellm', 'gemini')</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        112 output =
                                        375 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_aggregate_policy</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_aggregate_policy</p>
                                    <p><strong>Why Needed:</strong> to test the validation of an invalid aggregation policy</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'length of errors', 'value': 1, 'description': 'The number of errors found during validation'}</li>
                                            <li>{'name': 'error message', 'value': "Invalid aggregate_policy 'random'", 'description': 'The error message returned by the validation process'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        128 input +
                                        110 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-221, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_context_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_invalid_context_mode</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `validate()` method raises an error when a valid context mode is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'length', 'expected_value': 1, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        131 input +
                                        85 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-213, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_include_phase</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-229, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_invalid_provider</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for configuration options</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `Config` class correctly validates an invalid provider.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'The provider is invalid.', 'expected_value': "Invalid provider 'invalid_provider'"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        68 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_numeric_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of numeric constraints for TestConfig.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the default values for LLM context bytes, max tests, requests per minute, timeout seconds, and max retries are not validated against their expected minimum or maximum values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>cfg.validate() returns an empty list if all constraints are met</li>
                                            <li>cfg.validate() returns a list of errors with the specified message</li>
                                            <li>The 'llm_context_bytes' constraint is at least 1000 bytes</li>
                                            <li>The 'llm_max_tests' constraint is positive or zero</li>
                                            <li>The 'llm_requests_per_minute' constraint is at least 1</li>
                                            <li>The 'llm_timeout_seconds' constraint is at least 1</li>
                                            <li>The 'llm_max_retries' constraint is positive or zero</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        329 input +
                                        184 output =
                                        513 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">31 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245-254, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestConfig::test_validate_valid_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestConfig::test_validate_valid_config</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `validate` method returns an empty list of errors when a valid configuration is passed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'errors should be empty', 'expected_value': [], 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        100 input +
                                        85 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_aggregation_options</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loads aggregation options with correct directory, policy and run ID.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the aggregate options are not loaded correctly due to incorrect or missing values in the mock configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The expected value of `aggregate_dir` is set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        205 output =
                                        500 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_batch_flag_conflict</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_batch_flag_conflict</p>
                                    <p><strong>Why Needed:</strong> To test that the disabled batch flag works correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg.batch_parametrized_tests is True', 'expected_value': True, 'actual_value': 'assert cfg.batch_parametrized_tests is True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        90 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_config_missing_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when pyproject.toml doesn't exist.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in LLM configuration loading without a pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_max_retries' attribute is not set to its default value (10).</li>
                                            <li>The 'llm_report_html', 'llm_report_json', 'llm_report_pdf', 'llm_evidence_bundle', 'llm_dependency_snapshot', 'llm_requests_per_minute', 'llm_aggregate_dir', 'llm_aggregate_policy', 'llm_aggregate_run_id', 'llm_aggregate_group_id' attributes are set to None.</li>
                                            <li>The 'llm_provider' attribute is not set. This flag is required for LLMs.</li>
                                            <li>The 'llm_model' attribute is not set. This flag is required for LLMs.</li>
                                            <li>The 'llm_context_mode' attribute is not set. This flag is required for LLMs.</li>
                                            <li>The 'llm_prompt_tier', 'llm_batch_parametrized', and 'llm_context_compression' attributes are set to None, which may cause issues with the LLM configuration.</li>
                                            <li>}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        413 input +
                                        260 output =
                                        673 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_coverage_source</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_coverage_source</p>
                                    <p><strong>Why Needed:</strong> To test the coverage source option.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_pytest_config.option.llm_coverage_source', 'expected_value': 'cov_dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        126 input +
                                        72 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607-608, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_defaults</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_defaults</p>
                                    <p><strong>Why Needed:</strong> To test the default configuration when no options are set.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "cfg.provider == 'none'", 'expected_value': 'None'}</li>
                                            <li>{'name': 'cfg.report_html is None', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        93 output =
                                        209 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">85 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that CLI options override pyproject.toml options.</p>
                                    <p><strong>Why Needed:</strong> To test the ability of CLI options to override pyproject.toml settings.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml overrides CLI options', 'expected_value': {'key': 'value'}, 'actual_value': {'key': 'override value'}}</li>
                                            <li>{'name': 'CLI options override pyproject.toml values', 'expected_value': {'key': 'override value'}, 'actual_value': {'key': 'override value'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        131 output =
                                        265 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">132 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492-494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_provider_override</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that CLI provider option overrides pyproject.toml.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the CLI provider option can override the default configuration in pyproject.toml, which is used to load dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml', 'expected_content': '...toml'}</li>
                                            <li>{'name': 'CLI provider option overrides pyproject.toml', 'expected_content': '...overrides pyproject.toml'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        114 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">133 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options.py::TestLoadConfig::test_load_from_cli_retries</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading retries from the CLI.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_pytest_config.option.llm_max_retries', 'expected_value': 2, 'actual_value': 0}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        86 output =
                                        216 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">86 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494-495, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_from_pyproject</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Create a new directory with a pyproject.toml file</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of loading values from a pyproject.toml file in an environment where the file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': True, 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        87 output =
                                        206 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">134 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386-388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options.py::TestLoadConfig::test_load_token_optimization_options</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test loading token optimization options from CLI.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in token optimization configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `prompt_tier` option should be set to 'minimal'.</li>
                                            <li>The `batch_parametrized_tests` option should not be enabled.</li>
                                            <li>The `context_compression` option should be set to 'none'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        89 output =
                                        353 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">88 lines (ranges: 123, 171, 308, 311-312, 320-322, 460, 463, 466, 470-474, 476-477, 479, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_options_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">47 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_dependency_snapshot</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test_cli_dependency_snapshot function correctly sets the dependency snapshot to 'deps.json' when an option is set.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the CLI overrides for dependency snapshots are not being properly applied.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `cfg.report_dependency_snapshot` should be set to `'deps.json'` after setting the `llm_dependency_snapshot` option.</li>
                                            <li>The function `load_config(mock)` correctly loads the mock configuration and returns a valid configuration object.</li>
                                            <li>The `mock.option.llm_dependency_snapshot` attribute is set to the expected value 'deps.json'.</li>
                                            <li>The `cfg.report_dependency_snapshot` attribute of the loaded configuration object is updated with the correct value 'deps.json'.</li>
                                            <li>The test function does not fail when an option is set for dependency snapshot.</li>
                                            <li>The test function passes without any assertion failures when an option is set for dependency snapshot.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        213 input +
                                        203 output =
                                        416 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488, 490-492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_evidence_bundle</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing the `test_cli_evidence_bundle` function to ensure it correctly sets the `llm_evidence_bundle` option to 'bundle.zip'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `llm_evidence_bundle` option is not set correctly, potentially leading to incorrect evidence bundle reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `cfg.report_evidence_bundle` should be set to 'bundle.zip' after setting `mock.option.llm_evidence_bundle = 'bundle.zip'`.</li>
                                            <li>The function `load_config(mock)` should return the correct configuration with the updated option value.</li>
                                            <li>The assertion `assert cfg.report_evidence_bundle == 'bundle.zip'` should pass if the configuration is correctly loaded and the option is set to 'bundle.zip'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        217 input +
                                        175 output =
                                        392 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486, 488-490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_json</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the `test_cli_report_json` test verifies that the `report_json` option is set to 'output.json' when CLI override for report JSON is enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a bug where the `report_json` option is not correctly overridden in the configuration, potentially leading to incorrect output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `cfg.report_json` should be set to 'output.json' when `mock.option.llm_report_json = "output.json"`.</li>
                                            <li>The `load_config(mock)` function should return a valid configuration object with the correct `report_json` option value.</li>
                                            <li>The `assert cfg.report_json == "output.json"` statement should pass if the above conditions are met.</li>
                                            <li>If the `mock.option.llm_report_json = "other.json"` is executed, the test should fail and report an error message indicating that the `report_json` option was not overridden correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        207 output =
                                        419 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484-486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestCliOverrides::test_cli_report_pdf</span>
                            <div class="test-meta">
                                <span>6ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the CLI option to generate a report in PDF format.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the test fails due to incorrect report PDF path.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `llm_report_pdf` option is set to 'output.pdf' when the test runs.</li>
                                            <li>The `report_pdf` value of the configuration object matches 'output.pdf'.</li>
                                            <li>The `llm_report_pdf` option has been successfully overridden in the mock configuration.</li>
                                            <li>The report PDF path can be changed without affecting the test result.</li>
                                            <li>The `llm_report_pdf` option is correctly set even if the config file does not exist.</li>
                                            <li>The `report_pdf` value of the configuration object matches 'output.pdf' when the config file exists.</li>
                                            <li>The mock configuration has been successfully created with the correct report PDF path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        212 input +
                                        184 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">92 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470-474, 476-477, 479, 482, 484, 486-488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_invalid_token_output_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_token_output_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the token output format is correctly validated and raises an error when it's invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "errors contains 'litellm_token_output_format' key", 'description': 'The validation should return an error message indicating the invalid token output format.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        90 output =
                                        220 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-237, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_token_refresh_interval_too_short</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation when token refresh interval is too short</p>
                                    <p><strong>Why Needed:</strong> Token refresh intervals should be at least 60 seconds to ensure sufficient time for the token to expire and be refreshed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'litellm_token_refresh_interval must be at least 60', 'expected_value': 60}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        146 input +
                                        86 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241-242, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestConfigValidationCoverage::test_validate_valid_litellm_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test validation of valid LiteLLM configuration.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the LiteLLM provider is correctly configured and validated without any errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The validate method returns an empty list of errors.', 'expected_result': [], 'message': 'Expected validate method to return an empty list of errors.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        91 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_include_history</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_aggregate_include_history</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `aggregate_include_history` option is properly loaded and included in the generated code.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'include_history = True', 'actual': 'include_history = False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        85 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438-440, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_aggregate_policy_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that the aggregate policy can be loaded from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'expected_value': 'True'}</li>
                                            <li>{'name': 'aggregate_policy_path exists in pyproject.toml', 'expected_value': '/path/to/aggregate/policy.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        121 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436-438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_all_config_keys_combined</p>
                                    <p><strong>Why Needed:</strong> To ensure that all config keys are loaded when loading the entire pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'All config keys should be present in the pyproject.toml file', 'expected_value': {'all_keys': ['config', 'keys', 'load', 'pyproject']}, 'actual_value': [False], 'message': 'Expected all config keys to be present, but got {falses}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        120 input +
                                        136 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">150 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340-346, 348-350, 352-354, 356-357, 360-369, 372-375, 378-392, 396, 400, 402, 404, 408-410, 412-413, 416-422, 426-428, 430-432, 436-440, 444-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_dir</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache directory is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and has a valid cache_dir', 'expected_value': 'path/to/cache/dir'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        89 output =
                                        202 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390-392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_cache_ttl_seconds</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for PyProjectLoadingCoverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the cache TTL seconds are loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'value': 'True'}</li>
                                            <li>{'name': "pyproject.toml has a section named 'cache_ttl_seconds'", 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        103 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388-390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_failed_output</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `capture_failed_output` option in `pyproject.toml` is correctly loaded and used for coverage purposes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'expected': 'The pyproject.toml file was created successfully.'}</li>
                                            <li>{'name': 'capture_failed_output key exists in pyproject.toml', 'expected': "The 'capture_failed_output' key was found in the pyproject.toml file."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        140 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418-420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_capture_output_max_chars</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `capture_output_max_chars` option is properly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'max_chars = 100', 'actual': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        99 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420-422, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context bytes are loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'context_bytes_path', 'expected_value': 'path/to/pyproject.toml', 'actual_value': 'pyproject / pyproject.toml'}</li>
                                            <li>{'name': 'context_bytes_file_mode', 'expected_value': 'r', 'actual_value': 'rb'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        127 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362-364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_exclude_globs</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_exclude_globs` setting in `pyproject.toml` is properly excluded from coverage reports.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and is writable', 'expected': {'status': 'ok', 'message': ''}, 'actual': {'status': 'error', 'message': "PermissionError: 'tmp_path / ' is not writable"}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        127 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368-369, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_file_limit</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context file limit is correctly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected_value': True, 'message': 'Expected pyproject.toml to exist'}</li>
                                            <li>{'name': 'pyproject.toml content is correct', 'expected_value': {'context_file_limit': 100}, 'message': 'Expected context_file_limit to be 100'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        138 output =
                                        254 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364-366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_context_include_globs</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for `tests/test_options_coverage`</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `context_include_globs` setting is correctly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context include globs are loaded from pyproject.toml', 'description': 'The context include globs should be present in the test environment.', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        103 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366-368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_hmac_key_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the hmac_key_file is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and contains hmac_key_file', 'expected': {'hmac_key_file': 'path/to/hmac_key_file'}, 'actual': {'hmac_key_file': 'path/to/hmac_key_file'}}</li>
                                            <li>{'name': 'pyproject.toml does not contain hmac_key_file', 'expected': {}, 'actual': {}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        146 output =
                                        264 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446-447, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_param_values</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_param_values` option is correctly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The `include_param_values` option should be present in the `pyproject.toml` file.', 'expected_value': True}</li>
                                            <li>{'name': 'The value of `include_param_values` should match the expected value.', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        131 output =
                                        247 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372-374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_phase</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_phase` is loaded correctly from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': '```toml\n[tool.pyproject]\ninclude_phase = ["phase1", "phase2"]\n``', 'actual': '```toml\n[tool.pyproject]\ninclude_phase = []\n``', 'error_message': "The 'include_phase' key is missing from the PyProject.toml file."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        150 output =
                                        263 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_pytest_invocation</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_include_pytest_invocation</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `include_pytest_invocation` option is correctly loaded from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'include_pytest_invocation = True', 'actual': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        101 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426-428, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_invocation_redact_patterns</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for pyproject.toml coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the invocation_redact_patterns are correctly loaded and used in tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'File existence', 'expected_result': 'pyproject.toml exists in the test directory', 'actual_result': 'pyproject.toml does not exist'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        91 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430-432, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_base</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_base</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm_api_base is loaded correctly from pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'litellm_api_base exists in pyproject.toml', 'expected_value': 'True'}</li>
                                            <li>{'name': "pyproject.toml contains a [tool] section with 'litellm_api_base' as the name", 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        129 output =
                                        251 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340-342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_api_key</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm API key is correctly loaded from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'litellm_api_key exists in pyproject.toml', 'expected_value': 'litellm_api_key', 'actual_value': 'litellm_api_key'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        122 input +
                                        108 output =
                                        230 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342-344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_json_key</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Loading litellm_token_json_key from pyproject.toml</p>
                                    <p><strong>Why Needed:</strong> To ensure that the litellm token JSON key is correctly loaded and used in the application.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'description': 'The pyproject.toml file should exist at the specified path.', 'expected_result': 'True'}</li>
                                            <li>{'name': 'litellm_token_json_key is present in pyproject.toml', 'description': 'The litellm token JSON key should be present in the pyproject.toml file.', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        151 output =
                                        276 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356-357, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_output_format</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_output_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm` package correctly handles token output formats in PyProject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "```toml\noutput_format = 'litellm_token_output_format'\n``", 'actual': 'pyproject.toml contents'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        114 output =
                                        239 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352-354, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_command</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm_token_refresh_command` is loaded correctly from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'description': 'The `pyproject.toml` file should exist in the test directory.', 'expected_result': 'True'}</li>
                                            <li>{'name': 'litellm_token_refresh_command is present in pyproject.toml', 'description': 'The `litellm_token_refresh_command` should be present in the `pyproject.toml` file.', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        170 output =
                                        295 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344-346, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_interval</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_litellm_token_refresh_interval</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `litellm_token_refresh_interval` option is properly loaded from the PyProject.toml file, allowing for accurate coverage analysis.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'a string representing the contents of the PyProject.toml file'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        107 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348-350, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_malformed_pyproject</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 123, 171, 308, 311-312, 320-325, 449, 451, 453-456, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_concurrency</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `max_concurrency` setting in `pyproject.toml` is correctly loaded and used by the project.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The `max_concurrency` setting in `pyproject.toml` should be a non-negative integer.', 'expected_value': 0, 'actual_value': 1}</li>
                                            <li>{'name': 'The `max_concurrency` setting in `pyproject.toml` should not cause any errors when loaded by the project.', 'expected_error': 'max_concurrency must be a non-negative integer', 'actual_error': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        169 output =
                                        285 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380-382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_max_tests</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing the ability to load max_tests from pyproject.toml</p>
                                    <p><strong>Why Needed:</strong> To ensure that the 'max_tests' setting in the pyproject.toml file can be loaded correctly and used by the tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "The 'max_tests' setting is present in pyproject.toml", 'value': 'True'}</li>
                                            <li>{'name': "The 'max_tests' setting is a boolean value", 'value': 3}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        119 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378-380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_metadata_file</p>
                                    <p><strong>Why Needed:</strong> To ensure that the metadata file is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists', 'expected': 'True', 'actual': 'False'}</li>
                                            <li>{'name': 'metadata_file exists in pyproject.toml', 'expected': 'True', 'actual': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        118 output =
                                        231 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444-446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_ollama_host</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_pyproject_loading_coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ollama_host is loaded correctly from the pyproject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists and is not empty', 'expected_value': 'True'}</li>
                                            <li>{'name': 'ollama_host is defined in pyproject.toml', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        104 output =
                                        223 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336-337, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_omit_tests_from_coverage</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_omit_tests_from_coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `omit_tests_from_coverage` option is correctly loaded from the `pyproject.toml` file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "The 'omit_tests_from_coverage' setting in pyproject.toml should be set to a boolean value."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        108 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_param_value_max_chars</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_param_value_max_chars</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `param_value_max_chars` option is correctly loaded from the `pyproject.toml` file and that its value is being used in the build process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'The value of `param_value_max_chars` is a string', 'expected_type': 'str'}</li>
                                            <li>{'name': 'The length of `param_value_max_chars` is less than or equal to 50 characters', 'expected_value': 50}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        143 output =
                                        262 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374-375, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_report_collect_only</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `report_collect_only` option is correctly loaded from the PyProject.toml file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': 'Collect only: ["..."]', 'actual': 'Collect only: ["..."]'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        103 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416-418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_timeout_seconds</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectLoadingCoverage::test_load_timeout_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the timeout seconds are loaded correctly from pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml exists and is not empty', 'expected_value': 'True'}</li>
                                            <li>{'name': 'timeout_seconds key exists in pyproject.toml', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        109 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">109 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_max_tests</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_max_tests</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `batch_max_tests` option is correctly loaded from the PyProject.toml file and used to optimize Python packages.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml contents', 'expected': "The 'batch_max_tests' key in the PyProject.toml file should be set to a non-empty list of test names."}</li>
                                            <li>{'name': 'optimized_packages', 'expected': "The 'optimized_packages' key in the optimized package metadata should contain a list of test names that were batched together."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        156 output =
                                        273 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400-402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_batch_parametrized_tests</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_load_batch_parametrized_tests</p>
                                    <p><strong>Why Needed:</strong> Optimization of PyProject token in batch parameterized tests</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'PyProject token is not empty', 'description': 'The PyProject token should be present in the pyproject.toml file.', 'value': 'True'}</li>
                                            <li>{'name': 'PyProject path exists', 'description': 'The PyProject path should exist and point to a valid directory.', 'value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        125 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">131 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396-398, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context compression feature in Pytest is properly loaded and used.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context compression should be enabled by default', 'value': True, 'expected_value': False}</li>
                                            <li>{'name': 'Context compression should be disabled if --with-optional-removal flag is used', 'value': True, 'expected_value': False}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        127 output =
                                        244 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402-404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_context_line_padding</p>
                                    <p><strong>Why Needed:</strong> To ensure that the context line padding is correctly loaded and applied in the build process.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Context line padding is correctly loaded from pyproject.toml', 'expected_value': 'context_line_padding', 'actual_value': 'context_line_padding'}</li>
                                            <li>{'name': 'Context line padding is applied to the build output', 'expected_value': ['context_line_padding'], 'actual_value': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        135 output =
                                        252 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404-405, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</span>
                            <div class="test-meta">
                                <span>4ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestPyprojectTokenOptimization::test_load_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `prompt_tier` is correctly loaded from the `pyproject.toml` file and used to determine the token optimization strategy.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'prompt_tier loading', 'expected': "The 'prompt_tier' key should be present in the pyproject.toml file."}</li>
                                            <li>{'name': 'token_optimization_strategy', 'expected': "The 'token_optimization_strategy' value should be a string that indicates the optimization strategy to use."}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        117 input +
                                        148 output =
                                        265 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332, 334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392-393, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 502, 504-505, 507, 511-512, 514, 516-517, 519, 521-522, 524, 528-529, 531, 534-535, 537-538, 540, 542-543, 545, 547-548, 550-551, 554-555, 557-558, 561-562, 564, 566-567, 569, 572-573, 575-576, 578, 581-584, 588-589, 591, 593-594, 596, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_batch_max_tests_too_small</p>
                                    <p><strong>Why Needed:</strong> Because the `batch_max_tests` configuration option is not being used effectively.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'The validation error message should contain a clear indication that `batch_max_tests` must be at least 1.', 'expected_value': 'batch_max_tests must be at least 1', 'actual_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        135 input +
                                        113 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271-273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_context_line_padding_negative</p>
                                    <p><strong>Why Needed:</strong> Negative context_line_padding is not allowed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'context_line_padding must be 0 or positive'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        68 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273-274, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_context_compression</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_context_compression</p>
                                    <p><strong>Why Needed:</strong> To ensure that the validation of context compression settings does not fail when an invalid value is provided.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'errors', 'type': 'list', 'value': ['Invalid context_compression']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        88 output =
                                        212 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-269, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_options_coverage.py::TestValidationCoverageExtended::test_validate_invalid_prompt_tier</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_validate_invalid_prompt_tier</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `validate()` method correctly identifies and reports invalid `prompt_tier` values.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 'Invalid prompt_tier', 'actual': 'Invalid prompt_tier'}</li>
                                            <li>{'expected': 'Invalid prompt_tier', 'actual': 'Invalid prompt_tier'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        125 input +
                                        99 output =
                                        224 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-261, 265-266, 271, 273, 276)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_integration.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">14 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginConfigLoading::test_config_defaults</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin configuration has safe defaults.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'cfg is an instance of Config', 'expected_type': 'Config'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        72 output =
                                        191 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">124 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-337, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378-380, 382, 384-386, 388, 390, 392, 396, 400, 402, 404, 408-410, 412-413, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603-605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginConfigLoading::test_markers_exist_in_config</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginConfigLoading::test_markers_exist_in_config</p>
                                    <p><strong>Why Needed:</strong> The test checks if markers exist in the plugin configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytestconfig is not None', 'expected_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        108 input +
                                        74 output =
                                        182 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_both_json_and_html_outputs</span>
                            <div class="test-meta">
                                <span>102ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test generates both JSON and HTML reports for a test function.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where the plugin is used with both JSON and HTML output formats.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The generated report files should exist at `report.json` and `report.html` paths.</li>
                                            <li>The report data should be correctly formatted as either JSON or HTML depending on the configuration.</li>
                                            <li>The test function should produce a valid output that can be parsed by both Pytester's reporting tools.</li>
                                            <li>The plugin's integration with Pytester should not introduce any new bugs or regressions in this scenario.</li>
                                            <li>The generated report files should have the correct file extensions (JSON and HTML) even when using the `--llm-report` option.</li>
                                            <li>The test function should not fail to run due to a missing or incorrect report file path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        186 output =
                                        465 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">91 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</span>
                            <div class="test-meta">
                                <span>66ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_collection_finish_counts_items</p>
                                    <p><strong>Why Needed:</strong> pytest_collection_finish counts items (line 378)</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "assert data['run_meta']['collected_count'] == 3", 'expected_value': 3, 'message': 'Expected collected count to be 3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        198 input +
                                        96 output =
                                        294 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_creates_nested_directory</span>
                            <div class="test-meta">
                                <span>63ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `test_pass()` function is executed and a new directory 'nested' with 'dir' as its parent directory is created.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in cases where the plugin integration fails to create output directories.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'nested' directory should be created with 'dir' as its parent directory.</li>
                                            <li>The 'report.json' file within the 'nested' directory should exist.</li>
                                            <li>The 'test_pass()' function should be executed successfully.</li>
                                            <li>The 'pytester.path / nested / dir / report.json' path should be an existing directory.</li>
                                            <li>The 'pytester.runpytest(f--llm-report-json={report_path})' command should execute without raising any errors.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        247 input +
                                        167 output =
                                        414 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 70-71, 73-75, 77, 79, 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_fixture_error_captured</span>
                            <div class="test-meta">
                                <span>67ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fixture errors are captured in report.</p>
                                    <p><strong>Why Needed:</strong> Fixture failures are not properly reported, leading to incorrect error counts and debugging issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'summary' key in the report contains an error code of 1.</li>
                                            <li>The 'error' value under the 'summary' key is set to a non-zero value (in this case, 1).</li>
                                            <li>The test fixture raises a RuntimeError and its name is included in the error summary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        286 input +
                                        113 output =
                                        399 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 78-79, 90, 93-94, 96, 99-103, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330, 332, 334-335, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_makereport_captures_all_outcomes</span>
                            <div class="test-meta">
                                <span>179ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_runtest_makereport captures outcomes to verify that it correctly identifies all test outcomes.</p>
                                    <p><strong>Why Needed:</strong> pytest_runtest_makereport prevents regression by ensuring that the plugin correctly identifies and reports all test outcomes, including skipped tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'passed' outcome should be present in the report.</li>
                                            <li>The 'failed' outcome should be present in the report.</li>
                                            <li>The 'skipped' outcome should be present in the report.</li>
                                            <li>All test names should be included in the report.</li>
                                            <li>The plugin should not miss any test outcomes, including skipped tests.</li>
                                            <li>The plugin should correctly identify and report all test outcomes, regardless of their status (e.g., running, pending).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        165 output =
                                        500 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">59 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">114 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_no_report_when_disabled</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin correctly handles cases where no output is specified.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'No report generated when run without a file path', 'expected': 'The report.json file should not exist'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        150 input +
                                        88 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">250 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403-404, 558-559, 562-563, 566-568, 579, 583, 602-603, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_pdf_option_enables_plugin</span>
                            <div class="test-meta">
                                <span>629ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `--llm-pdf` option enables the plugin and triggers its logic.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in plugin integration where --llm-pdf is used without enabling the plugin.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert True, 'Expected test_pass() to be called with no arguments.'</li>
                                            <li>assert result.ret == 0, 'Expected pytester.runpytest('--llm-pdf=report.pdf') to exit with code 0 (success) or warning.'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        435 input +
                                        113 output =
                                        548 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486-488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginHooksWithPytester::test_session_start_records_time</span>
                            <div class="test-meta">
                                <span>65ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that pytest_sessionstart records start time is verified by Pytester.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the start time of the session is not recorded correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'start_time' key should be present in the run_meta dictionary.</li>
                                            <li>The value of the 'start_time' key should be a valid timestamp.</li>
                                            <li>The 'start_time' value should be greater than or equal to 0.</li>
                                            <li>The start time should not be None.</li>
                                            <li>The start time should be within the expected range (e.g., between 2023-01-01 00:00:00 and 2024-01-01 23:59:59).</li>
                                            <li>The 'start_time' value should match the actual start time of the session recorded by pytest_sessionstart.</li>
                                            <li>The test should fail if the start time is not within the expected range or is None.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        205 output =
                                        481 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">75 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_context_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestPluginIntegration::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_integration.py</p>
                                    <p><strong>Why Needed:</strong> The requirement marker is used to mark requirements as having a plugin. This helps in identifying which requirements require plugins and can be useful for testing purposes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'Requirement marker should not cause errors.', 'expected_result': 'True', 'message': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        88 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_integration.py::TestReportGeneration::test_report_writer_integration</span>
                            <div class="test-meta">
                                <span>48ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the integration of report writer with pytest_llm_report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when integrating report writer with pytest_llm_report, as it ensures that all tests are properly formatted and include required information for a full report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report JSON file exists at `report.json` in the specified temporary directory.</li>
                                            <li>The total count of passed tests is 1 (test_a.py::test_pass) out of 2 (total)</li>
                                            <li>All test names are included in the report HTML, specifically including `test_a.py` and `test_b.py`.</li>
                                            <li>The report HTML file exists at `report.html` in the specified temporary directory.</li>
                                            <li>The report HTML contains a reference to each test name (`test_a.py` and `test_b.py`).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        417 input +
                                        179 output =
                                        596 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_plugin_maximal.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">26 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">


                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 579-580, 586-587)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginCollectReport</p>
                                    <p><strong>Why Needed:</strong> To test the collectreport functionality when it is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_collector.handle_collection_report was called once with mock_report', 'expected': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        204 input +
                                        68 output =
                                        272 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 558-559, 562, 566-568, 579-580, 586, 590-592)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_no_session</p>
                                    <p><strong>Why Needed:</strong> To ensure that collectreport does not throw an exception when a session is not available.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_report.session', 'expected_value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        138 input +
                                        81 output =
                                        219 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginCollectReport::test_pytest_collectreport_session_none</p>
                                    <p><strong>Why Needed:</strong> To ensure that the collectreport plugin behaves correctly when a Pytest session is None.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytest_collectreport() should not be called with a mock report object that has a None session attribute', 'description': 'The pytest_collectreport function should not be called with a mock report object that has a None session attribute.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        115 output =
                                        249 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 579, 583)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_llm_enabled_warning</p>
                                    <p><strong>Why Needed:</strong> LLM enabled warning is raised when pytest is run with the --llm flag.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'LLM enabled flag is present in pyproject.toml', 'value': 'True'}</li>
                                            <li>{'name': 'pyproject.toml does not exist or is empty', 'value': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        115 output =
                                        258 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_validation_errors</p>
                                    <p><strong>Why Needed:</strong> Validation errors are raised when the pytest configuration is invalid.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pytest_configure raises UsageError', 'description': 'The pytest_configure function should raise a UsageError if the configuration is invalid.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        87 output =
                                        221 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">135 lines (ranges: 123, 171, 199, 202-205, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-358, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigure::test_pytest_configure_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginConfigure::test_pytest_configure_worker_skip</p>
                                    <p><strong>Why Needed:</strong> To ensure that the configure function skips on xdist workers correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_config.addinivalue_line.called', 'expected_result': True}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        170 input +
                                        72 output =
                                        242 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 328-330, 332-334, 336-338, 342-343, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginConfigureFallback::test_pytest_configure_fallback_load</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that fallback to load_config is triggered when Config.load is missing.</p>
                                    <p><strong>Why Needed:</strong> To prevent regression where Config.load is missing, and the plugin falls back to load_config.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Mocking Config.load with None returns a mock object.</li>
                                            <li>Mocking load_config with no arguments calls validate() on mock_cfg.</li>
                                            <li>mock_load.assert_called_once() checks that load_config was called once.</li>
                                            <li>mock_cfg.validate.return_value is an empty list.</li>
                                            <li>mock_load.return_value is mock_cfg, which has the correct option values.</li>
                                            <li>Pytest_configure(mock_config) passes mock_config to load_config.</li>
                                            <li>load_config() does not call any other functions or methods on mock_cfg.</li>
                                            <li>The test fails if Config.load is missing and load_config is called without arguments.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        747 input +
                                        179 output =
                                        926 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_cli_overrides_pyproject</p>
                                    <p><strong>Why Needed:</strong> To test the plugin's ability to load configuration files with CLI options overriding those in pyproject.toml.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file creation', 'expected': 'pyproject.toml was created successfully', 'actual': 'pyproject.toml was not created'}</li>
                                            <li>{'name': 'pyproject.toml content', 'expected': 'pyproject.toml content was created with the correct CLI options', 'actual': 'pyproject.toml content was not created with the correct CLI options'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        159 output =
                                        299 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-334, 336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599-607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_from_pyproject</span>
                            <div class="test-meta">
                                <span>120ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginLoadConfig::test_load_config_from_pyproject</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin can load configuration files from the PyPI repository.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'pyproject.toml file exists', 'expected': 'True'}</li>
                                            <li>{'name': 'pyproject.toml file is not empty', 'expected': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        105 output =
                                        241 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 123, 171, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360-362, 364, 366, 368, 372, 374, 378, 380, 382-384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that terminal summary skips when plugin is disabled.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the plugin's terminal summary might be incorrectly reported as enabled even though it's not.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>mocked stash.get() was called once with _enabled_key and False argument.</li>
                                            <li>Mocking stash.get() to return False for enabled is necessary because pytest_terminal_summary() relies on this assertion.</li>
                                            <li>pytest_terminal_summary() should have checked if the plugin is enabled before reporting its terminal summary.</li>
                                            <li>The test verifies that the plugin's terminal summary is skipped when it's disabled.</li>
                                            <li>This test ensures that the plugin's terminal summary is correctly reported as disabled even without worker input.</li>
                                            <li>Without this test, there might be a false positive report of the plugin being enabled when it's not.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        281 input +
                                        179 output =
                                        460 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 399, 403-404, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_worker_skip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginMaximal::test_terminal_summary_worker_skip</p>
                                    <p><strong>Why Needed:</strong> To test that terminal summary skips on xdist worker.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'is_none', 'expected_result': 'None'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        164 input +
                                        74 output =
                                        238 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 399-400, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginMaximal::testload_config</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test config loading from pytest objects (CLI) to ensure the correct value is set for llm_report_html.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the correct value for llm_report_html is not being set, potentially leading to incorrect configuration output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `llm_report_html` option should be set to 'out.html'.</li>
                                            <li>The `llm_report_json` option should be set to 'out.json'.</li>
                                            <li>The `llm_report_pdf` option should be set to None.</li>
                                            <li>The `llm_evidence_bundle` option should be set to None.</li>
                                            <li>The `llm_dependency_snapshot` option should be set to None.</li>
                                            <li>The `llm_requests_per_minute` option should be set to None.</li>
                                            <li>The `llm_aggregate_dir` option should be set to None.</li>
                                            <li>The `llm_aggregate_policy` option should be set to None.</li>
                                            <li>The `llm_aggregate_run_id` option should be set to None.</li>
                                            <li>The `llm_aggregate_group_id` option should be set to None.</li>
                                            <li>The `llm_max_retries` option should be set to None.</li>
                                            <li>The `llm_coverage_source` option should be set to None.</li>
                                            <li>The `llm_prompt_tier` option should be set to None.</li>
                                            <li>The `llm_batch_parametrized` option should be set to None.</li>
                                            <li>The `llm_context_compression` option should be set to None.</li>
                                            <li>The `llm_context_bytes` option should be set to None.</li>
                                            <li>The `llm_context_file_limit` option should be set to None.</li>
                                            <li>The `llm_max_tests` option should be set to None.</li>
                                            <li>The `llm_max_concurrency` option should be set to None.</li>
                                            <li>The `llm_timeout_seconds` option should be set to None.</li>
                                            <li>The `llm_capture_failed` option should be set to None.</li>
                                            <li>The `llm_ollama_host` option should be set to None.</li>
                                            <li>The `llm_litellm_api_base` option should be set to None.</li>
                                            <li>The `llm_litellm_api_key` option should be set to None.</li>
                                            <li>The `llm_litellm_token_refresh_command` option should be set to None.</li>
                                            <li>The `llm_litellm_token_refresh_interval` option should be set to None.</li>
                                            <li>The `llm_litellm_token_output_format` option should be set to None.</li>
                                            <li>The `llm_litellm_token_json_key` option should be set to None.</li>
                                            <li>The `llm_cache_dir` option should be set to the value of `tmp_path`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        639 input +
                                        587 output =
                                        1226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 123, 171, 308, 311-312, 320-322, 460-461, 463-464, 466-467, 470, 472-473, 476-477, 482-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_disabled</p>
                                    <p><strong>Why Needed:</strong> The test is failing because the makereport hookwrapper is not completing successfully.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'gen.send(mock_outcome).exception', 'expected_type': 'StopIteration'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        220 input +
                                        86 output =
                                        306 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 558-559, 562-563, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginRuntest::test_runtest_makereport_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that makereport calls collector when enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the plugin does not report any errors even if makereport is called.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytest_runtest_makereport` function should be able to find and call the `mock_collector` instance when it is enabled.</li>
                                            <li>The `mock_collector.handle_runtest_logreport` method should be called with the `mock_report` object as its argument.</li>
                                            <li>The `mock_collector` instance should have a `handle_runtest_logreport` method that takes two arguments: `mock_report` and `mock_item`.</li>
                                            <li>The `mock_collector` instance should be able to handle runtest log reports by calling the `handle_runtest_logreport` method.</li>
                                            <li>The `pytest_runtest_makereport` function should not call any other functions or methods on the `mock_collector` instance when it is enabled.</li>
                                            <li>The `mock_collector` instance should have a `stash_get` method that returns `True` for `_enabled_key` and `mock_collector` instances, and `None` otherwise.</li>
                                            <li>The `stash_get` method should return `False` for `_collector_key` and `None` otherwise.</li>
                                            <li>The `stash_get` method should not raise an exception when called with a key that is neither `_enabled_key` nor `_collector_key`.</li>
                                            <li></key_assertions></li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        371 input +
                                        317 output =
                                        688 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_disabled</p>
                                    <p><strong>Why Needed:</strong> This test is needed because the pytest_collection_finish function should skip collection finish when disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_session.config.stash.get.assert_called_with(_enabled_key, False)', 'description': 'Verify that stash.get was called with _enabled_key and False as arguments.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        149 input +
                                        103 output =
                                        252 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 602-603)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_collection_finish_enabled</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginSessionHooks</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `pytest_collection_finish` function calls the `_collector_key` collector when collection finish is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Mocking pytest_collection_finish with mock_collector', 'expected_result': 1, 'actual_result': 0}</li>
                                            <li>{'name': 'Mocking stash_get with _enabled_key and _collector_key', 'expected_result': ['True', 'mock_collector'], 'actual_result': ['True', 'mock_collector']}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        219 input +
                                        134 output =
                                        353 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 558-559, 562, 566-568, 602, 606-608)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_disabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginSessionHooks</p>
                                    <p><strong>Why Needed:</strong> To ensure that the plugin correctly handles session start when disabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'mock_session.get', 'expected_calls': [{'_enabled_key': '_enabled_key', 'False': []}]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        157 input +
                                        76 output =
                                        233 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 558-559, 562, 566-568, 619-620)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginSessionHooks::test_pytest_sessionstart_enabled</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that sessionstart initializes collector when enabled and creates a stash with both get() and [] methods.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where the collector is not created or does not have access to the stash, potentially leading to incorrect data collection or other issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The _collector_key should be present in the mock_stash dictionary.</li>
                                            <li>The _start_time_key should also be present in the mock_stash dictionary.</li>
                                            <li>The collector should have been created successfully by pytest_sessionstart.</li>
                                            <li>_enabled_key should be set to True in stash_dict.</li>
                                            <li>Config() should have been created with stash_dict.</li>
                                            <li>pytest_sessionstart() should not raise any exceptions when called with a valid stash.</li>
                                            <li>The mock_stash should contain both get() and [] methods.</li>
                                            <li>The mock_stash should contain the _enabled_key and _config_key keys.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        198 output =
                                        533 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 558-559, 562, 566-568, 619, 623, 626, 628-629)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test pytest_addoption adds expected arguments and verifies specific options.</p>
                                    <p><strong>Why Needed:</strong> pytest_addoption prevents a potential bug where the plugin does not add all required arguments to the parser.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>parser.getgroup.assert_called_with('llm-report', 'LLM-enhanced test reports')</li>
                                            <li>group.addoption.call_args_list[0][0] == '--llm-report'</li>
                                            <li>group.addoption.call_args_list[1][0] == '--llm-coverage-source'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        117 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_pytest_addoption_no_ini</p>
                                    <p><strong>Why Needed:</strong> pytest_addoption no longer adds INI options</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'parser.addini was not called', 'expected_result': 0, 'actual_result': 1}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        140 input +
                                        85 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">220 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_coverage_calculation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage percentage calculation logic for terminal summary.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in coverage reporting when terminal summary is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report_html` option should be set to 'out.html' before calling `pytest_terminal_summary()`.</li>
                                            <li>The `CoverageMapper` instance should be created with the correct configuration.</li>
                                            <li>The `Coverage` object should have a report method that returns the coverage percentage correctly.</li>
                                            <li>The `MockStash` instance should be used as expected in the mock configuration.</li>
                                            <li>The `coverage.Coverage` class should be instantiated and returned correctly from the mock.</li>
                                            <li>The `pytest_llm_report.coverage_map.CoverageMapper` class should be patched to return a mock object.</li>
                                            <li>The `pytest_llm_report.report_writer.ReportWriter` class should be patched to return a mock object with a report method that returns 85.5 as expected.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        395 input +
                                        203 output =
                                        598 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">53 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 468, 470-473, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_llm_enabled</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary with LLM enabled runs annotations.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression by ensuring that the plugin is correctly configured when LLM is enabled.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Verify that the `pytest_terminal_summary_llm_enabled` test function is executed only once.</li>
                                            <li>Check if the correct configuration is passed to `pytest_terminal_summary`.</li>
                                            <li>Verify that the LLM annotator is called with the correct arguments.</li>
                                            <li>Ensure that the provider is correctly retrieved and used.</li>
                                            <li>Verify that the coverage map is not modified during testing.</li>
                                            <li>Confirm that the report writer is properly initialized.</li>
                                            <li>Check if the LLM model name matches the expected value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        477 input +
                                        152 output =
                                        629 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">66 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-486, 491-494, 497, 499, 502-504, 512-514, 516, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_no_collector</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary creates collector if missing.</p>
                                    <p><strong>Why Needed:</strong> The test prevents a potential bug where the plugin does not create a collector even when it is supposed to be present in the configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert mock_config.stash._enabled_key == True</li>
                                            <li>assert mock_config.stash._config_key == cfg</li>
                                            <li>assert mock_terminalreporter.call_args_list[0][1] == [0, {}]</li>
                                            <li>assert mock_mapper.map_coverage.return_value == {}</li>
                                            <li>assert mock_writer_cls.return_value.report_writer.call_args_list[0][1] == [0, {}]</li>
                                            <li>assert stash._enabled_key == True and stash._config_key == cfg</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        391 input +
                                        157 output =
                                        548 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">45 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummary::test_terminal_summary_with_aggregation</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test terminal summary with aggregation enabled.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the case where aggregation is enabled and there are multiple terminals being reported.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The aggregate_dir parameter should be set to '/agg' when aggregation is enabled.</li>
                                            <li>The stash object should support both get() and [] methods.</li>
                                            <li>The aggregator function should return a report when aggregate=True.</li>
                                            <li>The ReportWriter class should write JSON and HTML files correctly when aggregate=True.</li>
                                            <li>The aggregate method of the Aggregator class should be called once when aggregate=True.</li>
                                            <li>The aggregation flag should be set to True in the config object.</li>
                                            <li>The stash object should have an _enabled_key with value True.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        441 input +
                                        159 output =
                                        600 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">21 lines (ranges: 399, 403, 407, 410-411, 413-414, 417-418, 420, 422-426, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_plugin_maximal.py::TestPluginTerminalSummaryErrors::test_terminal_summary_coverage_error</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test coverage calculation error when loading coverage map.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the coverage calculation fails due to an OSError during load.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert mock_cov_cls.return_value is None</li>
                                            <li>assert mock_cov.load.side_effect == OSError('Disk full')</li>
                                            <li>assert pytest_terminal_summary(MagicMock(), 0, mock_config).report_html is None</li>
                                            <li>assert mock_config.stash._enabled_key is True</li>
                                            <li>assert mock_config.stash._config_key is cfg</li>
                                            <li>assert _enabled_key in mock_config.stash</li>
                                            <li>assert _config_key in mock_config.stash</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        389 input +
                                        145 output =
                                        534 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 123, 171, 284)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">52 lines (ranges: 399, 403, 407, 410, 429-430, 432, 434, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-466, 476-479, 485-486, 491-492, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">7 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_balanced_context</span>
                            <div class="test-meta">
                                <span>7ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests the ContextAssembler with a balanced context configuration to ensure it correctly includes dependencies and passes coverage tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the ContextAssembler correctly assembles a balanced context, including all necessary dependencies.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'utils.py' file is present in the assembled context.</li>
                                            <li>The 'def util()' function is found in the 'utils.py' file within the assembled context.</li>
                                            <li>The coverage report includes the 'utils.py' file and the 'def util()' function.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        122 output =
                                        453 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">63 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_complete_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts.py::TestContextAssembler::test_assemble_complete_context</p>
                                    <p><strong>Why Needed:</strong> To test the ContextAssembler's ability to assemble a complete context for a test file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'expected_value': 'test_1', 'actual_value': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        176 input +
                                        87 output =
                                        263 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116, 139-140, 268-272)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_assemble_minimal_context</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ContextAssembler with minimal context mode and a test file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression when using minimal context mode without specifying a repository root.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'test_1' function is present in the source code of the test file.</li>
                                            <li>The context for the test function is empty.</li>
                                            <li>The test result nodeid matches the expected outcome.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        267 input +
                                        94 output =
                                        361 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_balanced_context_limits</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the ContextAssembler with balanced context limits to ensure it does not truncate long content within a file.</p>
                                    <p><strong>Why Needed:</strong> This test prevents bugs that may occur when the ContextAssembler is used with large files, causing the context to be truncated unnecessarily.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'f1.py' file in the test result should contain the original long content.</li>
                                            <li>The 'truncated' message should not appear within the 'f1.py' file in the test result.</li>
                                            <li>The length of the 'f1.py' file in the test result should be less than or equal to 40 bytes (20 bytes + truncation message).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        335 input +
                                        147 output =
                                        482 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">46 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_complete_context_limits_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that 'complete' mode does not truncate long files despite a small llm_context_bytes limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the LLM context size exceeds the file content size, causing truncation of long files in complete mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Context is present in the assembled output.</li>
                                            <li>File content is preserved and not truncated.</li>
                                            <li>The 'truncated' assertion is not triggered.</li>
                                            <li>Context does not contain any 'truncated' key.</li>
                                            <li>Context size matches the file content size.</li>
                                            <li>LLM context bytes limit is respected for long files.</li>
                                            <li>Context assembler correctly handles large files in complete mode.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        361 input +
                                        150 output =
                                        511 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">50 lines (ranges: 33, 49, 52, 55, 58, 60, 63, 65, 78-79, 82-84, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_get_test_source_edge_cases</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify the correct handling of non-existent files and nested test names with parameters.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler incorrectly handles cases where the test file does not exist or has nested test names with parameters.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `_get_test_source` returns an empty string when given a non-existent file path.</li>
                                            <li>The function `_get_test_source` correctly identifies the nested test name with parameters in the provided source code.</li>
                                            <li>The function `_get_test_source` handles nested test names with parameters by including the parameter value in the source code.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        275 input +
                                        135 output =
                                        410 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 33, 78-79, 82-84, 86-87, 92, 94-95, 98-101, 103-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts.py::TestContextAssembler::test_should_exclude</span>
                            <div class="test-meta">
                                <span>2ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the ContextAssembler should exclude certain Python files and directories from being processed.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the ContextAssembler incorrectly includes certain files or directories in its processing, leading to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert assembler._should_exclude('test.pyc') is True</li>
                                            <li>assert assembler._should_exclude('secret/key.txt') is True</li>
                                            <li>assert assembler._should_exclude('public/readme.md') is False</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        227 input +
                                        114 output =
                                        341 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 33, 284-287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_prompts_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_minimal_mode</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble minimal mode returns no context files.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where the assemble function does not generate any context files when run in minimal mode.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context_files == {}</li>
                                            <li>def test_foo()</li>
                                            <li>test_source contains 'def test_foo'</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        78 output =
                                        376 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_assemble_with_context_override</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test assemble respects llm_context_override from test.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring the ContextAssembler uses the correct mode when overriding LLM context.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>ContextAssembler should use balanced mode due to override.</li>
                                            <li>ContextAssembler should include module.py in context_files.</li>
                                            <li>ContextAssembler should respect llm_context_override from test.</li>
                                            <li>Test assemble respects llm_context_override from test.</li>
                                            <li>ContextAssembler should not modify test file content when overriding LLM context.</li>
                                            <li>ContextAssembler should preserve original file path and line information when assembling with override mode.</li>
                                            <li>ContextAssembler should use correct mode for assembly (balanced in this case).</li>
                                            <li>ContextAssembler should respect the specified llm_context_override value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        362 input +
                                        166 output =
                                        528 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 33, 49, 52, 55, 58, 60-61, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_excludes_patterns</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_balanced_context_excludes_patterns' verifies that a balanced context excludes files matching exclude patterns.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the LLM context mode is set to 'balanced', and it includes files in the context that match exclude patterns.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file 'secret_config.py' should not be included in the balanced context.</li>
                                            <li>The file 'test_foo.py' should not be included in the balanced context.</li>
                                            <li>The LLM context mode is set to 'balanced', and it excludes files matching exclude patterns.</li>
                                            <li>The LLM context include glob pattern '*secret*' is excluded from the balanced context.</li>
                                            <li>The coverage of the test file 'secret_config.py' under the balanced context should be 0%.</li>
                                            <li>The coverage of the test file 'test_foo.py' under the balanced context should be 0%.</li>
                                            <li>The LLM context exclude glob pattern '*secret*' is not included in the output files.</li>
                                            <li>The LLM context include glob pattern '**/*' is excluded from the balanced context.</li>
                                            <li>The LLM context include glob pattern '**/*' excludes files that match exclude patterns.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        254 output =
                                        585 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163-164, 201, 284-286)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_file_not_exists</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler correctly handles cases where a balanced context file is not found.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'context is empty', 'description': 'The ContextAssembler should return an empty dictionary when no balanced context file exists.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        201 input +
                                        96 output =
                                        297 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-161, 201)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_max_bytes_limit</span>
                            <div class="test-meta">
                                <span>14ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that balanced context respects max bytes limit.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the LLM context exceeds the maximum allowed bytes, causing truncated content.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The content of the source file is not longer than 120 bytes.</li>
                                            <li>The LLM context is not truncated when the source file exceeds 6000 bytes.</li>
                                            <li>The LLM context is truncated when the source file exceeds 10000 bytes (1000 + 9000).</li>
                                            <li>The LLM context does not exceed the maximum allowed bytes even if it contains a large number of lines.</li>
                                            <li>The LLM context does not contain any 'truncated' messages when the source file exceeds 6000 bytes.</li>
                                            <li>The LLM context is truncated only after the last line of the source file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        405 input +
                                        180 output =
                                        585 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">34 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_no_coverage</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler can correctly assemble a balanced context with no coverage.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'equals', 'expected_value': '{}', 'actual_value': '{}'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        162 input +
                                        86 output =
                                        248 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 33, 139-140)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_balanced_context_reaches_max_bytes_before_file</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that loop exits when max bytes is reached before processing file.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential memory leak by ensuring the context assembler does not exceed the maximum allowed bytes before processing files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>context should have only one node (either 'file1.py' or 'file2.py')</li>
                                            <li>context length should be less than or equal to 1</li>
                                            <li>context should contain both file paths and their respective lines and line counts</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        409 input +
                                        110 output =
                                        519 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">35 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-157, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-194, 196-197, 201, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_complete_context_delegates_to_balanced</p>
                                    <p><strong>Why Needed:</strong> To ensure that complete context delegates to balanced correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'inclusion', 'expected_values': ['module.py'], 'actual_value': 'module.py'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        87 output =
                                        298 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/context_util.py</span>
                                        <span style="color: var(--text-secondary)">17 lines (ranges: 27, 29, 33, 35-36, 64, 66-69, 108, 124, 126-127, 129, 133, 135)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">38 lines (ranges: 33, 139, 142-145, 147-148, 152-153, 155-156, 159-160, 163, 166-167, 170-171, 173-174, 177, 181-182, 189, 192-193, 196-197, 201, 268-272, 284-285, 287)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_empty_nodeid</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test _get_test_source with empty nodeid returns empty string</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ContextAssembler correctly handles an empty node ID in the test source.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_name': 'result == ""', 'expected_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        148 input +
                                        74 output =
                                        222 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 33, 78-79, 82-83, 86-89)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_extraction_stops_at_next_def</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_extraction_stops_at_next_def</p>
                                    <p><strong>Why Needed:</strong> To ensure that source extraction stops at the next function definition, even if there are multiple definitions in a single file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The test source extraction should stop at the next function definition.', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        100 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_file_not_exists</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Edge Case: Test Source File Not Exists</p>
                                    <p><strong>Why Needed:</strong> The test assembly function `_get_test_source` should handle cases where the test source file does not exist.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': 'Test that the function returns an empty string for a non-existent test source file.', 'expected_result': '', 'actual_result': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        90 output =
                                        232 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 33, 78-79, 82-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class</p>
                                    <p><strong>Why Needed:</strong> To ensure that the _get_test_source function correctly extracts functions with proper indentation, even when they are nested within other code blocks.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected output is a string', 'expected_value': 'test_example.py', 'actual_value': {'scenario': 'tests/test_prompts_coverage.py::TestContextAssemblerEdgeCases::test_get_test_source_with_class', 'why_needed': 'To ensure that the _get_test_source function correctly extracts functions with proper indentation, even when they are nested within other code blocks.', 'key_assertions': ['Expected output is a string'], 'value': 'test_example.py'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        174 output =
                                        292 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 33, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-112, 114, 116)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_ranges.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">13 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> To ensure that consecutive lines are compressed into a single range.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3', 'actual': '1-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        72 output =
                                        178 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_duplicates</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_duplicates</p>
                                    <p><strong>Why Needed:</strong> To test the handling of duplicate ranges in the compress_ranges function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3', 'actual': '1-2'}</li>
                                            <li>{'expected': '2-4', 'actual': '2-3'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        107 input +
                                        93 output =
                                        200 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_empty_list</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_empty_list</p>
                                    <p><strong>Why Needed:</strong> Because an empty list is considered a valid input for the `compress_ranges` function.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '', 'actual_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        92 input +
                                        70 output =
                                        162 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 29-30)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_mixed_ranges</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of compressing mixed ranges in a list.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3, 5, 10-12, 15', 'actual': '1-3, 5, 10-12, 15'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        130 input +
                                        95 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_non_consecutive_lines</p>
                                    <p><strong>Why Needed:</strong> To ensure that non-consecutive lines are correctly compressed to a single comma-separated value.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '1, 3, 5', 'actual_value': '1, 3, 5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        113 input +
                                        88 output =
                                        201 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 29, 33, 35-37, 39-40, 45-47, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_single_line</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_single_line</p>
                                    <p><strong>Why Needed:</strong> The single line should be compressed using the range notation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': 5, 'actual': '5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        96 input +
                                        66 output =
                                        162 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 29, 33, 35-37, 39, 50, 52, 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_two_consecutive</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_two_consecutive</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because the current implementation does not handle two consecutive lines correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-2', 'actual': '1-2'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        103 input +
                                        76 output =
                                        179 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 29, 33, 35-37, 39-40, 42, 50, 52, 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestCompressRanges::test_unsorted_input</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestCompressRanges::test_unsorted_input</p>
                                    <p><strong>Why Needed:</strong> The test is necessary to ensure that the `compress_ranges` function can handle unsorted input correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '1-3, 5', 'actual': '1-3, 5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        86 output =
                                        196 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_empty_string</p>
                                    <p><strong>Why Needed:</strong> The current implementation does not handle empty strings correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [], 'actual': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        90 input +
                                        60 output =
                                        150 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 81-82)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_mixed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_mixed</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks for the correct expansion of mixed ranges and singles.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3, 5, 10, 11, 12], 'actual': ['1', '2', '3', '5', '10', '11', '12']}</li>
                                            <li>{'expected': [], 'actual': []}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        113 output =
                                        234 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_range</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_range</p>
                                    <p><strong>Why Needed:</strong> The range function is not correctly expanding the input string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': [1, 2, 3], 'actual': ['1', '2', '3']}</li>
                                            <li>{'expected': "expand_ranges('1-3')", 'actual': "['1', '2', '3']"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        99 input +
                                        99 output =
                                        198 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">10 lines (ranges: 81, 84-91, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_roundtrip</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> compress_ranges and expand_ranges should be inverses.</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the `compress_ranges` and `expand_ranges` functions are inverse operations, meaning they can be used to reconstruct the original list from a compressed representation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'original == expanded', 'expected': [1, 2, 3, 5, 10, 11, 12, 15], 'message': 'Original and expanded lists must be equal.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        134 input +
                                        116 output =
                                        250 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 29, 33, 35-37, 39-40, 42, 45-47, 50, 52, 65-67, 81, 84-91, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_ranges.py::TestExpandRanges::test_single_number</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_ranges.py::TestExpandRanges::test_single_number</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `expand_ranges` function correctly handles a single number as input.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'The output should be an array containing only the single element: 5', 'expected_value': [5]}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        95 input +
                                        85 output =
                                        180 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/ranges.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 81, 84-87, 93, 95)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_render.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestFormatDuration::test_milliseconds verifies that the function correctly formats durations in milliseconds for times less than 1 second.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the function does not format durations as expected for times less than 1 second, potentially leading to incorrect rendering of time-related content.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "durations under 1s are formatted correctly as '0ms'"}</li>
                                            <li>{'description': "durations between 1s and 2s are formatted correctly as '100ms'"}</li>
                                            <li>{'description': "durations exactly equal to 1 second are formatted correctly as '1000ms'"}</li>
                                            <li>{'description': "durations greater than or equal to 2 seconds are formatted correctly as '2000ms'"}</li>
                                            <li>{'description': "durations under 0.5s are formatted correctly as '500ms'"}</li>
                                            <li>{'description': "durations between 0.5s and 1 second are formatted correctly as '1000ms'"}</li>
                                            <li>{'description': "durations exactly equal to 1 second is formatted correctly as '2000ms'"}</li>
                                            <li>{'description': "durations greater than or equal to 2 seconds are formatted correctly as '4000ms'}"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        211 input +
                                        274 output =
                                        485 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65, 67)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestFormatDuration::test_seconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestFormatDuration::test_seconds</p>
                                    <p><strong>Why Needed:</strong> To ensure the function `format_duration` correctly formats time durations in seconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': "Expected format to be '1.23s' for duration 1.23 seconds"}</li>
                                            <li>{'message': "Expected format to be '60.00s' for duration 60 seconds"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        94 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 65-66)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Outcome Mapping to CSS Classes</p>
                                    <p><strong>Why Needed:</strong> To ensure that all outcomes are correctly mapped to their corresponding CSS classes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `outcome_to_css_class` function should map each outcome to a unique CSS class.</li>
                                            <li>The function should handle cases where an outcome is not recognized (e.g., 'xfailed').</li>
                                            <li>The function should preserve the original outcome value when mapping to a CSS class (e.g., 'passed' -> 'outcome-passed').</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        263 input +
                                        116 output =
                                        379 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestOutcomeToCssClass::test_unknown_outcome</p>
                                    <p><strong>Why Needed:</strong> The test is necessary because it checks for the default CSS class when an unknown outcome is encountered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': "outcome_to_css_class('unknown') == 'outcome-unknown'", 'expected_result': 'outcome-unknown'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        102 input +
                                        91 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 79-85, 87)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_basic_report</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that a complete HTML document is rendered with the expected report content.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential rendering issue where the report might not be displayed correctly due to missing or incorrect HTML elements.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The presence of the '<!DOCTYPE html>' header in the rendered HTML.</li>
                                            <li>The inclusion of 'Test Report' in the HTML content.</li>
                                            <li>The presence of 'test::passed' and 'test::failed' node IDs in the HTML.</li>
                                            <li>The correct display of 'PASSED' and 'FAILED' text within the report.</li>
                                            <li>The accurate display of plugin and repository versions in the HTML.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        426 input +
                                        149 output =
                                        575 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65-67, 79-85, 87, 121-124, 126-127, 131-132, 155-157, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders coverage for fallback HTML test.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression and ensures accurate coverage reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'src/foo.py' file should be included in the rendered HTML.</li>
                                            <li>The number of lines rendered should match the total number of lines in the file.</li>
                                            <li>All lines in the file should be present in the rendered HTML.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        90 output =
                                        378 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">57 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-129, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_render.py::TestRenderFallbackHtml::test_renders_llm_annotation</p>
                                    <p><strong>Why Needed:</strong> This test prevents the rendering of LLM annotations with a low confidence score, which could be misleading and potentially lead to security vulnerabilities.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report includes "Tests login flow" in its HTML content.</li>
                                            <li>The report includes "Prevents auth bypass" in its HTML content.</li>
                                            <li>The report includes the string 'Confidence:' in its HTML content with a confidence score of '85%'.</li>
                                            <li>The report does not include any LLM annotations without a confidence score.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        139 output =
                                        456 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">64 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-134, 136-137, 140-142, 144, 147, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_source_coverage</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders source coverage for fallback HTML.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the source coverage summary is not displayed correctly when using fallback HTML.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'Source Coverage' section should be present in the rendered HTML.</li>
                                            <li>The 'src/foo.py' file path should be included in the 'Source Coverage' section.</li>
                                            <li>The percentage of covered code (80.0%) should be displayed correctly in the 'Source Coverage' section.</li>
                                            <li>The ranges of missed code ('1-4, 6-8') and missed files ('5, 9-10') should be accurately represented in the 'Source Coverage' section.</li>
                                            <li>The coverage percentage should be calculated correctly based on the actual number of statements (10) and the total number of lines (12).</li>
                                            <li>The covered code ranges should match the expected values ('1-4', '6-8').</li>
                                            <li>The missed code ranges should match the expected values ('5', '9-10').</li>
                                            <li></source_coverage></li>
                                            <li>key_assertions[0] = True</li>
                                            <li># The 'Source Coverage' section should be present in the rendered HTML.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        331 input +
                                        254 output =
                                        585 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">68 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-178, 180-186, 191, 206, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_render.py::TestRenderFallbackHtml::test_renders_xpass_summary</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test renders xpass summary for ReportRoot report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the 'xfailed/xpassed' summary is not rendered correctly when there are multiple failed and passed tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The string 'XFailed' should be present in the HTML output.</li>
                                            <li>The string 'XPassed' should be present in the HTML output.</li>
                                            <li>Both 'XFailed' and 'XPassed' strings should be found in the HTML output.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        113 output =
                                        396 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65, 67, 79-85, 87, 121-124, 126-127, 131-132, 155-156, 159-167, 172-174, 210-211, 224, 257-264, 267, 269, 271-277, 280-281, 285)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">19 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_different_content</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_different_content</p>
                                    <p><strong>Why Needed:</strong> To ensure that different content produces different hashes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': {'hash': 'd41d8cd98f00b804d0a131e86038e95'}, 'actual': {'hash': '6f5dbce7c8694edd9f2d0783ba3f1d32'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        115 input +
                                        111 output =
                                        226 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestComputeSha256::test_empty_bytes</p>
                                    <p><strong>Why Needed:</strong> To ensure that the test suite is robust and can handle empty input data.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'message': 'Empty bytes should produce consistent hash.', 'expected_result': 'True'}</li>
                                            <li>{'message': 'Hash1 length should be 64 (SHA256 hex length).', 'expected_result': 64}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        129 input +
                                        98 output =
                                        227 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 55)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_run_meta</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'Run meta should include version info' verifies that the test report writer correctly includes version information in the build run metadata.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the test report writer does not include version information in the build run metadata, potentially leading to incorrect reporting or analysis of test results.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The duration of the test should be 60.0 seconds.</li>
                                            <li>The pytest version should have a value.</li>
                                            <li>The plugin version should match the current __version__.</li>
                                            <li>The Python version should match the current __python_version__.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        318 input +
                                        131 output =
                                        449 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">72 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_all_outcomes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `build_summary` method counts all outcome types correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the summary does not include all outcome types, potentially leading to incorrect reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total count of outcomes should be equal to 6 (all outcome types).</li>
                                            <li>The number of passed outcomes should be 1.</li>
                                            <li>The number of failed outcomes should be 1.</li>
                                            <li>The number of skipped outcomes should be 1.</li>
                                            <li>The number of xfailed outcomes should be 1.</li>
                                            <li>The number of xpassed outcomes should be 1.</li>
                                            <li>The number of error outcomes should be 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        336 input +
                                        152 output =
                                        488 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 156-158, 319, 321-322, 324-335, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_build_summary_counts</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `build_summary_counts` method correctly counts outcomes in a test report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the total count of passed, failed and skipped tests is not updated correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total number of tests should be equal to the sum of passed, failed and skipped tests.</li>
                                            <li>The number of passed tests should be equal to the sum of passed outcomes.</li>
                                            <li>The number of failed tests should be equal to the sum of failed outcomes.</li>
                                            <li>The number of skipped tests should be equal to the sum of skipped outcomes.</li>
                                            <li>All test results should have a valid `nodeid` and an associated `outcome`.</li>
                                            <li>The summary should not contain any invalid or missing data.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        283 input +
                                        165 output =
                                        448 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 319, 321-322, 324-329, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_create_writer</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Testing the creation of a ReportWriter instance with a valid configuration.</p>
                                    <p><strong>Why Needed:</strong> This test prevents potential bugs where a new ReportWriter instance is created without properly initializing its configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `config` attribute of the `ReportWriter` instance should be equal to the provided `Config` object.</li>
                                            <li>The `warnings` list of the `ReportWriter` instance should be empty.</li>
                                            <li>The `artifacts` list of the `ReportWriter` instance should be empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        199 input +
                                        117 output =
                                        316 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 156-158)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_assembles_tests</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test writes a report with all assembled tests.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report does not include all tests, potentially leading to incorrect reporting or missing important information.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of the report.tests list should be equal to 2 (the number of tests).</li>
                                            <li>The total value of report.summary.total should be equal to 2 (the number of tests).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        255 input +
                                        99 output =
                                        354 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer.py::TestReportWriter::test_write_report_includes_coverage_percent</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ReportWriter class correctly calculates and returns the total coverage percentage in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert report.summary.coverage_total_percent == 85.5', 'expected_value': 85.5, 'message': 'Expected coverage total percent to be 85.5'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        132 input +
                                        108 output =
                                        240 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">98 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-199, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_includes_source_coverage</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_includes_source_coverage verifies that the test writes a report with source coverage summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report does not include source coverage information, which is crucial for debugging and tracking changes in codebase.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The length of `report.source_coverage` should be 1.</li>
                                            <li>The file path of the first element in `report.source_coverage` should match 'src/foo.py'.</li>
                                            <li>All elements in `report.source_coverage` should have a valid `file_path` attribute.</li>
                                            <li>Each element in `report.source_coverage` should have a corresponding `covered` value between 0 and 100.</li>
                                            <li>The total coverage percentage of all covered statements should be greater than or equal to the given coverage percent.</li>
                                            <li>All covered ranges should match one of the provided patterns.</li>
                                            <li>All missed ranges should match an empty string.</li>
                                            <li>Each statement in `source_coverage` should have a corresponding `missed` value between 0 and 100.</li>
                                            <li>The total number of statements in `source_coverage` should be greater than or equal to the given number of statements.</li>
                                            <li>All covered ranges should cover at least one statement.</li>
                                            <li>All missed ranges should not contain any statements.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        291 input +
                                        274 output =
                                        565 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">97 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriter::test_write_report_merges_coverage</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ReportWriter::test_write_report_merges_coverage verifies that the test writes a merged coverage report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the coverage is not properly merged into tests, potentially leading to inaccurate reporting.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report should contain only one coverage entry for the specified test.</li>
                                            <li>The file path of the coverage entry matches the expected file path.</li>
                                            <li>All line ranges and counts in the coverage entry match the expected values.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        285 input +
                                        110 output =
                                        395 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">99 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186-189, 192-193, 197-198, 202, 211-218, 222, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the ReportWriterWithFiles class falls back to direct write if atomic write fails and writes warnings.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the ReportWriterWithFiles class does not fall back to direct write when an atomic write operation fails, potentially leading to incorrect report generation or data loss.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The file "report.json" exists at the expected location.</li>
                                            <li>Any warnings generated by the ReportWriter are marked with code 'W203'.</li>
                                            <li>The `write_report` method does not raise an exception when writing to a non-existent file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        133 output =
                                        409 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">62 lines (ranges: 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202-206, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513-514, 516-519, 522-523)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_creates_directory_if_missing</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test case 'tests/test_report_writer.py::TestReportWriterWithFiles::test_creates_directory_if_missing'</p>
                                    <p><strong>Why Needed:</strong> Because the test writer does not create an output directory if it already exists.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion': 'The output directory should exist.', 'expected_result': 'True'}</li>
                                            <li>{'assertion': 'The output file should be created.', 'expected_result': 'False'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        171 input +
                                        109 output =
                                        280 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 70-71, 73-75, 77, 79)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">81 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528-530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">128 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-484, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_ensure_dir_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that a directory creation failure prevents the capture of a warning code 'W201' from ReportWriter._ensure_dir.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report writer does not capture warnings when creating directories with permission issues.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `writer.warnings` is populated with warnings that have a code of 'W201'.</li>
                                            <li>The directory creation fails and an OSError is raised.</li>
                                            <li>The `pathlib.Path.mkdir` mock raises an OSError with the message 'Permission denied' when called on the specified path.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        278 input +
                                        129 output =
                                        407 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 156-158, 477-480, 487-491)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_git_info_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test 'test_git_info_failure' verifies that the `get_git_info` function handles git command failures gracefully by returning `None` for both SHA and dirty flag values.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the `get_git_info` function fails to return expected values when it encounters a git command failure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_git_info()` function should not raise an exception when `git` is not found.</li>
                                            <li>The `get_git_info()` function should set both `sha` and `dirty` attributes to `None` in such cases.</li>
                                            <li>The test should be able to run without any issues or errors when the git command fails.</li>
                                            <li>The expected values of `sha` and `dirty` should match the actual output for a successful git command execution.</li>
                                            <li>The function should not raise an exception when it encounters a non-existent git repository.</li>
                                            <li>The function should set both `sha` and `dirty` attributes to `None` even if the git command fails but returns no error message.</li>
                                            <li>The test should be able to handle cases where the git command fails due to other reasons (e.g., network issues, etc.) without crashing or raising an exception.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        231 input +
                                        262 output =
                                        493 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_creates_file</span>
                            <div class="test-meta">
                                <span>45ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the report writer creates an HTML file with expected content.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report writer does not create an HTML file even if there are tests that fail or are skipped.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'report.html' file should exist in the temporary directory.</li>
                                            <li>The 'report.html' file should contain the expected content.</li>
                                            <li>The 'report.html' file should include the following text: 'test1', 'test2', 'PASSED', 'FAILED', 'Skipped', 'XFailed', and 'XPassed'.</li>
                                            <li>The 'report.html' file should not be empty.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        366 input +
                                        149 output =
                                        515 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">120 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_html_includes_xfail_summary</span>
                            <div class="test-meta">
                                <span>46ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that xfail outcomes are included in the HTML summary.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where xfail results are not included in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'XFAILED' keyword is present in the HTML summary.</li>
                                            <li>The 'XFailed' keyword is present in the HTML summary.</li>
                                            <li>The 'XPASSED' keyword is present in the HTML summary.</li>
                                            <li>The 'XPassed' keyword is present in the HTML summary.</li>
                                            <li>All xfail results are included in the report.</li>
                                            <li>No xfail results are excluded from the report.</li>
                                            <li>The report includes a summary of all test outcomes.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        148 output =
                                        456 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">123 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-333, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_json_creates_file</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a JSON file is created with the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the report writer does not create a JSON file.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `report.json` file should be created in the specified path.</li>
                                            <li>At least one artifact should be tracked for the report.</li>
                                            <li>The number of artifacts should be greater than zero.</li>
                                            <li>The `writer.artifacts` list should contain at least one element.</li>
                                            <li>The JSON file should have a valid hash.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        118 output =
                                        383 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_creates_file</span>
                            <div class="test-meta">
                                <span>49ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that the `write_pdf` method creates a PDF file when Playwright is available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the `report_writer` module does not create a PDF file when Playwright is installed.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `writer` object should have created a new PDF file at the specified path.</li>
                                            <li>Any artifacts generated by the test should match the expected path.</li>
                                            <li>The `writer` object should have returned a list of artifact paths that match the expected path.</li>
                                            <li>The `writer` object's `artifacts` attribute should contain any artifacts generated by the test.</li>
                                            <li>The `writer` object's `path` attribute should be set to the expected PDF file path.</li>
                                            <li>Any errors raised during the execution of the `write_pdf` method should have been caught and reported correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        478 input +
                                        186 output =
                                        664 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">130 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408, 417, 419, 421-430, 441-442, 444-450, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer.py::TestReportWriterWithFiles::test_write_pdf_missing_playwright_warns</span>
                            <div class="test-meta">
                                <span>11ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test should warn when Playwright is missing for PDF output.</p>
                                    <p><strong>Why Needed:</strong> To prevent a warning about missing Playwright for PDF output, which may indicate an issue with the test environment.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pdf_path` does not exist after writing the report.</li>
                                            <li>At least one warning has the code `WarningCode.W204_PDF_PLAYWRIGHT_MISSING.value`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        311 input +
                                        95 output =
                                        406 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226, 230-231, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_report_writer_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">10 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</span>
                            <div class="test-meta">
                                <span>3ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_nonexistent_path</p>
                                    <p><strong>Why Needed:</strong> To test that the report writer does not attempt to write to a non-existent Git directory.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert sha is None', 'expected_result': {'type': 'NoneType', 'message': 'git info from nonexistent path should return None'}}</li>
                                            <li>{'name': 'assert dirty is None', 'expected_result': {'type': 'NoneType', 'message': 'git info from nonexistent path should return None'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        139 output =
                                        262 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 67-73, 85-86)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</span>
                            <div class="test-meta">
                                <span>10ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_report_writer_coverage.py::TestGetGitInfo::test_git_info_from_valid_repo</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `get_git_info` function returns a valid git SHA for a valid repository.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result is None or str', 'description': 'The test expects the function to return either None or a string (representing the git SHA).'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        159 input +
                                        103 output =
                                        262 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 67-74, 76-81, 83-84)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_fallback</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test falls back to git runtime when _git_info import fails.</p>
                                    <p><strong>Why Needed:</strong> Prevents a regression where the plugin's Git info cannot be retrieved due to an import failure.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_plugin_git_info()` returns None or a string when the fallback is necessary.</li>
                                            <li>The function `get_plugin_git_info()` does not raise any exceptions when the fallback is necessary.</li>
                                            <li>The function `get_plugin_git_info()` still works via git runtime after the fallback.</li>
                                            <li>The `_git_info` cache is cleared before the fallback occurs.</li>
                                            <li>The `sha` variable is None or a string in the case of a fallback.</li>
                                            <li>The `isinstance(sha, str)` assertion passes when the fallback is necessary.</li>
                                            <li>The function does not raise an exception when the fallback is necessary.</li>
                                            <li>The function still works after clearing the `_git_info` cache.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        253 input +
                                        199 output =
                                        452 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestGetPluginGitInfo::test_plugin_git_info_returns_values</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_get_plugin_git_info</p>
                                    <p><strong>Why Needed:</strong> to ensure plugin git info returns some values</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert sha is not None or isinstance(sha, str)', 'description': "Test that the function returns a non-None value for sha and a string if it's dirty"}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        141 input +
                                        84 output =
                                        225 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 127-128, 130)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterAtomicWrite::test_atomic_write_fallback</span>
                            <div class="test-meta">
                                <span>12ms</span>
                                <span title="Covered file count">üõ°Ô∏è 5</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test atomic write fallback</p>
                                    <p><strong>Why Needed:</strong> To ensure that the ReportWriter can handle unexpected errors during an atomic write operation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected report to be written with correct content', 'description': 'The report should contain the expected key assertions.', 'expected_value': {'scenario': 'Test atomic write fallback', 'why_needed': 'To ensure that the ReportWriter can handle unexpected errors during an atomic write operation.'}}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        181 input +
                                        112 output =
                                        293 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">80 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">122 lines (ranges: 55, 67-74, 76-81, 83-84, 98-99, 102, 105-108, 110, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_exception</span>
                            <div class="test-meta">
                                <span>123ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PDF generation with playwright exception when browser launch fails.</p>
                                    <p><strong>Why Needed:</strong> Prevents test from passing if playwright raises an exception during PDF generation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>Mocked playwright context should raise a RuntimeError when browser launch fails.</li>
                                            <li>Writer should have warnings about PDF failure for the mocked playwright context.</li>
                                            <li>Any warning code in the writer should match 'W201'.</li>
                                            <li>The test should fail if no warnings are present in the writer's output.</li>
                                            <li>The test should pass if all warnings are removed or ignored by the writer.</li>
                                            <li>The writer should not raise an exception when the playwright context is successfully launched and PDF generation proceeds normally.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        356 input +
                                        149 output =
                                        505 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 156-158, 408, 417, 419, 421-423, 431-436, 439, 441-442, 455, 460, 462, 465-469, 477-478)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_pdf_playwright_not_installed</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test PDF generation when playwright is not installed.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the report writer fails to create a PDF file due to playwright being missing.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'W204' warning should be present in the warnings list.</li>
                                            <li>The PDF file 'report.pdf' should not exist.</li>
                                            <li>The 'ReportWriter' instance does not raise an exception when playwright is not installed.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        293 input +
                                        101 output =
                                        394 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">9 lines (ranges: 156-158, 408-412, 415)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_creates_temp</span>
                            <div class="test-meta">
                                <span>37ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that _resolve_pdf_html_source creates a temporary file when no HTML source is provided.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression where the test fails due to missing or empty HTML source configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report writer creates a new temporary file with the suffix '.html'.</li>
                                            <li>The path of the created temporary file exists and matches the expected extension.</li>
                                            <li>The path of the temporary file does not contain any non-existent files (i.e., no actual HTML content).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        265 input +
                                        115 output =
                                        380 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 156-158, 455, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_missing_html_file</span>
                            <div class="test-meta">
                                <span>37ms</span>
                                <span title="Covered file count">üõ°Ô∏è 6</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the test resolves an HTML source when a missing HTML file exists.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of missing HTML files, ensuring correct PDF generation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report writer should be able to resolve the HTML source and generate a PDF.</li>
                                            <li>The resolved path should exist and not point to an empty directory.</li>
                                            <li>The test should fail when the file does not exist, indicating a bug in the configuration or reporting logic.</li>
                                            <li>The temporary file created by the test should be deleted after use.</li>
                                            <li>The report writer should handle missing HTML files correctly, falling back to a temporary file if necessary.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        270 input +
                                        145 output =
                                        415 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">26 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65-67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">13 lines (ranges: 156-158, 455-457, 460, 462, 465-469)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_report_writer_coverage.py::TestReportWriterPDF::test_resolve_html_source_uses_existing</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 4</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the _resolve_pdf_html_source method uses an existing HTML file as its source.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the method does not find any existing HTML files and therefore cannot resolve the PDF.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function writes to the specified HTML path.</li>
                                            <li>The function returns False indicating that is_temp is True.</li>
                                            <li>The function writes to an existing HTML file.</li>
                                            <li>The function checks if the path matches the expected html_path.</li>
                                            <li>The function does not write to a non-existent HTML file.</li>
                                            <li>The function returns True indicating that is_temp is False.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        266 input +
                                        142 output =
                                        408 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 123, 171)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 156-158, 455-458)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_schemas.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">2 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_from_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that `AnnotationSchema.from_dict` can create a full annotation from a dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in case of missing required fields, ensuring the validation logic works correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert schema.scenario == 'Verify login'</li>
                                            <li>assert schema.why_needed == 'Catch auth bugs'</li>
                                            <li>assert schema.key_assertions == ['assert 200', 'assert token']</li>
                                            <li>assert schema.confidence == 0.95</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        276 input +
                                        115 output =
                                        391 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">5 lines (ranges: 77-81)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_schemas.py::TestAnnotationSchema::test_to_dict_full</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_to_dict_full verifies that the AnnotationSchema can convert to a dictionary with all required fields.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression bugs in the AnnotationSchema where it may not be able to generate a full dictionary representation of an annotation.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert data['scenario'] == 'Verify login',</li>
                                            <li>assert data['why_needed'] == 'Catch auth bugs',</li>
                                            <li>assert data['key_assertions'] == ['assert 200', 'assert token'],</li>
                                            <li>assert data['confidence'] == 0.95</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        273 input +
                                        128 output =
                                        401 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">8 lines (ranges: 90-92, 94-98)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_smoke_pytester.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_report_created</span>
                            <div class="test-meta">
                                <span>100ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The HTML report is generated correctly.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential issue where the test does not produce an HTML report even if the function `test_simple` passes.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The report path exists and contains the expected content.</li>
                                            <li>The report path exists and contains the string 'test_simple' in its content.</li>
                                            <li>The report path is a valid file system path.</li>
                                            <li>The report path does not contain any other HTML tags than '<html' and 'test_simple'.</li>
                                            <li>The report path does not contain any other text except for the expected content.</li>
                                            <li>The test function `test_simple` passes correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        147 output =
                                        411 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_html_summary_counts_all_statuses</span>
                            <div class="test-meta">
                                <span>145ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> test_html_summary_counts_all_statuses verifies that HTML summary counts include all statuses.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where the HTML summary counts do not include all statuses, such as when there are multiple failed tests or skipped tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert True is called for each label in the labels list</li>
                                            <li>assert int(match.group(1)) == expected for match in re.findall(card_pattern, html)</li>
                                            <li>assert int(match.group(1)) == expected for match in re.findall(fallback_pattern, html)</li>
                                            <li>assert_summary(['Total Tests', 'Total'], 6) is not called</li>
                                            <li>assert_summary(['Passed'], 1) is called and asserts True</li>
                                            <li>assert_summary(['Failed'], 1) is called and asserts False</li>
                                            <li>assert_summary(['Skipped'], 1) is called and asserts True</li>
                                            <li>assert_summary(['XFailed'], 1) is called and asserts False</li>
                                            <li>assert_summary(['XPassed'], 1) is called and asserts True</li>
                                            <li>assert_summary(['Errors', 'Error'], 1) is called and asserts True</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        621 input +
                                        242 output =
                                        863 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">69 lines (ranges: 78-79, 90, 93-94, 96, 99-104, 106-107, 109-112, 114-119, 121-122, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212-214, 216, 227-228, 230-236, 250-251, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">116 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-335, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_json_report_created</span>
                            <div class="test-meta">
                                <span>73ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The JSON report is created and contains the expected schema version, summary statistics, and test counts.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the report generation process fails to create a valid JSON file with the required metadata.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `schema_version` key in the report data should be set to '1.0'.</li>
                                            <li>The `summary` object should contain exactly two keys: `total` and `passed`.</li>
                                            <li>The `summary` object should have a single key-value pair for `failed`, with a value of 1.</li>
                                            <li>The number of tests passed should match the total count in the report.</li>
                                            <li>The number of failed tests should match the failed count in the report.</li>
                                            <li>The JSON data should be well-formed and contain only valid JSON syntax.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        295 input +
                                        180 output =
                                        475 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-118, 124, 127, 132-133, 140-141, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 227-228, 230-236, 261, 264, 268, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-327, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_annotations_in_report</span>
                            <div class="test-meta">
                                <span>66ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that LLM annotations are included in the report when a provider is enabled.</p>
                                    <p><strong>Why Needed:</strong> Prevent regressions by ensuring LLM annotations are present in the report.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `test_pass()` passes without any errors.</li>
                                            <li>The `pytester.makepyfile` call returns a valid test file.</li>
                                            <li>The `pytester.makeconftest` call creates a conftest that patches litellm.completion before it's imported.</li>
                                            <li>The `pytester.makefile` call creates a pyproject.toml configuration with the [tool.pytest_llm_report] setting.</li>
                                            <li>The `pytester.makepyfile` call returns a valid test file after the patch is applied.</li>
                                            <li>The `pytester.makeconftest` call sets up the conftest to use the patched completion function.</li>
                                            <li>The `pytester.makefile` call creates a pyproject.toml configuration with the [tool.pytest_llm_report] setting.</li>
                                            <li>The `pytester.makepyfile` call returns a valid test file after the patch is applied and the config is set up.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        385 input +
                                        246 output =
                                        631 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 39-41, 53, 55-56, 86, 90, 92, 94, 97-101, 103, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">96 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221, 223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">55 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 325-326, 329-330, 333-334, 337-339, 342, 344, 346, 351, 353-357, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 170-174, 176-178, 182, 186-187, 190, 192-193, 196, 204, 213, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/schemas.py</span>
                                        <span style="color: var(--text-secondary)">7 lines (ranges: 38, 42-43, 50-53)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">103 lines (ranges: 130-133, 135-137, 139, 141, 143, 190, 194-199, 201, 203, 205, 207, 210, 212-214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419-437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-506, 509, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">115 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestBasicReportGeneration::test_llm_error_is_reported</span>
                            <div class="test-meta">
                                <span>105ms</span>
                                <span title="Covered file count">üõ°Ô∏è 14</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that LLM errors are surfaced in HTML output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where LLM errors might not be reported in the expected format.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `test_llm_error_is_reported` should raise an error when executed with the given input.</li>
                                            <li>The error message should include the string 'boom'.</li>
                                            <li>The HTML output of the test should contain a table with the error details.</li>
                                            <li>The table columns should be labeled correctly (e.g., 'Error Type', 'Error Message').</li>
                                            <li>The error type column should display the correct value ('LLM Error').</li>
                                            <li>The error message column should display the correct text ('boom').</li>
                                            <li>The test output should include a descriptive title indicating that an LLM error occurred.</li>
                                            <li>The test output should contain a link to the LLM error report (if available).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        313 input +
                                        198 output =
                                        511 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/cache.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 39-41, 53, 55-56, 86, 88, 118-119, 121, 153)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">39 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/annotator.py</span>
                                        <span style="color: var(--text-secondary)">100 lines (ranges: 47, 50-51, 58-59, 65, 67, 70, 73-74, 76, 84, 86-89, 95-96, 98-99, 106-108, 112-113, 116, 121-122, 132, 134, 137-141, 144-151, 181-182, 184, 186, 188, 199-206, 213-219, 221-223, 249-252, 254-255, 257-258, 260, 262, 264, 269-274, 277-279, 281, 283-284, 289-290, 292-295, 298-301, 303)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/base.py</span>
                                        <span style="color: var(--text-secondary)">37 lines (ranges: 65-66, 87-89, 97, 105, 134, 137-138, 155, 163, 174, 185, 188, 191-198, 200, 212, 214, 216, 219-221, 384, 386, 388, 391, 396-397, 399)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/batching.py</span>
                                        <span style="color: var(--text-secondary)">33 lines (ranges: 34, 39, 53, 55, 92-93, 95, 103-106, 108-110, 112-116, 136, 156-157, 160, 162, 181-185, 187-188, 190, 224)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/litellm_provider.py</span>
                                        <span style="color: var(--text-secondary)">44 lines (ranges: 37-38, 41, 60, 62, 82-83, 89, 92, 95-96, 100-101, 104, 106-107, 112, 114, 116-117, 120, 135, 137, 170-174, 176-178, 182, 186-187, 190, 221-222, 224, 227-229, 242-243, 245)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">136 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-325, 327-328, 332-336, 340, 342, 344, 348, 352, 356, 360, 362, 364, 366, 368, 372, 374, 378, 380, 382, 384, 386, 388, 390, 392, 396, 400, 402, 404, 408, 412, 416, 418, 420, 426, 430, 436, 438, 444, 446, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">316 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362-364, 366-367, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-494, 497, 499, 502-507, 512-514, 516-517, 523-531, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/prompts.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 33, 49, 52, 55, 58-59, 65, 78-79, 82-83, 86-87, 92, 94, 98-101, 103-109, 111-112, 116)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">111 lines (ranges: 55, 67-73, 85-86, 98-99, 102, 105-108, 113, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-296, 298-299, 301-302, 304-305, 307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_llm_opt_out_marker</span>
                            <div class="test-meta">
                                <span>63ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that the LLM opt-out marker is correctly recorded in the test report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression where a test might not record the LLM opt-out marker due to a missing or incorrect configuration.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'llm_opt_out' marker should be present in the test report.</li>
                                            <li>The 'llm_opt_out' marker should be set to True for this test.</li>
                                            <li>There should be only one test associated with the 'llm_opt_out' marker in the report.</li>
                                            <li>The 'llm_opt_out' marker should not be False for this test.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        140 output =
                                        430 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181-182, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214-216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestMarkers::test_requirement_marker</span>
                            <div class="test-meta">
                                <span>62ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the requirement marker functionality.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the requirement marker is not recorded correctly, potentially leading to incorrect reporting or analysis of tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `pytest.mark.requirement` decorator should be applied to the `test_with_req` function with both 'REQ-001' and 'REQ-002' requirements.</li>
                                            <li>The `reqs` list in the test data should contain both 'REQ-001' and 'REQ-002'.</li>
                                            <li>The requirement string 'REQ-001' should be present in the `reqs` list of the first test in the report.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        307 input +
                                        145 output =
                                        452 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-200, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203, 205, 207, 210, 212, 214, 216, 218, 220, 222-224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_multiple_xfail_outcomes</span>
                            <div class="test-meta">
                                <span>69ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that multiple xfailed tests are recorded in the report.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that all xfailed tests are properly reported and counted.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of xfailed tests is correctly reported as 2.</li>
                                            <li>All xfailed tests are included in the report.</li>
                                            <li>Each xfailed test has an outcome of 'xfailed'.</li>
                                            <li>No other outcomes are present in the report.</li>
                                            <li>The report path contains a file named 'report.json' with the correct format.</li>
                                            <li>The JSON data is correctly parsed and loaded into memory.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        317 input +
                                        136 output =
                                        453 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_skip_outcome</span>
                            <div class="test-meta">
                                <span>65ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that skipping tests prevents the 'skip' marker from being recorded.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in case of a skipped test, ensuring that the expected number of skipped tests is reported correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The value of `data['summary']['skipped']` should be equal to 1 when the 'skip' marker is applied.</li>
                                            <li>The 'summary' key should exist in the report data and its value should be an integer.</li>
                                            <li>The 'skipped' key should contain a single integer value, which represents the number of skipped tests.</li>
                                            <li>The 'summary' dictionary should have a 'skipped' key with a string value equal to 1.</li>
                                            <li>The 'report.json' file should contain a 'summary' section with a 'skipped' key and its corresponding value.</li>
                                            <li>The 'json.loads()' method should successfully parse the report data from the 'report.json' file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        206 output =
                                        470 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">43 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 106-107, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">112 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328-329, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestOutcomes::test_xfail_outcome</span>
                            <div class="test-meta">
                                <span>68ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that xfailed tests are recorded and reported correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression in the reporting of failed tests, ensuring accurate tracking of xfailed tests.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The number of xfailed tests is exactly 1 as recorded in the report.json file.</li>
                                            <li>The value of `xfailed` in the `summary` dictionary matches the actual count of xfailed tests.</li>
                                            <li>The test data contains a single failed test with the label 'xfailed'.</li>
                                            <li>The report.json file includes an entry for the xfailed test, indicating its status.</li>
                                            <li>The number of xfailed tests is not affected by changes to the test code or environment.</li>
                                            <li>The test does not fail when run without pytester or any other dependencies.</li>
                                            <li>The test can be run multiple times with different inputs and still produce the same report.json file.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        264 input +
                                        192 output =
                                        456 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">47 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-116, 119, 121-122, 124, 127, 132-133, 140, 155-159, 163, 167-169, 171, 181, 185-186, 198-199, 209-210, 212, 216, 250-251, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201-203, 205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">113 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324, 326, 328, 330-331, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestParametrization::test_parametrized_tests</span>
                            <div class="test-meta">
                                <span>66ms</span>
                                <span title="Covered file count">üõ°Ô∏è 7</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test Parametrized Tests: Verify that parameterized tests are recorded separately and their results are reported correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring that the same test is run multiple times with different inputs, which can lead to false negatives if the test is not properly configured.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'pytester.makepyfile' function creates a pytest file with parameterized tests.</li>
                                            <li>The 'pytester.runpytest' function runs the tests and reports their results in a JSON format.</li>
                                            <li>The 'json.loads' function parses the report JSON and verifies that it contains the correct information.</li>
                                            <li>The test asserts that the total number of tests is 3 (since there are three input values) and that all tests pass (since all assertions pass).</li>
                                            <li>The test also asserts that the passed count matches the expected value (three passes).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        290 input +
                                        192 output =
                                        482 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">76 lines (ranges: 190, 194-199, 201, 203-205, 207, 210, 212, 214, 216, 218, 220, 222, 224, 376-392, 394, 397, 399, 402-405, 407, 409, 411, 413, 415, 419, 437, 467-475, 477, 479, 518, 520-524, 526, 528, 530, 532, 534, 536, 538, 540)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484-486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">110 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222-223, 226, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 347, 350-352, 355-356, 359-361, 364, 367-371, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</span>
                            <div class="test-meta">
                                <span>55ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_help_contains_examples</p>
                                    <p><strong>Why Needed:</strong> This test is necessary to ensure that the CLI help text includes usage examples for the plugin registration feature.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_name': 'CLI help text includes usage examples', 'expected_result': 'The CLI help text should include usage examples for the plugin registration feature.', 'actual_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        123 input +
                                        106 output =
                                        229 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_markers_registered</span>
                            <div class="test-meta">
                                <span>49ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> TestPluginRegistration</p>
                                    <p><strong>Why Needed:</strong> To verify that LLM markers are registered.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Markers are registered', 'description': 'LLM markers should be present in the test suite.', 'expected_result': 'True'}</li>
                                            <li>{'name': 'Markers match expected lines', 'description': 'The output of `pytest --markers` should contain the expected marker lines.', 'expected_result': 'True'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        142 input +
                                        115 output =
                                        257 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestPluginRegistration::test_plugin_registered</span>
                            <div class="test-meta">
                                <span>56ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_smoke_pytester.py::TestPluginRegistration::test_plugin_registered</p>
                                    <p><strong>Why Needed:</strong> To verify that the plugin is registered correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'assertion_type': 'contains', 'pattern': '--llm-report*', 'expected_value': ''}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        118 input +
                                        77 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">89 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482, 484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">240 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_smoke_pytester.py::TestSpecialCharacters::test_special_chars_in_nodeid</span>
                            <div class="test-meta">
                                <span>107ms</span>
                                <span title="Covered file count">üõ°Ô∏è 8</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify that special characters in nodeid do not cause Pytest to crash or produce invalid HTML reports.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential regression where special characters in nodeids might cause Pytest to fail or produce corrupted report files.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The presence of special characters in the nodeid does not cause Pytest to crash.</li>
                                            <li>The HTML report generated by Pytest is valid and contains the '<html' tag.</li>
                                            <li>The 'report.html' file exists after running the test.</li>
                                            <li>The content of the 'report.html' file includes the '<html' tag.</li>
                                            <li>The presence of special characters in nodeids does not prevent Pytest from generating a report with a valid HTML structure.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        288 input +
                                        162 output =
                                        450 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">40 lines (ranges: 78-79, 90, 93-94, 96, 99-100, 104, 109-112, 114-115, 124, 127, 132-133, 140, 155-159, 163-164, 167-169, 171, 181, 185-186, 198-199, 209-210, 277, 285)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/coverage_map.py</span>
                                        <span style="color: var(--text-secondary)">12 lines (ranges: 44-45, 58-60, 72-73, 83, 86, 88-90)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/errors.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 142-145)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/models.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 190)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/options.py</span>
                                        <span style="color: var(--text-secondary)">90 lines (ranges: 123, 171, 199, 202-203, 209-210, 217-218, 225-226, 233-234, 241, 245, 247, 249, 251, 253, 257-258, 265-266, 271, 273, 276, 284, 308, 311-312, 320-322, 460, 463, 466, 470, 472-473, 476-477, 482-484, 486, 488, 490, 492, 494, 499-500, 504-505, 511-512, 516-517, 521-522, 528-529, 534, 537-538, 542-543, 547-548, 554-555, 561-562, 566-567, 572, 575-576, 581, 583, 588-589, 593-594, 599, 601, 603, 605, 607, 611, 613)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">288 lines (ranges: 41, 44-48, 50-54, 56-60, 62-66, 68-72, 74-79, 81-86, 90-94, 96-100, 102-106, 108-112, 114-118, 122-126, 128-132, 134-138, 142-146, 148-153, 155-159, 161-165, 169-174, 176-181, 185-190, 192-197, 199-204, 208-213, 215-219, 223-227, 229-233, 235-239, 241-245, 247-252, 254-258, 260-264, 268-272, 274-279, 283-287, 289-293, 297-302, 304-309, 311-315, 328-330, 332-334, 336-338, 342, 346-347, 349, 351, 354-355, 362, 371-373, 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485, 491-492, 534-544, 558-559, 562, 566-568, 579, 583, 602, 606-608, 619, 623, 626, 628-629)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/render.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 30-31, 40, 42-46, 50-51, 53, 65, 67, 79-85, 87, 99, 101-102, 107)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/report_writer.py</span>
                                        <span style="color: var(--text-secondary)">106 lines (ranges: 55, 67-73, 85-86, 98-100, 127-128, 130, 156-158, 186, 192-193, 197-198, 202, 211-218, 222, 226-227, 230, 233, 254, 256-259, 262-264, 266, 268-275, 277-278, 280-289, 291-294, 296-297, 299-300, 302-303, 305-307, 319, 321-322, 324-325, 337, 383, 385-386, 389, 392, 395, 398-402, 477-478, 502, 504, 506-508, 510, 513)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_time.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">15 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_boundary_one_minute</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_boundary_one_minute</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats durations in one minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected_value': '1m 0.0s', 'actual_value': '1m 0.0s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        106 input +
                                        84 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_microseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_microseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats sub-millisecond durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The result contains 'Œºs' (microseconds) assertion", 'expected': '500Œºs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        121 input +
                                        86 output =
                                        207 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_milliseconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_milliseconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats sub-second durations as milliseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': "result contains 'ms'", 'expected': '500.0ms'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        119 input +
                                        78 output =
                                        197 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_minutes_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_minutes_format</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats durations over a minute, including minutes and seconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The result should contain 'm' (minutes) in its string representation.", 'expected_value': '1m'}</li>
                                            <li>{'description': 'The result should be equal to the expected value.', 'expected_value': '1m 30.5s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        124 input +
                                        122 output =
                                        246 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_multiple_minutes</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_multiple_minutes</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats multiple minutes into a human-readable string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected': '3m 5.0s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        112 input +
                                        78 output =
                                        190 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 39, 41, 43, 46-48)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_one_second</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_one_second</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats a duration of exactly one second as '1.00s'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'description': "The result of calling format_duration(1.0) should be equal to '1.00s'.", 'expected_value': '1.00s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        101 input +
                                        102 output =
                                        203 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_seconds_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_seconds_format</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats seconds under a minute.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'expected': '5.50s', 'actual': '5.50s'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        110 input +
                                        76 output =
                                        186 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 39, 41, 43-44)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_small_milliseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_small_milliseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure the `format_duration` function correctly formats small millisecond durations.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'result', 'expected_value': '1.0ms'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        111 input +
                                        74 output =
                                        185 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">3 lines (ranges: 39, 41-42)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestFormatDuration::test_very_small_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestFormatDuration::test_very_small_microseconds</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `format_duration` function correctly formats very small durations as microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'value': '1Œºs'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        77 output =
                                        193 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">2 lines (ranges: 39-40)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_datetime_with_utc</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test ISO Format with UTC</p>
                                    <p><strong>Why Needed:</strong> To verify the correct formatting of datetime objects with UTC timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected output', 'value': '2024-01-15T10:30:45+00:00'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        143 input +
                                        75 output =
                                        218 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_naive_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Tests for ISO Format</p>
                                    <p><strong>Why Needed:</strong> To ensure the naive datetime format is correct without timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected result', 'value': '2024-06-20T14:00:00'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        136 input +
                                        69 output =
                                        205 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestIsoFormat::test_formats_with_microseconds</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test IsoFormat with microseconds</p>
                                    <p><strong>Why Needed:</strong> To test the functionality of formatting datetime objects with microseconds.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected value in result', 'value': '123456'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        133 input +
                                        62 output =
                                        195 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 27)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_has_utc_timezone</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the current time has a valid UTC timezone.</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `datetime` object returned by `utc_now()` has a valid timezone.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'assert result.tzinfo is not None', 'description': 'The test asserts that the result of `utc_now()` has a timezone info.', 'expected_result': 'True'}</li>
                                            <li>{'name': 'assert result.tzinfo == UTC', 'description': 'The test asserts that the result of `utc_now()` has a valid UTC timezone.', 'expected_result': 'UTC'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        109 input +
                                        147 output =
                                        256 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_is_current_time</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_is_current_time</p>
                                    <p><strong>Why Needed:</strong> To ensure that the `utc_now` function returns a time within a reasonable tolerance of the current UTC time.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'before <= result <= after', 'description': 'The before and after times should be within a reasonable tolerance of each other.'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        116 input +
                                        94 output =
                                        210 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_time.py::TestUtcNow::test_returns_datetime</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> tests/test_time.py::TestUtcNow::test_returns_datetime</p>
                                    <p><strong>Why Needed:</strong> This test ensures that the function `utc_now()` returns a datetime object.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Type of result', 'expected': 'datetime', 'actual': 'isinstance(result, datetime)'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        94 input +
                                        82 output =
                                        176 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/util/time.py</span>
                                        <span style="color: var(--text-secondary)">1 lines (ranges: 15)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">12 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_command_failure</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> When TokenRefresher raises an error on command failure, then the test verifies that it correctly returns a TokenRefreshError with appropriate error message.</p>
                                    <p><strong>Why Needed:</strong> This test prevents potential regression where the TokenRefresher might not raise an error when encountering a command failure, potentially causing unexpected behavior or errors later in the application.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` of the `TokenRefresher` object should return a `TokenRefreshError` with the message 'Authentication failed'.</li>
                                            <li>The string 'exit 1' should be present in the error message returned by `get_token()`.</li>
                                            <li>The string 'Authentication failed' should be present in the error message returned by `get_token()`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        310 input +
                                        161 output =
                                        471 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_empty_output</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Verify TokenRefresher raises error on empty output when no token is available.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not raise an error when there is no token to refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method of the `TokenRefresher` class should raise a `TokenRefreshError` exception with the message 'empty output'.</li>
                                            <li>The `stdout` and `stderr` attributes of the `get_token()` method should be empty strings.</li>
                                            <li>The `returncode` attribute of the `get_token()` method should be 0 (indicating successful execution).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        297 input +
                                        144 output =
                                        441 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-109, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_force_refresh</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that forcing a refresh bypasses the cache and returns a new token.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a regression where the TokenRefresher does not return a new token when forced to refresh.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` of the `TokenRefresher` class returns the expected token value for both `token1` and `token2` after force refresh.</li>
                                            <li>The number of calls to the `run` method of the subprocess is equal to 2, which matches the expected behavior when forcing a refresh.</li>
                                            <li>Both `token1` and `token2` have different values than before the force refresh.</li>
                                            <li>The output of the subprocess contains the token value with the correct index (e.g. 'token-1' for `token1` and 'token-2' for `token2`).</li>
                                            <li>The error message from the subprocess is empty.</li>
                                            <li>The return code of the subprocess is 0, indicating successful execution.</li>
                                            <li>The output format of the subprocess is set to 'text'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        346 input +
                                        230 output =
                                        576 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_custom_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the `TokenRefresher` uses a custom JSON key for token refresh.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential issue where the default JSON key is used instead of a custom one.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method returns the expected custom JSON key value.</li>
                                            <li>The `access_token` attribute of the returned object matches the custom key value.</li>
                                            <li>The `json_key` parameter passed to the `TokenRefresher` constructor is used correctly.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        303 input +
                                        115 output =
                                        418 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_json_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `TokenRefresher` extracts a JSON object containing the extracted token from the expected JSON output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the `TokenRefresher` does not extract the token correctly if the output format is set to 'json'.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The output of the `get-token` command should be a JSON object with the following structure: `{'token': 'json-token-value', 'expires_in': 3600}`.</li>
                                            <li>The extracted token should match the expected value: `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        308 input +
                                        131 output =
                                        439 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">29 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132-135, 139, 143-144, 148)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_get_token_text_format</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the `TokenRefresher` class correctly extracts a token from text output when the `output_format` is set to 'text'.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the extracted token is not in the expected format, potentially leading to incorrect usage or unexpected behavior.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The extracted token matches the provided input string 'my-secret-token'.</li>
                                            <li>The output of `subprocess.run` contains the correct text after processing.</li>
                                            <li>The error message from `subprocess.run` does not indicate an issue with the token extraction process.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        298 input +
                                        135 output =
                                        433 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalid_json</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the TokenRefresher raises an error when it encounters invalid JSON.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher incorrectly interprets valid JSON as a token refresh request.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method of the `TokenRefresher` instance should raise a `TokenRefreshError` exception when it encounters invalid JSON.</li>
                                            <li>The error message returned by the `get_token()` method should indicate that the input is not valid JSON.</li>
                                            <li>The test should fail when running the `get_token()` method on an invalid JSON string.</li>
                                            <li>The test should pass when running the `get_token()` method on a valid JSON string.</li>
                                            <li>The error message returned by the `get_token()` method should be in lowercase (e.g. 'json' instead of 'JSON'),</li>
                                            <li>The test should only fail when running the `get_token()` method on an invalid JSON string, not on other types of exceptions.</li>
                                            <li>The test should pass for all other valid input strings.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        299 input +
                                        234 output =
                                        533 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">25 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-134, 149-150)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_invalidate</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher.invalidate() clears cache and updates the token count correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher does not update the token count after calling invalidate().</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `invalidate()` of the `TokenRefresher` class should clear the cache by setting the call_count to 1.</li>
                                            <li>The function `invalidate()` of the `TokenRefresher` class should update the token count by setting it to 2 after calling `get_token()`.</li>
                                            <li>The function `invalidate()` of the `TokenRefresher` class should not have any side effects on the token count.</li>
                                            <li>The function `invalidate()` of the `TokenRefresher` class should clear the cache even if an exception is raised during execution.</li>
                                            <li>The function `invalidate()` of the `TokenRefresher` class should update the token count after calling `get_token()` regardless of whether an exception is raised or not.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        340 input +
                                        211 output =
                                        551 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156, 160-162)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_missing_json_key</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher raises an error when the JSON key is missing.</p>
                                    <p><strong>Why Needed:</strong> To prevent a potential bug where the TokenRefresher fails to refresh tokens due to a missing required JSON key.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `TokenRefreshError` exception should be raised with a message indicating that the token was not found.</li>
                                            <li>The error message should include the word 'not found'.</li>
                                            <li>The error message should be case-insensitive (i.e., it should match 'Not Found' regardless of the original casing).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        325 input +
                                        125 output =
                                        450 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139-141, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_thread_safety</span>
                            <div class="test-meta">
                                <span>52ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test TokenRefresher thread safety by starting multiple threads concurrently and verifying that they all retrieve the same token.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where multiple threads accessing the TokenRefresher instance simultaneously could result in inconsistent or incorrect results due to race conditions.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` should return the same token for each thread that acquires the lock.</li>
                                            <li>Each thread should acquire the lock before executing the `get_token()` method and retrieve the same token.</li>
                                            <li>If multiple threads start retrieving tokens concurrently, they should all return the same token.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        427 input +
                                        134 output =
                                        561 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_timeout_handling</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> The test verifies that the TokenRefresher handles command timeouts correctly.</p>
                                    <p><strong>Why Needed:</strong> This test prevents a potential bug where the TokenRefresher fails to refresh tokens when they timeout.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method raises a `TokenRefreshError` with the message 'timed out' after a timeout of 30 seconds.</li>
                                            <li>The `get_token()` method does not raise an exception or log an error when the token refresh times out.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        279 input +
                                        111 output =
                                        390 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">16 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113-114)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh.py::TestTokenRefresher::test_token_caching</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that TokenRefresher caches tokens and doesn't call the command again.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where multiple requests to get a token would result in the same cached token being returned.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` returns the expected token value.</li>
                                            <li>The output of `refresher.get_token()` is the same as the input, indicating caching.</li>
                                            <li>The number of calls to `refresher.get_token()` is correct (1 in this case).</li>
                                            <li>The cached token has not changed even after multiple requests.</li>
                                            <li>The command 'get-token' is called only once with a valid token.</li>
                                            <li>The output format is set to 'text'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        353 input +
                                        159 output =
                                        512 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">28 lines (ranges: 59-60, 63-66, 69-72, 83, 85-86, 90, 93-98, 101, 107-108, 111, 132, 153-154, 156)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_refresh_coverage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">9 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_command_failure_no_stderr</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the TokenRefresher edge case when command fails with no stderr output.</p>
                                    <p><strong>Why Needed:</strong> To prevent a regression where the TokenRefresher does not raise an exception when the command fails without producing any error output.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token()` method of the `TokenRefresher` instance raises a `TokenRefreshError` with an exit code of 1.</li>
                                            <li>The `stderr` attribute of the `get_token()` method is set to an empty string, indicating no error output.</li>
                                            <li>The `stdout` attribute of the `get_token()` method is also set to an empty string, indicating no error output.</li>
                                            <li>When the command fails without producing any error output, the `TokenRefresher` instance raises a `TokenRefreshError` with an exit code of 1.</li>
                                            <li>The `exit_code` attribute of the exception raised by the `get_token()` method is set to 1.</li>
                                            <li>The `stderr` and `stdout` attributes are not changed in the case where the command fails without producing any error output.</li>
                                            <li>In this scenario, the `TokenRefresher` instance correctly raises a `TokenRefreshError` with an exit code of 1.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        322 input +
                                        261 output =
                                        583 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">20 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101-104, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_empty_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Token Refresh Coverage</p>
                                    <p><strong>Why Needed:</strong> Test case for handling empty command string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>{'name': 'Expected exception type', 'value': 'TokenRefreshError'}</li>
                                            <li>{'name': 'Expected error message', 'value': 'empty'}</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        151 input +
                                        77 output =
                                        228 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_invalid_command_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_invalid_command_string function to verify it handles an invalid command string (shlex parse error).</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the TokenRefresher class incorrectly raises a TokenRefreshError when given an invalid command string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `TokenRefresher` instance is created with an invalid command string that contains unescaped quotes, which causes a shlex parse error.</li>
                                            <li>When calling `get_token()` on the `TokenRefresher` instance with an invalid command string, it raises a `TokenRefreshError` exception containing the message 'Invalid command string'.</li>
                                            <li>The `TokenRefresher` class correctly handles the case where the input command string contains unescaped quotes, preventing the shlex parse error and ensuring the correct behavior.</li>
                                            <li>The test verifies that the `TokenRefresher` instance is created with an invalid command string that causes a `TokenRefreshError` exception to be raised when calling `get_token()`.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        251 input +
                                        213 output =
                                        464 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-88, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_not_dict</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test that the test_json_not_dict scenario verifies a bug preventing handling of non-dict JSON output.</p>
                                    <p><strong>Why Needed:</strong> This test prevents regression by ensuring the TokenRefresher handles non-dict JSON output correctly.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `get_token` method should raise a `TokenRefreshError` when receiving a non-dict JSON output.</li>
                                            <li>The error message should contain 'Expected JSON object'.</li>
                                            <li>The error message should contain 'list'.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        328 input +
                                        110 output =
                                        438 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">27 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-137, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_empty_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when token value is an empty string.</p>
                                    <p><strong>Why Needed:</strong> Prevents TestTokenRefresherEdgeCases::test_json_token_empty_string from failing due to unexpected behavior of the TokenRefresher class.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The 'token' key in the JSON output should be a non-empty string.</li>
                                            <li>The 'token' key in the JSON output should not contain any whitespace characters.</li>
                                            <li>The error message should indicate that the token value is empty or not a string.</li>
                                            <li>The test should raise a TokenRefreshError with an appropriate error message when encountering an empty or non-string token value.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        324 input +
                                        140 output =
                                        464 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_json_token_not_string</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when token value is not a string.</p>
                                    <p><strong>Why Needed:</strong> Prevents the TokenRefresher from attempting to refresh a non-string token value, which could lead to unexpected behavior or errors.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The `json.dumps` function is called with an integer value instead of a string.</li>
                                            <li>The `returncode` of the subprocess call is set to 0 (success), but the error message does not indicate that the token was invalid.</li>
                                            <li>The `stderr` parameter is empty, which may indicate that no error occurred or that the token is valid.</li>
                                            <li>The `json_key` parameter is set to `</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        326 input +
                                        147 output =
                                        473 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">30 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 101, 107-108, 111, 113, 115, 132-135, 139, 143-146, 149)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_oserror_on_execution</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test verifies that a TokenRefresher handles an OSError when executing a command.</p>
                                    <p><strong>Why Needed:</strong> This test prevents the regression of TokenRefreshError not being raised when executing commands that are not found.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` raises a `TokenRefreshError` with the message 'Failed to execute' when executed on a nonexistent command.</li>
                                            <li>The error message includes the string 'Command not found'.</li>
                                            <li>The function does not raise an exception or return an error code when executing a nonexistent command.</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        280 input +
                                        122 output =
                                        402 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">19 lines (ranges: 59-60, 63, 69, 83, 85-86, 90, 93-98, 113, 115-118)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_text_only_whitespace_lines</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test handling when text output has only whitespace lines after initial strip, specifically when parsing with only blank lines.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the TokenRefresher fails to handle text output with only whitespace lines after an initial strip.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>assert 'No non-empty lines' in str(exc_info.value)</li>
                                            <li>assert 'Only whitespace lines' in str(exc_info.value)</li>
                                            <li>assert 'Blank line' in str(exc_info.value)</li>
                                            <li>assert 'Only whitespace content lines' in str(exc_info.value)</li>
                                            <li>assert 'Non-empty wrapper but only whitespace content lines' in str(exc_info.value)</li>
                                            <li>assert 'No non-whitespace output' in str(exc_info.value)</li>
                                            <li>assert 'Output is empty' in str(exc_info.value)</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        376 input +
                                        174 output =
                                        550 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">4 lines (ranges: 132, 153-155)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_refresh_coverage.py::TestTokenRefresherEdgeCases::test_whitespace_only_command</span>
                            <div class="test-meta">
                                <span>1ms</span>
                                <span title="Covered file count">üõ°Ô∏è 3</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test the test_whitespace_only_command to ensure it correctly raises a TokenRefreshError for an empty whitespace-only command string.</p>
                                    <p><strong>Why Needed:</strong> Prevents a potential bug where the TokenRefresher is not raised with a meaningful error message when given an empty whitespace-only command string.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The function `get_token()` of the `TokenRefresher` object should raise a `TokenRefreshError` exception.</li>
                                            <li>The error message returned by `get_token()` should contain the word 'empty'.</li>
                                            <li>The assertion should fail when the input command is an empty string (i.e., no whitespace characters).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        236 input +
                                        141 output =
                                        377 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/llm/token_refresh.py</span>
                                        <span style="color: var(--text-secondary)">11 lines (ranges: 59-60, 63, 69, 83, 85-86, 90-91, 113, 115)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">6 lines (ranges: 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
            <div class="test-file-group">
                <div class="test-file-header">
                    <span>üìÑ tests/test_token_usage.py</span>
                    <span style="font-size: 0.9rem; font-weight: 400; color: var(--text-secondary)">1 tests</span>
                </div>
                <div class="test-row outcome-passed" data-status="passed">
                    <details open>
                        <summary class="test-header">
                            <span class="status-badge status-passed">PASSED</span>
                            <span class="test-name">tests/test_token_usage.py::test_token_usage_aggregation</span>
                            <div class="test-meta">
                                <span>5ms</span>
                                <span title="Covered file count">üõ°Ô∏è 2</span>
                            </div>
                        </summary>

                        <div class="test-details">

                            <div class="detail-section">
                                <div class="detail-title">AI Assessment</div>
                                <div class="llm-annotation">
                                    <p><strong>Scenario:</strong> Test token usage aggregation with mock stash and terminal reporter.</p>
                                    <p><strong>Why Needed:</strong> Prevents regression in token usage reporting for different test cases.</p>
                                    <div class="key-assertions">
                                        <strong>Key Assertions:</strong>
                                        <ul>
                                            <li>The total input tokens should be 30 (10 + 20).</li>
                                            <li>The total output tokens should be 15 (5 + 10).</li>
                                            <li>The number of annotations should be 2.</li>
                                            <li>The total tokens should be 45 (15 + 30).</li>
                                        </ul>
                                    </div>
                                    <p class="confidence-score" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem;">
                                        <strong>Confidence:</strong> 80%
                                    </p>
                                    <p class="token-usage" style="font-size: 0.85em; color: var(--text-secondary); margin-top: 0.5rem; border-top: 1px dashed #e5e7eb; padding-top: 0.5rem;">
                                        <strong>Tokens:</strong>
                                        775 input +
                                        107 output =
                                        882 total
                                    </p>
                                </div>
                            </div>

                            <div class="detail-section">
                                <div class="detail-title">Coverage</div>
                                <div class="coverage-list">
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/collector.py</span>
                                        <span style="color: var(--text-secondary)">14 lines (ranges: 90, 93, 96, 99, 110-112, 114-115, 124, 127, 140, 209-210)</span>
                                    </div>
                                    <div class="coverage-item" style="padding: 0.5rem 1rem;">
                                        <span>src/pytest_llm_report/plugin.py</span>
                                        <span style="color: var(--text-secondary)">73 lines (ranges: 399, 403, 407, 410, 429-430, 437-438, 441-442, 444-445, 448-452, 454, 457-458, 460, 463-464, 485-487, 491-494, 497, 499, 502-506, 509, 512-514, 516-521, 523-531, 534-544, 558-559, 562, 566-568)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </details>
                </div>
            </div>
        </div>
        </section>
    </div>
</body>
</html>